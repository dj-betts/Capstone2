{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('type_text.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_text_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def flatten(lst):\n",
    "#     doc = []\n",
    "#     for string in lst:\n",
    "#         doc.append(string)\n",
    "        \n",
    "#     return doc\n",
    "#         #for word in string:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_trim(string):\n",
    "    text = string.split(\" \")\n",
    "    text = text[3:-14]\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_text_df.text = type_text_df.text.apply(lambda string: split_trim(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = type_text_df.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-244-190fab0dc62d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-244-190fab0dc62d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    CountVectorizer(*, input='content',\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "CountVectorizer(*, input='content', \n",
    "                encoding='utf-8', \n",
    "                decode_error='strict', \n",
    "                strip_accents=None, \n",
    "                lowercase=True, \n",
    "                preprocessor=None, \n",
    "                tokenizer=None, \n",
    "                stop_words=None, \n",
    "                token_pattern='(?u)\\b\\w\\w+\\b', \n",
    "                ngram_range=(1, 1), \n",
    "                analyzer='word', \n",
    "                max_df=1.0, \n",
    "                min_df=1, \n",
    "                max_features=None, \n",
    "                vocabulary=None, \n",
    "                binary=False, \n",
    "                dtype=<class 'numpy.int64'>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "822\n",
      "['000', '120', '13', '1914', '1919', '2004', '2019', '38', '62', 'ability', 'able', 'accelerated', 'accidental', 'according', 'achievement', 'adolf', 'advancing', 'affairs', 'affected', 'affecting', 'africa', 'african', 'age', 'aggregation', 'ago', 'ahead', 'airplanes', 'alabama', 'alike', 'alter', 'altered', 'america', 'americans', 'anarchists', 'anxieties', 'apace', 'apart', 'apocalypse', 'approve', 'ash', 'asking', 'attacked', 'attention', 'attitudes', 'attorney', 'austrian', 'automobile', 'automobiles', 'averaged', 'awakened', 'babe', 'band', 'barely', 'bazaar', 'bear', 'beasts', 'began', 'begin', 'beginning', 'beleaguered', 'belgian', 'believe', 'believed', 'belligerents', 'belonging', 'best', 'better', 'bewildering', 'big', 'bit', 'blind', 'bloomed', 'blue', 'boisterous', 'bomb', 'bombs', 'book', 'boomeranged', 'boost', 'born', 'boston', 'british', 'broader', 'broke', 'broken', 'brooklyn', 'brought', 'build', 'built', 'business', 'bustling', 'butler', 'california', 'called', 'calling', 'calm', 'campaign', 'capitol', 'captures', 'career', 'carnegie', 'carpets', 'cars', 'case', 'cases', 'celebrated', 'center', 'century', 'certainly', 'chafed', 'challenge', 'change', 'changed', 'changing', 'chaos', 'cherished', 'chicago', 'children', 'chirpy', 'chose', 'christ', 'churchill', 'cities', 'citizenship', 'city', 'clear', 'clearly', 'clemenceau', 'close', 'closer', 'clumsy', 'coast', 'coax', 'college', 'combustion', 'come', 'comforts', 'coming', 'communication', 'complained', 'conditions', 'conducted', 'conflict', 'congress', 'conservative', 'constantly', 'consulting', 'continue', 'continued', 'contract', 'contradictions', 'contrast', 'contributions', 'convened', 'conversing', 'convoy', 'core', 'corral', 'correct', 'council', 'countries', 'country', 'crack', 'crackly', 'crackups', 'create', 'creation', 'crippled', 'criticized', 'crowds', 'crush', 'curse', 'cusp', 'daily', 'day', 'days', 'deadly', 'deal', 'decades', 'decisions', 'decisively', 'defend', 'defenders', 'demanding', 'democracies', 'democracy', 'democratic', 'demographic', 'desperate', 'despite', 'destabilizing', 'destination', 'determination', 'did', 'didn', 'different', 'difficult', 'diplomats', 'directed', 'directions', 'directly', 'disappeared', 'dismayed', 'distinguished', 'distress', 'divide', 'divided', 'dizzying', 'dominate', 'dominated', 'doom', 'doubled', 'doughboys', 'dreading', 'dream', 'driver', 'dwight', 'eager', 'earlier', 'easily', 'east', 'effect', 'efficiency', 'effort', 'efforts', 'eisenhower', 'elapsed', 'elected', 'electric', 'elites', 'elixir', 'elusive', 'em', 'embraced', 'emerged', 'emphasis', 'empires', 'end', 'ended', 'energy', 'engines', 'entertainment', 'entitled', 'entry', 'envy', 'epidemic', 'equal', 'era', 'essay', 'essays', 'ethics', 'euphoria', 'europe', 'european', 'events', 'eventually', 'exacerbated', 'excesses', 'exchanged', 'existed', 'expanded', 'experimentation', 'exploded', 'exuberant', 'factory', 'failed', 'failings', 'failures', 'fair', 'fall', 'famous', 'fans', 'fantastic', 'far', 'farm', 'farmers', 'fascism', 'fault', 'faulted', 'fear', 'fears', 'feature', 'fellow', 'felt', 'feted', 'film', 'fitzgerald', 'floodgates', 'followed', 'following', 'footage', 'forever', 'form', 'forms', 'fortunately', 'france', 'franklin', 'freedom', 'french', 'fueled', 'function', 'gain', 'galvanic', 'gave', 'general', 'generally', 'generation', 'geopolitical', 'george', 'georges', 'georgia', 'german', 'gleaming', 'glean', 'gloom', 'glorious', 'going', 'gone', 'gonna', 'government', 'grainy', 'grammarians', 'grasp', 'great', 'greeted', 'grew', 'grow', 'guises', 'half', 'hall', 'hand', 'happily', 'harbor', 'harding', 'harlem', 'harsh', 'harvest', 'hastily', 'headed', 'headlines', 'heap', 'heard', 'heavy', 'hellfighters', 'help', 'helped', 'heroes', 'highway', 'hint', 'historians', 'history', 'hit', 'hitler', 'hold', 'hollywood', 'honors', 'hope', 'hoped', 'hoping', 'horizons', 'hottest', 'hour', 'house', 'huge', 'idea', 'idealism', 'ideas', 'ii', 'illinois', 'imagination', 'imagined', 'immigrants', 'imperiled', 'important', 'imposed', 'impressive', 'incapacitated', 'included', 'independence', 'independent', 'influenza', 'ingenious', 'innovating', 'inside', 'inspired', 'intact', 'intelligence', 'internal', 'international', 'interstate', 'intoned', 'invented', 'invoked', 'ireland', 'jackie', 'james', 'jazz', 'jesus', 'joining', 'joyce', 'july', 'just', 'kept', 'killing', 'kind', 'know', 'known', 'lamented', 'large', 'largely', 'largest', 'late', 'later', 'lazy', 'leaders', 'league', 'lecturer', 'led', 'left', 'leisure', 'length', 'lengths', 'leon', 'letter', 'life', 'like', 'line', 'lines', 'lionized', 'live', 'lives', 'lofty', 'long', 'longed', 'longest', 'look', 'lovely', 'macaulay', 'machines', 'majority', 'make', 'manpower', 'map', 'marching', 'marketing', 'markets', 'mass', 'mat√©riel', 'measure', 'memorable', 'middle', 'midwest', 'miles', 'military', 'millions', 'mind', 'mirrors', 'misreading', 'mitchell', 'mobilize', 'mobsters', 'moderated', 'moment', 'money', 'monopoly', 'month', 'moralistic', 'mother', 'motor', 'moved', 'movements', 'movie', 'moving', 'mr', 'music', 'named', 'nasty', 'nation', 'national', 'nationalism', 'nationalisms', 'nations', 'near', 'nearly', 'need', 'needed', 'negotiators', 'neighbor', 'neighbors', 'neologism', 'nevada', 'new', 'newly', 'newsreels', 'nineteen', 'normalcy', 'northern', 'notebook', 'novelty', 'numbers', 'obliterated', 'obvious', 'occasional', 'oceanic', 'odd', 'officer', 'ohio', 'oil', 'old', 'ones', 'open', 'opinion', 'opposed', 'opposing', 'order', 'origins', 'ottoman', 'outcome', 'outflank', 'outside', 'overquoted', 'overseas', 'overwhelmingly', 'overzealous', 'owner', 'palaces', 'palmer', 'parade', 'parades', 'paralyzed', 'paree', 'paris', 'parts', 'passage', 'paved', 'peace', 'people', 'pesky', 'phrase', 'phrases', 'pivotal', 'plan', 'playing', 'pockets', 'poem', 'poems', 'poles', 'police', 'political', 'politically', 'politician', 'popular', 'populated', 'possible', 'postwar', 'poverty', 'powered', 'presidency', 'president', 'presidents', 'prewar', 'problem', 'problems', 'produced', 'production', 'profound', 'prognosticators', 'prohibition', 'promised', 'promises', 'promising', 'promote', 'protect', 'prove', 'publicized', 'publish', 'pursuits', 'push', 'question', 'quick', 'quickly', 'quiet', 'quieter', 'quite', 'quoted', 'race', 'radio', 'raids', 'rakish', 'rallies', 'rascality', 'rascals', 'rate', 'raucously', 'reach', 'realism', 'reality', 'realm', 'reasons', 'received', 'recipe', 'recording', 'red', 'redraw', 'reeled', 'refused', 'regiment', 'released', 'relevant', 'relish', 'remained', 'remembered', 'repeatedly', 'repeating', 'republican', 'research', 'resentment', 'response', 'responsibilities', 'result', 'resulted', 'retain', 'retaliatory', 'return', 'returned', 'revealed', 'rhetoric', 'ride', 'ring', 'ringing', 'rings', 'riot', 'rise', 'road', 'roads', 'robinson', 'roosevelt', 'rowling', 'run', 'rural', 'russia', 'ruth', 'safe', 'sales', 'saw', 'scorned', 'scott', 'scribbledehobble', 'scrutiny', 'seat', 'second', 'seconded', 'section', 'seeing', 'seeking', 'seen', 'self', 'senator', 'senior', 'sense', 'sent', 'series', 'sermonettes', 'set', 'settling', 'shaped', 'share', 'shimmering', 'shortcomings', 'sights', 'significant', 'simmered', 'simply', 'small', 'socially', 'solemnity', 'solve', 'songs', 'soon', 'sounds', 'south', 'sox', 'speech', 'speeches', 'spent', 'spirited', 'spokesman', 'sports', 'spots', 'sprang', 'spring', 'stars', 'start', 'started', 'state', 'states', 'statue', 'steam', 'strain', 'stroke', 'struggling', 'studios', 'studying', 'stunning', 'suburban', 'successful', 'superhuman', 'support', 'sure', 'surely', 'surface', 'surfaces', 'survived', 'swirling', 'talking', 'tall', 'tanks', 'targeted', 'team', 'ted', 'tensions', 'terrifying', 'territories', 'test', 'thanks', 'things', 'thought', 'thoughts', 'thousands', 'threatened', 'thriving', 'tide', 'time', 'times', 'titled', 'today', 'took', 'torn', 'towns', 'trace', 'traction', 'traded', 'transformation', 'travel', 'treaty', 'tremendous', 'trend', 'tried', 'trip', 'trotsky', 'true', 'truth', 'trying', 'turned', 'ugly', 'unbridled', 'undergoing', 'understood', 'unexpected', 'united', 'university', 'unleash', 'urban', 'use', 'used', 'ushered', 'using', 'utah', 'vaguely', 'vanished', 'various', 've', 'vehicle', 'vehicles', 'versailles', 'versions', 'victory', 'vigorous', 'villains', 'virtue', 'vividly', 'voice', 'waging', 'wallace', 'waned', 'war', 'warren', 'washington', 'waves', 'way', 'ways', 'wealthiest', 'weary', 'welcoming', 'went', 'west', 'white', 'widmer', 'william', 'wilson', 'win', 'winds', 'winston', 'women', 'woodrow', 'word', 'words', 'work', 'working', 'world', 'worth', 'writers', 'writing', 'wrong', 'wrote', 'ya', 'yankees', 'year', 'years', 'yeats', 'york', 'young']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(text)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "print(len(feature_names))\n",
    "print(feature_names)\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sklearn.feature_extraction.text.TfidfVectorizer(*, \n",
    "                                                      input='content', \n",
    "                                                      encoding='utf-8', \n",
    "                                                      decode_error='strict', \n",
    "                                                      strip_accents=None, \n",
    "                                                      lowercase=True, \n",
    "                                                      preprocessor=None, \n",
    "                                                      tokenizer=None, \n",
    "                                                      analyzer='word', \n",
    "                                                      stop_words=None, \n",
    "                                                      token_pattern='(?u)\\b\\w\\w+\\b', \n",
    "                                                      ngram_range=(1, 1), \n",
    "                                                      max_df=1.0, \n",
    "                                                      min_df=1, \n",
    "                                                      max_features=None, \n",
    "                                                      vocabulary=None, \n",
    "                                                      binary=False, \n",
    "                                                      dtype=<class 'numpy.float64'>, \n",
    "                                                      norm='l2', use_idf=True, \n",
    "                                                      smooth_idf=True, \n",
    "                                                      sublinear_tf=False)["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2301"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "964\n",
      "['000', '120', '13', '1914', '1919', '2004', '2019', '38', '62', 'ability', 'able', 'about', 'accelerated', 'accidental', 'according', 'achievement', 'adolf', 'advancing', 'affairs', 'affected', 'affecting', 'africa', 'african', 'after', 'again', 'age', 'aggregation', 'ago', 'ahead', 'airplanes', 'alabama', 'alike', 'all', 'almost', 'along', 'already', 'also', 'alter', 'altered', 'america', 'americans', 'an', 'anarchists', 'and', 'another', 'anxieties', 'anyone', 'apace', 'apart', 'apocalypse', 'approve', 'are', 'around', 'as', 'ash', 'asking', 'at', 'attacked', 'attention', 'attitudes', 'attorney', 'austrian', 'automobile', 'automobiles', 'averaged', 'awakened', 'babe', 'back', 'band', 'barely', 'bazaar', 'be', 'bear', 'beasts', 'become', 'been', 'before', 'began', 'begin', 'beginning', 'behind', 'being', 'beleaguered', 'belgian', 'believe', 'believed', 'belligerents', 'belonging', 'below', 'best', 'better', 'between', 'bewildering', 'big', 'bit', 'blind', 'bloomed', 'blue', 'boisterous', 'bomb', 'bombs', 'book', 'boomeranged', 'boost', 'born', 'boston', 'british', 'broader', 'broke', 'broken', 'brooklyn', 'brought', 'build', 'built', 'business', 'bustling', 'but', 'butler', 'by', 'california', 'called', 'calling', 'calm', 'campaign', 'can', 'cannot', 'capitol', 'captures', 'career', 'carnegie', 'carpets', 'cars', 'case', 'cases', 'celebrated', 'center', 'century', 'certainly', 'chafed', 'challenge', 'change', 'changed', 'changing', 'chaos', 'cherished', 'chicago', 'children', 'chirpy', 'chose', 'christ', 'churchill', 'cities', 'citizenship', 'city', 'clear', 'clearly', 'clemenceau', 'close', 'closer', 'clumsy', 'coast', 'coax', 'college', 'combustion', 'come', 'comforts', 'coming', 'communication', 'complained', 'conditions', 'conducted', 'conflict', 'congress', 'conservative', 'constantly', 'consulting', 'continue', 'continued', 'contract', 'contradictions', 'contrast', 'contributions', 'convened', 'conversing', 'convoy', 'core', 'corral', 'correct', 'could', 'council', 'countries', 'country', 'crack', 'crackly', 'crackups', 'create', 'creation', 'crippled', 'criticized', 'crowds', 'crush', 'curse', 'cusp', 'daily', 'day', 'days', 'deadly', 'deal', 'decades', 'decisions', 'decisively', 'defend', 'defenders', 'demanding', 'democracies', 'democracy', 'democratic', 'demographic', 'describe', 'desperate', 'despite', 'destabilizing', 'destination', 'determination', 'did', 'didn', 'different', 'difficult', 'diplomats', 'directed', 'directions', 'directly', 'disappeared', 'dismayed', 'distinguished', 'distress', 'divide', 'divided', 'dizzying', 'dominate', 'dominated', 'done', 'doom', 'doubled', 'doughboys', 'down', 'dreading', 'dream', 'driver', 'during', 'dwight', 'each', 'eager', 'earlier', 'easily', 'east', 'effect', 'efficiency', 'effort', 'efforts', 'eisenhower', 'either', 'elapsed', 'elected', 'electric', 'elites', 'elixir', 'else', 'elusive', 'em', 'embraced', 'emerged', 'emphasis', 'empires', 'end', 'ended', 'energy', 'engines', 'entertainment', 'entitled', 'entry', 'envy', 'epidemic', 'equal', 'era', 'essay', 'essays', 'ethics', 'euphoria', 'europe', 'european', 'even', 'events', 'eventually', 'ever', 'every', 'everything', 'exacerbated', 'excesses', 'exchanged', 'existed', 'expanded', 'experimentation', 'exploded', 'exuberant', 'factory', 'failed', 'failings', 'failures', 'fair', 'fall', 'famous', 'fans', 'fantastic', 'far', 'farm', 'farmers', 'fascism', 'fault', 'faulted', 'fear', 'fears', 'feature', 'fellow', 'felt', 'feted', 'few', 'film', 'first', 'fitzgerald', 'five', 'floodgates', 'followed', 'following', 'footage', 'for', 'forever', 'form', 'forms', 'fortunately', 'found', 'france', 'franklin', 'freedom', 'french', 'from', 'fueled', 'function', 'gain', 'galvanic', 'gave', 'general', 'generally', 'generation', 'geopolitical', 'george', 'georges', 'georgia', 'german', 'get', 'give', 'gleaming', 'glean', 'gloom', 'glorious', 'going', 'gone', 'gonna', 'government', 'grainy', 'grammarians', 'grasp', 'great', 'greeted', 'grew', 'grow', 'guises', 'had', 'half', 'hall', 'hand', 'happily', 'harbor', 'harding', 'harlem', 'harsh', 'harvest', 'has', 'hastily', 'have', 'he', 'headed', 'headlines', 'heap', 'heard', 'heavy', 'hellfighters', 'help', 'helped', 'her', 'heroes', 'highway', 'him', 'hint', 'his', 'historians', 'history', 'hit', 'hitler', 'hold', 'hollywood', 'honors', 'hope', 'hoped', 'hoping', 'horizons', 'hottest', 'hour', 'house', 'how', 'huge', 'hundred', 'idea', 'idealism', 'ideas', 'if', 'ii', 'illinois', 'imagination', 'imagined', 'immigrants', 'imperiled', 'important', 'imposed', 'impressive', 'in', 'incapacitated', 'included', 'independence', 'independent', 'influenza', 'ingenious', 'innovating', 'inside', 'inspired', 'intact', 'intelligence', 'internal', 'international', 'interstate', 'into', 'intoned', 'invented', 'invoked', 'ireland', 'is', 'it', 'its', 'jackie', 'james', 'jazz', 'jesus', 'joining', 'joyce', 'july', 'just', 'keep', 'kept', 'killing', 'kind', 'know', 'known', 'lamented', 'large', 'largely', 'largest', 'last', 'late', 'later', 'lazy', 'leaders', 'league', 'lecturer', 'led', 'left', 'leisure', 'length', 'lengths', 'leon', 'less', 'letter', 'life', 'like', 'line', 'lines', 'lionized', 'live', 'lives', 'lofty', 'long', 'longed', 'longest', 'look', 'lovely', 'macaulay', 'machines', 'made', 'majority', 'make', 'manpower', 'many', 'map', 'marching', 'marketing', 'markets', 'mass', 'mat√©riel', 'measure', 'memorable', 'middle', 'midwest', 'miles', 'military', 'millions', 'mind', 'mirrors', 'misreading', 'mitchell', 'mobilize', 'mobsters', 'moderated', 'moment', 'money', 'monopoly', 'month', 'moralistic', 'more', 'most', 'mother', 'motor', 'move', 'moved', 'movements', 'movie', 'moving', 'mr', 'music', 'named', 'nasty', 'nation', 'national', 'nationalism', 'nationalisms', 'nations', 'near', 'nearly', 'need', 'needed', 'negotiators', 'neighbor', 'neighbors', 'neither', 'neologism', 'nevada', 'never', 'new', 'newly', 'newsreels', 'next', 'nineteen', 'no', 'nor', 'normalcy', 'northern', 'not', 'notebook', 'novelty', 'now', 'numbers', 'obliterated', 'obvious', 'occasional', 'oceanic', 'odd', 'of', 'officer', 'often', 'ohio', 'oil', 'old', 'on', 'once', 'one', 'ones', 'only', 'open', 'opinion', 'opposed', 'opposing', 'or', 'order', 'origins', 'other', 'others', 'ottoman', 'out', 'outcome', 'outflank', 'outside', 'over', 'overquoted', 'overseas', 'overwhelmingly', 'overzealous', 'own', 'owner', 'palaces', 'palmer', 'parade', 'parades', 'paralyzed', 'paree', 'paris', 'part', 'parts', 'passage', 'paved', 'peace', 'people', 'perhaps', 'pesky', 'phrase', 'phrases', 'pivotal', 'plan', 'playing', 'pockets', 'poem', 'poems', 'poles', 'police', 'political', 'politically', 'politician', 'popular', 'populated', 'possible', 'postwar', 'poverty', 'powered', 'presidency', 'president', 'presidents', 'prewar', 'problem', 'problems', 'produced', 'production', 'profound', 'prognosticators', 'prohibition', 'promised', 'promises', 'promising', 'promote', 'protect', 'prove', 'publicized', 'publish', 'pursuits', 'push', 'question', 'quick', 'quickly', 'quiet', 'quieter', 'quite', 'quoted', 'race', 'radio', 'raids', 'rakish', 'rallies', 'rascality', 'rascals', 'rate', 'raucously', 'reach', 'realism', 'reality', 'realm', 'reasons', 'received', 'recipe', 'recording', 'red', 'redraw', 'reeled', 'refused', 'regiment', 'released', 'relevant', 'relish', 'remained', 'remembered', 'repeatedly', 'repeating', 'republican', 'research', 'resentment', 'response', 'responsibilities', 'result', 'resulted', 'retain', 'retaliatory', 'return', 'returned', 'revealed', 'rhetoric', 'ride', 'ring', 'ringing', 'rings', 'riot', 'rise', 'road', 'roads', 'robinson', 'roosevelt', 'rowling', 'run', 'rural', 'russia', 'ruth', 'safe', 'sales', 'same', 'saw', 'scorned', 'scott', 'scribbledehobble', 'scrutiny', 'seat', 'second', 'seconded', 'section', 'see', 'seeing', 'seeking', 'seem', 'seemed', 'seen', 'self', 'senator', 'senior', 'sense', 'sent', 'series', 'sermonettes', 'set', 'settling', 'shaped', 'share', 'shimmering', 'shortcomings', 'side', 'sights', 'significant', 'simmered', 'simply', 'since', 'six', 'small', 'so', 'socially', 'solemnity', 'solve', 'some', 'something', 'songs', 'soon', 'sounds', 'south', 'sox', 'speech', 'speeches', 'spent', 'spirited', 'spokesman', 'sports', 'spots', 'sprang', 'spring', 'stars', 'start', 'started', 'state', 'states', 'statue', 'steam', 'still', 'strain', 'stroke', 'struggling', 'studios', 'studying', 'stunning', 'suburban', 'successful', 'such', 'superhuman', 'support', 'sure', 'surely', 'surface', 'surfaces', 'survived', 'swirling', 'system', 'take', 'talking', 'tall', 'tanks', 'targeted', 'team', 'ted', 'tensions', 'terrifying', 'territories', 'test', 'than', 'thanks', 'that', 'the', 'their', 'them', 'then', 'there', 'these', 'they', 'things', 'this', 'those', 'thought', 'thoughts', 'thousands', 'threatened', 'thriving', 'throughout', 'tide', 'time', 'times', 'titled', 'to', 'today', 'too', 'took', 'torn', 'toward', 'towns', 'trace', 'traction', 'traded', 'transformation', 'travel', 'treaty', 'tremendous', 'trend', 'tried', 'trip', 'trotsky', 'true', 'truth', 'trying', 'turned', 'two', 'ugly', 'unbridled', 'undergoing', 'understood', 'unexpected', 'united', 'university', 'unleash', 'until', 'up', 'upon', 'urban', 'use', 'used', 'ushered', 'using', 'utah', 'vaguely', 'vanished', 'various', 've', 'vehicle', 'vehicles', 'versailles', 'versions', 'very', 'victory', 'vigorous', 'villains', 'virtue', 'vividly', 'voice', 'waging', 'wallace', 'waned', 'war', 'warren', 'was', 'washington', 'waves', 'way', 'ways', 'we', 'wealthiest', 'weary', 'welcoming', 'well', 'went', 'were', 'west', 'what', 'when', 'where', 'which', 'while', 'white', 'who', 'whose', 'widmer', 'will', 'william', 'wilson', 'win', 'winds', 'winston', 'with', 'within', 'women', 'woodrow', 'word', 'words', 'work', 'working', 'world', 'worth', 'would', 'writers', 'writing', 'wrong', 'wrote', 'ya', 'yankees', 'year', 'years', 'yeats', 'york', 'young']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdidf_vectorizer = TfidfVectorizer()\n",
    "X = tdidf_vectorizer.fit_transform(text)\n",
    "feature_names_tdidf = tdidf_vectorizer.get_feature_names()\n",
    "print(len(feature_names_tdidf))\n",
    "print(feature_names_tdidf)\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(type_text_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2301"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-261-953c39ab8497>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtdidf_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtdidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfeature_names_tdidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtdidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names_tdidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names_tdidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1839\u001b[0m         \"\"\"\n\u001b[1;32m   1840\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1841\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1842\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1199\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "tdidf_vectorizer = TfidfVectorizer()\n",
    "X = tdidf_vectorizer.fit_transform(corpus)\n",
    "feature_names_tdidf = tdidf_vectorizer.get_feature_names()\n",
    "print(len(feature_names_tdidf))\n",
    "print(feature_names_tdidf)\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
