{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Pipeline \n",
    "\n",
    "![](images/pipeline-walkthrough1.png)\n",
    "\n",
    "Below is a to do list when converting text into vector form: \n",
    "\n",
    "**Clean text and Create a Bag of Words (BoW)**\n",
    ">1. Lowercase the text\n",
    "2. Tokenize \n",
    "3. Strip out punctuation or undesirable text\n",
    "4. Remove Stopwords \n",
    "5. Stemming or Lemmatizing\n",
    "6. Compute N-Grams\n",
    "7. Use this to create BoW\n",
    "\n",
    "**Vectorize BoW**\n",
    ">8. Term Frequencies\n",
    "9. Document Frequencies\n",
    "10. TF-IDF\n",
    "11. Normalize vectors\n",
    "\n",
    "Let's go through both what each of these steps are and how to do them in python with the following corpus of comments about data science...\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion to cut off extra intro paragraphs from beautiful soup scrape\n",
    "\n",
    "# def trim_fat(string):\n",
    "#     return string[35:-115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to vectorize the type_of_material series into a y target vector.\n",
    "def vectorize_type(ser):\n",
    "    y = ser.copy()\n",
    "    y.replace({'Op-Ed': 1,'News': 0}, inplace=True)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rate of correct predictions out of total predictions\n",
    "def metrics_(tn, fp, fn, tp):\n",
    "    accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "    print(f'accuracy = {accuracy}')\n",
    "    recall = (tp) / (tp + fn)\n",
    "    print(f'recall = {recall}')\n",
    "    precision = (tp) / (tp + fp)\n",
    "    print(f'precision = {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.56 s, sys: 268 ms, total: 1.83 s\n",
      "Wall time: 1.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_2019 = pd.read_csv('data/trim2019_text_type.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 831 µs, sys: 177 µs, total: 1.01 ms\n",
      "Wall time: 995 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_2019_df = _2019.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X. X is currently pandas series of unsplit strings\n",
    "\n",
    "X = _2019_df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define y as a series of op-ed or news\n",
    "\n",
    "y = _2019_df.type_of_material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.9 ms, sys: 2.44 ms, total: 15.4 ms\n",
      "Wall time: 14.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# vectorize y in to (1, 0) (op-ed, news)\n",
    "\n",
    "y = vectorize_type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn series into list...\n",
    "\n",
    "corpus = list(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn TfidfVectorizer(stop_words='english', strip_accents='ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.9 s, sys: 457 ms, total: 25.4 s\n",
      "Wall time: 25.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#create vectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(#input='content', \n",
    "#                 encoding='utf-8', \n",
    "#                 decode_error='strict', \n",
    "                 strip_accents=None, \n",
    "                 lowercase=True, \n",
    "#                 preprocessor=None, \n",
    "#                 tokenizer=None, \n",
    "#                 analyzer='word', \n",
    "                 stop_words='english', \n",
    "#                 token_pattern='(?u)\\b\\w\\w+\\b', \n",
    "#                 ngram_range=(1, 1), \n",
    "#                 max_df=1.0, \n",
    "#                 min_df=1, \n",
    "                 max_features=None, \n",
    "#                 vocabulary=None, \n",
    "#                 binary=False, \n",
    "#                 dtype=<class 'numpy.float64'>, \n",
    "#                 norm='l2', \n",
    "#                 use_idf=True, \n",
    "#                 smooth_idf=True, \n",
    "#                 sublinear_tf=False\n",
    ")\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 176 ms, sys: 3.7 ms, total: 180 ms\n",
      "Wall time: 179 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 1e+03 ns, total: 8 µs\n",
      "Wall time: 9.06 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stop_words = vectorizer.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215840"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resample class size w/ imbalanced learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41748,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41748, 215840)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43 µs, sys: 14 µs, total: 57 µs\n",
      "Wall time: 201 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#balance the classes\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 4139), (1, 4139)]\n",
      "CPU times: user 28.6 ms, sys: 10.9 ms, total: 39.5 ms\n",
      "Wall time: 38.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#X, y --> X_resampled, y_resampled\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "\n",
    "#return a list of tuples for item, and count of item. in this case 4139 each\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8278,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8278, 215840)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 ms, sys: 10.2 ms, total: 22.7 ms\n",
      "Wall time: 22 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#test, train, split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes/imbalanced learn/TFIDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# multinm_clf = MultinomialNB()\n",
    "# multinm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multinm_clf.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = multinm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #clf.score = accuracy = 'true'(pos/neg) / total\n",
    "\n",
    "# multinm_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix(y_true = y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tn, fp, fn, tp = confusion_matrix(y_true = y_test, y_pred = y_pred).ravel()\n",
    "# (tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "\n",
    "# accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # rate of actual op-ed articles, out of all the actual od-ed articles\n",
    "\n",
    "# recall = (tp) / (tp + fn)\n",
    "# recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rate of correct predictions of op-ed articles out of all predictions\n",
    "\n",
    "# precision = (tp) / (tp + fp)\n",
    "# precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "\n",
    "# accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "# print(f'accuracy = {accuracy}')\n",
    "# recall = (tp) / (tp + fn)\n",
    "# print(f'recall = {recall}')\n",
    "# precision = (tp) / (tp + fp)\n",
    "# print(f'precision = {precision}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class sklearn.ensemble.RandomForestClassifier(n_estimators=100, \n",
    "#                                               *, \n",
    "#                                               criterion='gini', \n",
    "#                                               max_depth=None, \n",
    "#                                               min_samples_split=2, \n",
    "#                                               min_samples_leaf=1, \n",
    "#                                               min_weight_fraction_leaf=0.0, \n",
    "#                                               max_features='auto', \n",
    "#                                               max_leaf_nodes=None, \n",
    "#                                               min_impurity_decrease=0.0, \n",
    "#                                               min_impurity_split=None, \n",
    "#                                               bootstrap=True, \n",
    "#                                               oob_score=False, \n",
    "#                                               n_jobs=None, \n",
    "#                                               random_state=None, \n",
    "#                                               verbose=0, \n",
    "#                                               warm_start=False, \n",
    "#                                               class_weight=None, \n",
    "#                                               ccp_alpha=0.0, \n",
    "#                                               max_samples=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43 µs, sys: 0 ns, total: 43 µs\n",
      "Wall time: 46 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_clf = RandomForestClassifier(max_depth=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 372 ms, sys: 30.2 ms, total: 402 ms\n",
      "Wall time: 402 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9415458937198068"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf.score = accuracy = 'true'(pos/neg) / total\n",
    "\n",
    "rf_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1003,   17],\n",
       "       [ 104,  946]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true = y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1003, 17, 104, 946)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true = y_test, y_pred = y_pred).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "\n",
    "# accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rate of actual op-ed articles, out of all the actual od-ed articles\n",
    "\n",
    "# recall = (tp) / (tp + fn)\n",
    "# recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rate of correct predictions of op-ed articles out of all predictions\n",
    "\n",
    "# precision = (tp) / (tp + fp)\n",
    "# precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9415458937198068\n",
      "recall = 0.900952380952381\n",
      "precision = 0.9823468328141225\n"
     ]
    }
   ],
   "source": [
    "#rate of correct predictions out of total predictions\n",
    "\n",
    "accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "print(f'accuracy = {accuracy}')\n",
    "recall = (tp) / (tp + fn)\n",
    "print(f'recall = {recall}')\n",
    "precision = (tp) / (tp + fp)\n",
    "print(f'precision = {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class sklearn.ensemble.RandomForestClassifier(n_estimators=100, \n",
    "#                                               *, \n",
    "#                                               criterion='gini', \n",
    "#                                               max_depth=None, \n",
    "#                                               min_samples_split=2, \n",
    "#                                               min_samples_leaf=1, \n",
    "#                                               min_weight_fraction_leaf=0.0, \n",
    "#                                               max_features='auto', \n",
    "#                                               max_leaf_nodes=None, \n",
    "#                                               min_impurity_decrease=0.0, \n",
    "#                                               min_impurity_split=None, \n",
    "#                                               bootstrap=True, \n",
    "#                                               oob_score=False, \n",
    "#                                               n_jobs=None, \n",
    "#                                               random_state=None, \n",
    "#                                               verbose=0, \n",
    "#                                               warm_start=False, \n",
    "#                                               class_weight=None, \n",
    "#                                               ccp_alpha=0.0, \n",
    "#                                               max_samples=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what is this random forest doing?\n",
    "1. takes all X and y which is my text and classifiers as vectors(tfidf)\n",
    "2. take a random number of 8278 instances (tfidf vector) and uses a random number of 219112 features to make best decision.\n",
    "3. bags/bootstraps that model\n",
    "4. does it again a bunch of times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accuracy, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "# def metrics_(tn, fp, fn, tp):\n",
    "#     accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "#     print(f'accuracy = {accuracy}')\n",
    "#     recall = (tp) / (tp + fn)\n",
    "#     print(f'recall = {recall}')\n",
    "#     precision = (tp) / (tp + fp)\n",
    "#     print(f'precision = {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics_(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bag of words\n",
    "# get sparse matrix\n",
    "# overlay bag of words onto sparce matrix\n",
    "# argsort to find most important (highest number) word that it's splitting w/ most infomation gain/ least entroy... whatever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215840"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000',\n",
       " '0000001',\n",
       " '000001',\n",
       " '0000044',\n",
       " '00001',\n",
       " '0000797113',\n",
       " '0001',\n",
       " '0002',\n",
       " '00025',\n",
       " '0003',\n",
       " '0004',\n",
       " '0005',\n",
       " '0008',\n",
       " '000ers',\n",
       " '000s',\n",
       " '000th',\n",
       " '001',\n",
       " '0010',\n",
       " '0012',\n",
       " '0014',\n",
       " '0017',\n",
       " '001st',\n",
       " '002',\n",
       " '0020',\n",
       " '0025',\n",
       " '0026',\n",
       " '0028',\n",
       " '003',\n",
       " '0033',\n",
       " '0039',\n",
       " '004',\n",
       " '0042',\n",
       " '0046',\n",
       " '005',\n",
       " '0051',\n",
       " '006',\n",
       " '0064',\n",
       " '0065',\n",
       " '0069',\n",
       " '007',\n",
       " '0077',\n",
       " '007s',\n",
       " '008',\n",
       " '0083',\n",
       " '0086',\n",
       " '009',\n",
       " '00s',\n",
       " '01',\n",
       " '010',\n",
       " '0100',\n",
       " '0102',\n",
       " '011',\n",
       " '0115',\n",
       " '0116',\n",
       " '012',\n",
       " '013',\n",
       " '0139',\n",
       " '014',\n",
       " '015',\n",
       " '0150',\n",
       " '0153',\n",
       " '016',\n",
       " '0160',\n",
       " '017',\n",
       " '018',\n",
       " '0180',\n",
       " '0186',\n",
       " '019',\n",
       " '01am',\n",
       " '01kylb8mda',\n",
       " '02',\n",
       " '020',\n",
       " '0200',\n",
       " '0202',\n",
       " '0203',\n",
       " '021',\n",
       " '0211',\n",
       " '0216',\n",
       " '021672',\n",
       " '022',\n",
       " '0221',\n",
       " '0222',\n",
       " '023',\n",
       " '0230',\n",
       " '0236',\n",
       " '024',\n",
       " '0248',\n",
       " '025',\n",
       " '0251',\n",
       " '0255',\n",
       " '026',\n",
       " '027',\n",
       " '0271',\n",
       " '0277',\n",
       " '028',\n",
       " '0280',\n",
       " '029',\n",
       " '0292',\n",
       " '0299',\n",
       " '03',\n",
       " '030',\n",
       " '0302',\n",
       " '0303',\n",
       " '031',\n",
       " '031019',\n",
       " '0312',\n",
       " '0313',\n",
       " '0318',\n",
       " '032',\n",
       " '032c',\n",
       " '033',\n",
       " '0332',\n",
       " '0336',\n",
       " '0339',\n",
       " '034',\n",
       " '0347',\n",
       " '035',\n",
       " '0350',\n",
       " '0351',\n",
       " '0358',\n",
       " '036',\n",
       " '0366',\n",
       " '0368',\n",
       " '037',\n",
       " '0371',\n",
       " '0376',\n",
       " '038',\n",
       " '039',\n",
       " '0392',\n",
       " '04',\n",
       " '040',\n",
       " '0400',\n",
       " '0400hrs',\n",
       " '0401',\n",
       " '041',\n",
       " '042',\n",
       " '043',\n",
       " '0438',\n",
       " '044',\n",
       " '0444',\n",
       " '0447',\n",
       " '045',\n",
       " '0455',\n",
       " '046',\n",
       " '0468',\n",
       " '047',\n",
       " '0471',\n",
       " '0474',\n",
       " '0476',\n",
       " '0478',\n",
       " '048',\n",
       " '0484',\n",
       " '049',\n",
       " '04cf139',\n",
       " '05',\n",
       " '050',\n",
       " '0500',\n",
       " '0505',\n",
       " '051',\n",
       " '0510',\n",
       " '0516',\n",
       " '0518',\n",
       " '052',\n",
       " '053',\n",
       " '0531',\n",
       " '054',\n",
       " '0545',\n",
       " '0547',\n",
       " '055',\n",
       " '0555',\n",
       " '0557',\n",
       " '056',\n",
       " '0565',\n",
       " '0566',\n",
       " '0567',\n",
       " '057',\n",
       " '0570',\n",
       " '0576',\n",
       " '058',\n",
       " '059',\n",
       " '0591',\n",
       " '06',\n",
       " '060',\n",
       " '0600',\n",
       " '0607',\n",
       " '061',\n",
       " '0612',\n",
       " '0614',\n",
       " '062',\n",
       " '0620',\n",
       " '0622',\n",
       " '063',\n",
       " '0633',\n",
       " '0637',\n",
       " '064',\n",
       " '0640',\n",
       " '06413',\n",
       " '065',\n",
       " '066',\n",
       " '0666',\n",
       " '067',\n",
       " '0670',\n",
       " '0675',\n",
       " '068',\n",
       " '0686',\n",
       " '0688',\n",
       " '069',\n",
       " '0690',\n",
       " '07',\n",
       " '070',\n",
       " '0700',\n",
       " '0707',\n",
       " '070th',\n",
       " '071',\n",
       " '0711',\n",
       " '072',\n",
       " '0722',\n",
       " '072419',\n",
       " '073',\n",
       " '0730',\n",
       " '0731',\n",
       " '0736',\n",
       " '074',\n",
       " '0742',\n",
       " '0745',\n",
       " '075',\n",
       " '076',\n",
       " '077',\n",
       " '078',\n",
       " '07853',\n",
       " '0789',\n",
       " '079',\n",
       " '08',\n",
       " '080',\n",
       " '0800',\n",
       " '0804',\n",
       " '0808',\n",
       " '081',\n",
       " '0810',\n",
       " '08157',\n",
       " '0818',\n",
       " '082',\n",
       " '0820',\n",
       " '082519',\n",
       " '083',\n",
       " '0837',\n",
       " '084',\n",
       " '0845',\n",
       " '085',\n",
       " '0850',\n",
       " '0859',\n",
       " '086',\n",
       " '0864',\n",
       " '0866',\n",
       " '087',\n",
       " '0870',\n",
       " '088',\n",
       " '0886',\n",
       " '089',\n",
       " '0897',\n",
       " '09',\n",
       " '090',\n",
       " '0900',\n",
       " '0902',\n",
       " '0906',\n",
       " '091',\n",
       " '0910',\n",
       " '091819',\n",
       " '092',\n",
       " '093',\n",
       " '0934',\n",
       " '094',\n",
       " '0947',\n",
       " '095',\n",
       " '0951',\n",
       " '0954',\n",
       " '096',\n",
       " '0967',\n",
       " '097',\n",
       " '0974',\n",
       " '098',\n",
       " '0986',\n",
       " '098th',\n",
       " '099',\n",
       " '0992',\n",
       " '099364',\n",
       " '0998',\n",
       " '09er',\n",
       " '09ers',\n",
       " '0b',\n",
       " '0cyu4ixn0e',\n",
       " '0dpa3ljzps',\n",
       " '0lb',\n",
       " '0n',\n",
       " '0ol',\n",
       " '0ro5ztjjkk',\n",
       " '0s',\n",
       " '0ug2jg558e',\n",
       " '0xl9s7w8v2',\n",
       " '0xu0b7dcvd',\n",
       " '0yqjaoxuk1',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '100000',\n",
       " '1000bulbs',\n",
       " '1000s',\n",
       " '1001',\n",
       " '10018',\n",
       " '1002',\n",
       " '1003',\n",
       " '1005',\n",
       " '1006',\n",
       " '1008',\n",
       " '10087',\n",
       " '100a',\n",
       " '100b',\n",
       " '100c',\n",
       " '100d',\n",
       " '100k',\n",
       " '100ml',\n",
       " '100postcards',\n",
       " '100pre',\n",
       " '100projects',\n",
       " '100s',\n",
       " '100th',\n",
       " '100x',\n",
       " '100⅓',\n",
       " '101',\n",
       " '1010',\n",
       " '10100',\n",
       " '1010oct',\n",
       " '1011',\n",
       " '101145',\n",
       " '1014',\n",
       " '1015',\n",
       " '10151nerivenwoodln',\n",
       " '1017',\n",
       " '1018',\n",
       " '101801',\n",
       " '1019',\n",
       " '101a',\n",
       " '101st',\n",
       " '102',\n",
       " '1020',\n",
       " '1023',\n",
       " '1024th',\n",
       " '1026',\n",
       " '1027',\n",
       " '1028',\n",
       " '1029',\n",
       " '102a',\n",
       " '102d',\n",
       " '102nd',\n",
       " '103',\n",
       " '1030',\n",
       " '1031',\n",
       " '1032',\n",
       " '1033',\n",
       " '1036',\n",
       " '1038',\n",
       " '103a',\n",
       " '103d',\n",
       " '103rd',\n",
       " '104',\n",
       " '1040',\n",
       " '1041',\n",
       " '1043',\n",
       " '10432',\n",
       " '10450',\n",
       " '1047',\n",
       " '1048',\n",
       " '104a',\n",
       " '104d',\n",
       " '104th',\n",
       " '104½',\n",
       " '105',\n",
       " '1050',\n",
       " '1051',\n",
       " '1052',\n",
       " '1054',\n",
       " '1055',\n",
       " '1059',\n",
       " '105a',\n",
       " '105d',\n",
       " '105th',\n",
       " '106',\n",
       " '1062',\n",
       " '1063',\n",
       " '1066',\n",
       " '1067',\n",
       " '106a',\n",
       " '106d',\n",
       " '106th',\n",
       " '107',\n",
       " '1070',\n",
       " '1071',\n",
       " '10785',\n",
       " '107a',\n",
       " '107d',\n",
       " '107th',\n",
       " '108',\n",
       " '1080',\n",
       " '1080p',\n",
       " '1087',\n",
       " '1088',\n",
       " '1089',\n",
       " '108a',\n",
       " '108th',\n",
       " '109',\n",
       " '1090',\n",
       " '1091',\n",
       " '1092',\n",
       " '1093',\n",
       " '1095',\n",
       " '1096',\n",
       " '1098',\n",
       " '1099',\n",
       " '1099s',\n",
       " '109a',\n",
       " '109d',\n",
       " '109s',\n",
       " '109th',\n",
       " '10a',\n",
       " '10b',\n",
       " '10cc',\n",
       " '10d',\n",
       " '10f',\n",
       " '10k',\n",
       " '10ks',\n",
       " '10min',\n",
       " '10news',\n",
       " '10purplegate',\n",
       " '10s',\n",
       " '10th',\n",
       " '10ths',\n",
       " '10x',\n",
       " '10yearchallenge',\n",
       " '10¹²',\n",
       " '10½',\n",
       " '10⅔',\n",
       " '10⅛',\n",
       " '10⅝',\n",
       " '11',\n",
       " '110',\n",
       " '1100',\n",
       " '110101',\n",
       " '1103',\n",
       " '1104',\n",
       " '1105',\n",
       " '1107',\n",
       " '1109',\n",
       " '110a',\n",
       " '110th',\n",
       " '111',\n",
       " '1111',\n",
       " '1112',\n",
       " '1113',\n",
       " '1114',\n",
       " '111447',\n",
       " '11150',\n",
       " '1116',\n",
       " '1118',\n",
       " '1119',\n",
       " '111d',\n",
       " '111th',\n",
       " '112',\n",
       " '1122',\n",
       " '1123',\n",
       " '1125',\n",
       " '1126',\n",
       " '1127',\n",
       " '1128',\n",
       " '1129',\n",
       " '112a',\n",
       " '112d',\n",
       " '112s',\n",
       " '112th',\n",
       " '113',\n",
       " '1130',\n",
       " '1131',\n",
       " '1132',\n",
       " '1133',\n",
       " '1135',\n",
       " '1136',\n",
       " '1137',\n",
       " '1138',\n",
       " '113a',\n",
       " '113th',\n",
       " '114',\n",
       " '1140',\n",
       " '11405',\n",
       " '1149th',\n",
       " '114a',\n",
       " '114th',\n",
       " '115',\n",
       " '1150',\n",
       " '1154',\n",
       " '1155',\n",
       " '1158',\n",
       " '115a',\n",
       " '115th',\n",
       " '116',\n",
       " '1162',\n",
       " '1163',\n",
       " '116508',\n",
       " '116508s',\n",
       " '1167',\n",
       " '1168',\n",
       " '116a',\n",
       " '116th',\n",
       " '117',\n",
       " '1171',\n",
       " '1172',\n",
       " '1174',\n",
       " '1177',\n",
       " '1178',\n",
       " '117a',\n",
       " '117d',\n",
       " '117th',\n",
       " '118',\n",
       " '1185',\n",
       " '1189',\n",
       " '118a',\n",
       " '118b',\n",
       " '118s',\n",
       " '118th',\n",
       " '119',\n",
       " '1191',\n",
       " '1195',\n",
       " '1196',\n",
       " '1199',\n",
       " '1199seiu',\n",
       " '119a',\n",
       " '119th',\n",
       " '11a',\n",
       " '11c',\n",
       " '11d',\n",
       " '11ish',\n",
       " '11pm',\n",
       " '11s',\n",
       " '11starts',\n",
       " '11th',\n",
       " '11½',\n",
       " '11⅓',\n",
       " '11⅝',\n",
       " '12',\n",
       " '120',\n",
       " '1200',\n",
       " '1200s',\n",
       " '1201',\n",
       " '1202',\n",
       " '1204',\n",
       " '1207',\n",
       " '1208',\n",
       " '1209',\n",
       " '120a',\n",
       " '120th',\n",
       " '121',\n",
       " '1210',\n",
       " '1211',\n",
       " '1212',\n",
       " '1213',\n",
       " '1215',\n",
       " '1216',\n",
       " '121a',\n",
       " '121st',\n",
       " '122',\n",
       " '1220',\n",
       " '1220cabrillo',\n",
       " '1221',\n",
       " '1222',\n",
       " '1223',\n",
       " '1225',\n",
       " '1228',\n",
       " '122a',\n",
       " '122nd',\n",
       " '123',\n",
       " '1230',\n",
       " '1231',\n",
       " '1233',\n",
       " '1234',\n",
       " '1235',\n",
       " '1238',\n",
       " '1239',\n",
       " '123a',\n",
       " '123andres',\n",
       " '123m',\n",
       " '123rd',\n",
       " '124',\n",
       " '1240',\n",
       " '1242',\n",
       " '1244',\n",
       " '1245',\n",
       " '124d',\n",
       " '124th',\n",
       " '124v124',\n",
       " '125',\n",
       " '1250',\n",
       " '1250w',\n",
       " '1252',\n",
       " '125349',\n",
       " '12538',\n",
       " '1254',\n",
       " '1255',\n",
       " '1258',\n",
       " '125a',\n",
       " '125th',\n",
       " '126',\n",
       " '1260',\n",
       " '1264',\n",
       " '1265',\n",
       " '126a',\n",
       " '126th',\n",
       " '127',\n",
       " '1270',\n",
       " '1271',\n",
       " '1272',\n",
       " '1275',\n",
       " '127th',\n",
       " '128',\n",
       " '1280',\n",
       " '1281',\n",
       " '1282',\n",
       " '1283',\n",
       " '1284',\n",
       " '1285',\n",
       " '1286',\n",
       " '128a',\n",
       " '128th',\n",
       " '129',\n",
       " '1290',\n",
       " '1295',\n",
       " '1297',\n",
       " '1298',\n",
       " '1299',\n",
       " '129a',\n",
       " '129th',\n",
       " '129⅔',\n",
       " '12a',\n",
       " '12d',\n",
       " '12e',\n",
       " '12f',\n",
       " '12ish',\n",
       " '12s',\n",
       " '12th',\n",
       " '12½',\n",
       " '12⅓',\n",
       " '13',\n",
       " '130',\n",
       " '1300',\n",
       " '1300s',\n",
       " '1302',\n",
       " '1306',\n",
       " '1308',\n",
       " '130a',\n",
       " '130j',\n",
       " '130th',\n",
       " '131',\n",
       " '1310',\n",
       " '1311',\n",
       " '1313',\n",
       " '1314',\n",
       " '1316',\n",
       " '1317',\n",
       " '131st',\n",
       " '132',\n",
       " '1320',\n",
       " '1320s',\n",
       " '1322',\n",
       " '1323',\n",
       " '1325',\n",
       " '1326',\n",
       " '1327',\n",
       " '1329',\n",
       " '132a',\n",
       " '132nd',\n",
       " '133',\n",
       " '1330',\n",
       " '1332',\n",
       " '1333',\n",
       " '1334',\n",
       " '1336',\n",
       " '133rd',\n",
       " '134',\n",
       " '1344',\n",
       " '1345',\n",
       " '1347',\n",
       " '1348',\n",
       " '134th',\n",
       " '135',\n",
       " '1350',\n",
       " '1351',\n",
       " '1352',\n",
       " '13535',\n",
       " '135k',\n",
       " '135th',\n",
       " '136',\n",
       " '1361',\n",
       " '1362',\n",
       " '1363',\n",
       " '1367',\n",
       " '1368',\n",
       " '136th',\n",
       " '137',\n",
       " '1375',\n",
       " '13768',\n",
       " '1377',\n",
       " '1378',\n",
       " '137th',\n",
       " '138',\n",
       " '1380',\n",
       " '1384',\n",
       " '1387',\n",
       " '1389',\n",
       " '138th',\n",
       " '139',\n",
       " '1390',\n",
       " '1394',\n",
       " '1395',\n",
       " '1399',\n",
       " '139th',\n",
       " '13a',\n",
       " '13d',\n",
       " '13s',\n",
       " '13th',\n",
       " '13½',\n",
       " '13¾',\n",
       " '14',\n",
       " '140',\n",
       " '1400',\n",
       " '1400s',\n",
       " '1401',\n",
       " '1405',\n",
       " '1407',\n",
       " '1408',\n",
       " '140s',\n",
       " '140th',\n",
       " '141',\n",
       " '1410',\n",
       " '1413',\n",
       " '1415',\n",
       " '1415926',\n",
       " '141592653589793238462643383279502',\n",
       " '1415927',\n",
       " '141st',\n",
       " '142',\n",
       " '1420',\n",
       " '1421',\n",
       " '1422',\n",
       " '1429',\n",
       " '142nd',\n",
       " '143',\n",
       " '1430',\n",
       " '1431',\n",
       " '1432',\n",
       " '14351',\n",
       " '1439',\n",
       " '143rd',\n",
       " '144',\n",
       " '1440',\n",
       " '1440p',\n",
       " '1440s',\n",
       " '1441',\n",
       " '1444',\n",
       " '1445',\n",
       " '1448',\n",
       " '144th',\n",
       " '145',\n",
       " '1450',\n",
       " '1451',\n",
       " '1452',\n",
       " '1453',\n",
       " '1455',\n",
       " '1458',\n",
       " '145th',\n",
       " '146',\n",
       " '1460',\n",
       " '1460s',\n",
       " '1465',\n",
       " '146th',\n",
       " '147',\n",
       " '1470',\n",
       " '1470s',\n",
       " '1473',\n",
       " '1475',\n",
       " '1476',\n",
       " '1477',\n",
       " '1478',\n",
       " '147th',\n",
       " '148',\n",
       " '1480',\n",
       " '1481',\n",
       " '1482',\n",
       " '1483',\n",
       " '1484',\n",
       " '1486',\n",
       " '1487',\n",
       " '1488',\n",
       " '1488s',\n",
       " '148th',\n",
       " '149',\n",
       " '1490',\n",
       " '1491',\n",
       " '1492',\n",
       " '1493',\n",
       " '1495',\n",
       " '1498',\n",
       " '1499',\n",
       " '149th',\n",
       " '14a',\n",
       " '14b',\n",
       " '14d',\n",
       " '14e',\n",
       " '14k',\n",
       " '14kxbv4jjw',\n",
       " '14peaks7months',\n",
       " '14streety',\n",
       " '14th',\n",
       " '14w',\n",
       " '14x15',\n",
       " '14x16',\n",
       " '14ymedio',\n",
       " '14½',\n",
       " '14⅔',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '1500s',\n",
       " '1503',\n",
       " '1504',\n",
       " '1505',\n",
       " '1506',\n",
       " '1507',\n",
       " '1508',\n",
       " '1509',\n",
       " '150k',\n",
       " '150s',\n",
       " '150th',\n",
       " '151',\n",
       " '1510',\n",
       " '1512',\n",
       " '1513',\n",
       " '1514',\n",
       " '1515',\n",
       " '1516',\n",
       " '1518',\n",
       " '1519',\n",
       " '151st',\n",
       " '152',\n",
       " '1520',\n",
       " '1521',\n",
       " '1522',\n",
       " '1523',\n",
       " '1524',\n",
       " '1526',\n",
       " '1528',\n",
       " '152nd',\n",
       " '153',\n",
       " '1530',\n",
       " '1532',\n",
       " '1533',\n",
       " '1534',\n",
       " '1535',\n",
       " '1539',\n",
       " '153news',\n",
       " '153rd',\n",
       " '154',\n",
       " '1540',\n",
       " '1540s',\n",
       " '1542',\n",
       " '1543',\n",
       " '1545',\n",
       " '1546',\n",
       " '1547',\n",
       " '1548',\n",
       " '1549',\n",
       " '154th',\n",
       " '154⅓',\n",
       " '155',\n",
       " '1550',\n",
       " '1550s',\n",
       " '1551',\n",
       " '1552',\n",
       " '1553',\n",
       " '1555',\n",
       " '1556',\n",
       " '1557',\n",
       " '1558',\n",
       " '1559',\n",
       " '155th',\n",
       " '156',\n",
       " '1560',\n",
       " '1561',\n",
       " '1562',\n",
       " '1563',\n",
       " '1564',\n",
       " '156411',\n",
       " '1566',\n",
       " '1567',\n",
       " '1568',\n",
       " '156r',\n",
       " '156th',\n",
       " '157',\n",
       " '1570',\n",
       " '1570jonive',\n",
       " '1571',\n",
       " '1572',\n",
       " '1573',\n",
       " '1574',\n",
       " '1575',\n",
       " '1576',\n",
       " '1577',\n",
       " '1578',\n",
       " '1579',\n",
       " '157th',\n",
       " '158',\n",
       " '1580',\n",
       " '1580s',\n",
       " '1582',\n",
       " '1583',\n",
       " '1586',\n",
       " '1587',\n",
       " '159',\n",
       " '1590',\n",
       " '1591',\n",
       " '1593',\n",
       " '1594',\n",
       " '1595',\n",
       " '1596',\n",
       " '1597',\n",
       " '1598',\n",
       " '1599',\n",
       " '15a',\n",
       " '15andfairness',\n",
       " '15b',\n",
       " '15c',\n",
       " '15d',\n",
       " '15e',\n",
       " '15es',\n",
       " '15k',\n",
       " '15ls',\n",
       " '15s',\n",
       " '15th',\n",
       " '15x',\n",
       " '15x14',\n",
       " '15x15',\n",
       " '15x16',\n",
       " '15xs',\n",
       " '15½',\n",
       " '16',\n",
       " '160',\n",
       " '1600',\n",
       " '1600s',\n",
       " '1601',\n",
       " '1602',\n",
       " '1603',\n",
       " '1604',\n",
       " '1605',\n",
       " '1606',\n",
       " '1607',\n",
       " '1608',\n",
       " '1609',\n",
       " '160th',\n",
       " '160⅓',\n",
       " '161',\n",
       " '1610',\n",
       " '1611',\n",
       " '1612',\n",
       " '1613',\n",
       " '1614',\n",
       " '1615',\n",
       " '1616',\n",
       " '1617',\n",
       " '1618',\n",
       " '1619',\n",
       " '1619podcast',\n",
       " '161st',\n",
       " '162',\n",
       " '1620',\n",
       " '1621',\n",
       " '1622',\n",
       " '1623',\n",
       " '1624',\n",
       " '1625',\n",
       " '1626',\n",
       " '1627',\n",
       " '1628',\n",
       " '1629',\n",
       " '162nd',\n",
       " '163',\n",
       " '1630',\n",
       " '1630s',\n",
       " '1631',\n",
       " '1632',\n",
       " '1633',\n",
       " '1634',\n",
       " '1635',\n",
       " ...]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer(*, \n",
    "#                 input='content', \n",
    "#                 encoding='utf-8', \n",
    "#                 decode_error='strict', \n",
    "#                 strip_accents=None, \n",
    "#                 lowercase=Truelowercase=True \n",
    "#                 preprocessor=None, \n",
    "#                 tokenizer=None, \n",
    "#                 analyzer='word', \n",
    "#                 stop_words=None, \n",
    "#                 token_pattern='(?u)\\b\\w\\w+\\b', \n",
    "#                 ngram_range=(1, 1), \n",
    "#                 max_df=1.0, \n",
    "#                 min_df=1, \n",
    "#                 max_features=None, \n",
    "#                 vocabulary=None, \n",
    "#                 binary=False, \n",
    "#                 dtype=<class 'numpy.float64'>, \n",
    "#                 norm='l2', \n",
    "#                 use_idf=True, \n",
    "#                 smooth_idf=True, \n",
    "#                 sublinear_tf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_2019_df = _2019.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X. X is currently pandas series of unsplit strings\n",
    "\n",
    "X_nltk = nltk_2019_df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define y as a series of op-ed or news\n",
    "\n",
    "y_nktk = nltk_2019_df.type_of_material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.9 ms, sys: 3.32 ms, total: 16.2 ms\n",
      "Wall time: 15 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# vectorize y in to (1, 0) (op-ed, news)\n",
    "\n",
    "y = vectorize_type(y_nktk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn series into list...\n",
    "\n",
    "corpus_nltk = list(X_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenize w/ nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tokenized = [word_tokenize(article.lower()) for article in corpus_nltk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
