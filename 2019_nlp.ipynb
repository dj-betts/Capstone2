{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Pipeline \n",
    "\n",
    "![](images/pipeline-walkthrough1.png)\n",
    "\n",
    "Below is a to do list when converting text into vector form: \n",
    "\n",
    "**Clean text and Create a Bag of Words (BoW)**\n",
    ">1. Lowercase the text\n",
    "2. Tokenize \n",
    "3. Strip out punctuation or undesirable text\n",
    "4. Remove Stopwords \n",
    "5. Stemming or Lemmatizing\n",
    "6. Compute N-Grams\n",
    "7. Use this to create BoW\n",
    "\n",
    "**Vectorize BoW**\n",
    ">8. Term Frequencies\n",
    "9. Document Frequencies\n",
    "10. TF-IDF\n",
    "11. Normalize vectors\n",
    "\n",
    "Let's go through both what each of these steps are and how to do them in python with the following corpus of comments about data science...\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion to cut off extra intro paragraphs from beautiful soup scrape\n",
    "\n",
    "# def trim_fat(string):\n",
    "#     return string[35:-115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to vectorize the type_of_material series into a y target vector.\n",
    "def vectorize_type(ser):\n",
    "    y = ser.copy()\n",
    "    y.replace({'Op-Ed': 1,'News': 0}, inplace=True)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rate of correct predictions out of total predictions\n",
    "def metrics_(tn, fp, fn, tp):\n",
    "    accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "    print(f'accuracy = {accuracy}')\n",
    "    recall = (tp) / (tp + fn)\n",
    "    print(f'recall = {recall}')\n",
    "    precision = (tp) / (tp + fp)\n",
    "    print(f'precision = {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.51 s, sys: 254 ms, total: 1.77 s\n",
      "Wall time: 1.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_2019 = pd.read_csv('data/trim2019_text_type.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 749 µs, sys: 171 µs, total: 920 µs\n",
      "Wall time: 920 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_2019_df = _2019.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X. X is currently pandas series of unsplit strings\n",
    "\n",
    "X = _2019_df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define y as a series of op-ed or news\n",
    "\n",
    "y = _2019_df.type_of_material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.6 ms, sys: 1.95 ms, total: 13.5 ms\n",
      "Wall time: 12.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# vectorize y in to (1, 0) (op-ed, news)\n",
    "\n",
    "y = vectorize_type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn series into list...\n",
    "\n",
    "corpus = list(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn TfidfVectorizer(stop_words='english', strip_accents='ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25 s, sys: 472 ms, total: 25.4 s\n",
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#create vectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(#input='content', \n",
    "#                 encoding='utf-8', \n",
    "#                 decode_error='strict', \n",
    "                 strip_accents=None, \n",
    "                 lowercase=True, \n",
    "#                 preprocessor=None, \n",
    "#                 tokenizer=None, \n",
    "#                 analyzer='word', \n",
    "                 stop_words='english', \n",
    "#                 token_pattern='(?u)\\b\\w\\w+\\b', \n",
    "#                 ngram_range=(1, 1), \n",
    "#                 max_df=1.0, \n",
    "#                 min_df=1, \n",
    "                 max_features=None, \n",
    "#                 vocabulary=None, \n",
    "#                 binary=False, \n",
    "#                 dtype=<class 'numpy.float64'>, \n",
    "#                 norm='l2', \n",
    "#                 use_idf=True, \n",
    "#                 smooth_idf=True, \n",
    "#                 sublinear_tf=False\n",
    ")\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 176 ms, sys: 2.95 ms, total: 179 ms\n",
      "Wall time: 178 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stop_words = vectorizer.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215840"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resample class size w/ imbalanced learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41748,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41748, 215840)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 µs, sys: 1e+03 ns, total: 24 µs\n",
      "Wall time: 26 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#balance the classes\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 4139), (1, 4139)]\n",
      "CPU times: user 28.2 ms, sys: 11 ms, total: 39.2 ms\n",
      "Wall time: 38.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#X, y --> X_resampled, y_resampled\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "\n",
    "#return a list of tuples for item, and count of item. in this case 4139 each\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8278,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8278, 215840)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 ms, sys: 10.1 ms, total: 22.9 ms\n",
      "Wall time: 22 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#test, train, split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes/imbalanced learn/TFIDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# multinm_clf = MultinomialNB()\n",
    "# multinm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multinm_clf.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = multinm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #clf.score = accuracy = 'true'(pos/neg) / total\n",
    "\n",
    "# multinm_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix(y_true = y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tn, fp, fn, tp = confusion_matrix(y_true = y_test, y_pred = y_pred).ravel()\n",
    "# (tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "\n",
    "# accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # rate of actual op-ed articles, out of all the actual od-ed articles\n",
    "\n",
    "# recall = (tp) / (tp + fn)\n",
    "# recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rate of correct predictions of op-ed articles out of all predictions\n",
    "\n",
    "# precision = (tp) / (tp + fp)\n",
    "# precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "\n",
    "# accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "# print(f'accuracy = {accuracy}')\n",
    "# recall = (tp) / (tp + fn)\n",
    "# print(f'recall = {recall}')\n",
    "# precision = (tp) / (tp + fp)\n",
    "# print(f'precision = {precision}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class sklearn.ensemble.RandomForestClassifier(n_estimators=100, \n",
    "#                                               *, \n",
    "#                                               criterion='gini', \n",
    "#                                               max_depth=None, \n",
    "#                                               min_samples_split=2, \n",
    "#                                               min_samples_leaf=1, \n",
    "#                                               min_weight_fraction_leaf=0.0, \n",
    "#                                               max_features='auto', \n",
    "#                                               max_leaf_nodes=None, \n",
    "#                                               min_impurity_decrease=0.0, \n",
    "#                                               min_impurity_split=None, \n",
    "#                                               bootstrap=True, \n",
    "#                                               oob_score=False, \n",
    "#                                               n_jobs=None, \n",
    "#                                               random_state=None, \n",
    "#                                               verbose=0, \n",
    "#                                               warm_start=False, \n",
    "#                                               class_weight=None, \n",
    "#                                               ccp_alpha=0.0, \n",
    "#                                               max_samples=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58 µs, sys: 5 µs, total: 63 µs\n",
      "Wall time: 65.6 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_clf = RandomForestClassifier(max_depth=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 373 ms, sys: 33.5 ms, total: 406 ms\n",
      "Wall time: 406 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9415458937198068"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf.score = accuracy = 'true'(pos/neg) / total\n",
    "\n",
    "rf_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1003,   17],\n",
       "       [ 104,  946]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true = y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1003, 17, 104, 946)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true = y_test, y_pred = y_pred).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "\n",
    "# accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rate of actual op-ed articles, out of all the actual od-ed articles\n",
    "\n",
    "# recall = (tp) / (tp + fn)\n",
    "# recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rate of correct predictions of op-ed articles out of all predictions\n",
    "\n",
    "# precision = (tp) / (tp + fp)\n",
    "# precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9415458937198068\n",
      "recall = 0.900952380952381\n",
      "precision = 0.9823468328141225\n"
     ]
    }
   ],
   "source": [
    "#rate of correct predictions out of total predictions\n",
    "\n",
    "accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "print(f'accuracy = {accuracy}')\n",
    "recall = (tp) / (tp + fn)\n",
    "print(f'recall = {recall}')\n",
    "precision = (tp) / (tp + fp)\n",
    "print(f'precision = {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class sklearn.ensemble.RandomForestClassifier(n_estimators=100, \n",
    "#                                               *, \n",
    "#                                               criterion='gini', \n",
    "#                                               max_depth=None, \n",
    "#                                               min_samples_split=2, \n",
    "#                                               min_samples_leaf=1, \n",
    "#                                               min_weight_fraction_leaf=0.0, \n",
    "#                                               max_features='auto', \n",
    "#                                               max_leaf_nodes=None, \n",
    "#                                               min_impurity_decrease=0.0, \n",
    "#                                               min_impurity_split=None, \n",
    "#                                               bootstrap=True, \n",
    "#                                               oob_score=False, \n",
    "#                                               n_jobs=None, \n",
    "#                                               random_state=None, \n",
    "#                                               verbose=0, \n",
    "#                                               warm_start=False, \n",
    "#                                               class_weight=None, \n",
    "#                                               ccp_alpha=0.0, \n",
    "#                                               max_samples=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what is this random forest doing?\n",
    "1. takes all X and y which is my text and classifiers as vectors(tfidf)\n",
    "2. take a random number of 8278 instances (tfidf vector) and uses a random number of 219112 features to make best decision.\n",
    "3. bags/bootstraps that model\n",
    "4. does it again a bunch of times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accuracy, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "# def metrics_(tn, fp, fn, tp):\n",
    "#     accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "#     print(f'accuracy = {accuracy}')\n",
    "#     recall = (tp) / (tp + fn)\n",
    "#     print(f'recall = {recall}')\n",
    "#     precision = (tp) / (tp + fp)\n",
    "#     print(f'precision = {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics_(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bag of words\n",
    "# get sparse matrix\n",
    "# overlay bag of words onto sparce matrix\n",
    "# argsort to find most important (highest number) word that it's splitting w/ most infomation gain/ least entroy... whatever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer(*, \n",
    "#                 input='content', \n",
    "#                 encoding='utf-8', \n",
    "#                 decode_error='strict', \n",
    "#                 strip_accents=None, \n",
    "#                 lowercase=Truelowercase=True \n",
    "#                 preprocessor=None, \n",
    "#                 tokenizer=None, \n",
    "#                 analyzer='word', \n",
    "#                 stop_words=None, \n",
    "#                 token_pattern='(?u)\\b\\w\\w+\\b', \n",
    "#                 ngram_range=(1, 1), \n",
    "#                 max_df=1.0, \n",
    "#                 min_df=1, \n",
    "#                 max_features=None, \n",
    "#                 vocabulary=None, \n",
    "#                 binary=False, \n",
    "#                 dtype=<class 'numpy.float64'>, \n",
    "#                 norm='l2', \n",
    "#                 use_idf=True, \n",
    "#                 smooth_idf=True, \n",
    "#                 sublinear_tf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_2019_df = _2019.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X. X is currently pandas series of unsplit strings\n",
    "\n",
    "X_nltk = nltk_2019_df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define y as a series of op-ed or news\n",
    "\n",
    "y_nktk = nltk_2019_df.type_of_material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.6 ms, sys: 3.2 ms, total: 14.8 ms\n",
      "Wall time: 13.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# vectorize y in to (1, 0) (op-ed, news)\n",
    "\n",
    "y_nktk = vectorize_type(y_nktk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn series into list...\n",
    "\n",
    "corpus_nltk = list(X_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenize w/ nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.3 s, sys: 1.96 s, total: 16.2 s\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "regex_tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "tokenized_punc = [regex_tokenizer.tokenize(article.lower())for article in corpus_nltk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2218"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(tokenized_punc[0])) #2218"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41748"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# tokenized = [word_tokenize(article.lower()) for article in corpus_nltk]\n",
    "\n",
    "# CPU times: user 4min 46s, sys: 2.39 s, total: 4min 48s\n",
    "# Wall time: 4min 50s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #list of list of strings. one list of strings per documents. list are various lengths around 1000\n",
    "\n",
    "# len(tokenized[0]) #2596"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## take out stop work via ntlk. does this work against sklearn when i vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.05 s, sys: 1.09 s, total: 5.14 s\n",
      "Wall time: 5.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stop = set(stopwords.words('english'))\n",
    "tokenized_docs = [[word for word in words if word not in stop]\n",
    "            for words in tokenized_punc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1132"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hopefully this reduced the number of strings / list\n",
    "\n",
    "len(tokenized[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41748"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#docs is new tokenized, but with stop words removed\n",
    "\n",
    "len(tokenized_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stemming/lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "snowball = SnowballStemmer('english')\n",
    "wordnet = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# docs_porter = [[porter.stem(word) for word in words]\n",
    "#                    for words in docs]\n",
    "# docs_snowball = [[snowball.stem(word) for word in words]\n",
    "#                      for words in docs]\n",
    "# docs_wordnet = [[wordnet.lemmatize(word) for word in words]\n",
    "#                     for words in docs]\n",
    "\n",
    "# CPU times: user 14min 59s, sys: 18.4 s, total: 15min 18s\n",
    "# Wall time: 15min 26s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# docs_porter = [[porter.stem(word) for word in words]\n",
    "#                    for words in docs]\n",
    "\n",
    "# CPU times: user 7min 16s, sys: 5.21 s, total: 7min 21s\n",
    "# Wall time: 7min 22s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min, sys: 1.24 s, total: 5min 1s\n",
      "Wall time: 5min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "snowball_stemm = [[snowball.stem(word) for word in words]\n",
    "                     for words in tokenized_docs]\n",
    "\n",
    "# CPU times: user 5min 5s, sys: 5.98 s, total: 5min 11s\n",
    "# Wall time: 5min 13s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# docs_wordnet = [[wordnet.lemmatize(word) for word in words]\n",
    "#                     for words in docs]\n",
    "\n",
    "# CPU times: user 1min 24s, sys: 4.5 s, total: 1min 28s\n",
    "# Wall time: 1min 30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# ## Print the stemmed and lemmatized words from the first document\n",
    "# print(\"%16s %16s %16s %16s\" % (\"word\", \"porter\", \"snowball\", \"lemmatizer\"))\n",
    "# for i in range(min(len(docs_porter[0]), len(docs_snowball[0]), len(docs_wordnet[0]))):\n",
    "#     p, s, w = docs_porter[0][i], docs_snowball[0][i], docs_wordnet[0][i]\n",
    "#     if len(set((p, s, w))) != 1:\n",
    "#         print(\"%16s %16s %16s %16s\" % (docs[0][i], p, s, w))\n",
    "#         print(docs[0][i], w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs and lemmatizer are the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I choose SNOWBALL!!!! to sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs_snowball_stemm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus_nltk[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snowball = SnowballStemmer('english')\n",
    "# snowball_tokenized = [snowball.stem(word) for word in word_tokenize(doc.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 µs, sys: 0 ns, total: 14 µs\n",
      "Wall time: 17.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def snowball_tokenize(doc):\n",
    "    snowball = SnowballStemmer('english')\n",
    "    return [snowball.stem(word) for word in word_tokenize(doc.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#create vectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(#input='content', \n",
    "#                 encoding='utf-8', \n",
    "#                 decode_error='strict', \n",
    "                 strip_accents='ascii', \n",
    "                 lowercase=True, \n",
    "#                 preprocessor=None, \n",
    "                 tokenizer=snowball_tokenize, \n",
    "#                 analyzer='word', \n",
    "                 stop_words=None, \n",
    "#                 token_pattern='(?u)\\b\\w\\w+\\b', \n",
    "#                 ngram_range=(1, 1), \n",
    "#                 max_df=1.0, \n",
    "#                 min_df=1, \n",
    "                 max_features=None, \n",
    "#                 vocabulary=None, \n",
    "#                 binary=False, \n",
    "#                 dtype=<class 'numpy.float64'>, \n",
    "#                 norm='l2', \n",
    "#                 use_idf=True, \n",
    "#                 smooth_idf=True, \n",
    "#                 sublinear_tf=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_snowball = vectorizer.fit_transform(corpus_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rf_clf = RandomForestClassifier(max_depth=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.score = accuracy = 'true'(pos/neg) / total\n",
    "\n",
    "rf_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true = y_test, y_pred = y_pred).ravel()\n",
    "(tn, fp, fn, tp)\n",
    "metrics_(tn, fp, fn, tp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
