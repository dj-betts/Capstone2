{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Pipeline \n",
    "\n",
    "![](images/pipeline-walkthrough1.png)\n",
    "\n",
    "Below is a to do list when converting text into vector form: \n",
    "\n",
    "**Clean text and Create a Bag of Words (BoW)**\n",
    ">1. Lowercase the text\n",
    "2. Tokenize \n",
    "3. Strip out punctuation or undesirable text\n",
    "4. Remove Stopwords \n",
    "5. Stemming or Lemmatizing\n",
    "6. Compute N-Grams\n",
    "7. Use this to create BoW\n",
    "\n",
    "**Vectorize BoW**\n",
    ">8. Term Frequencies\n",
    "9. Document Frequencies\n",
    "10. TF-IDF\n",
    "11. Normalize vectors\n",
    "\n",
    "Let's go through both what each of these steps are and how to do them in python with the following corpus of comments about data science...\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion to cut off extra intro paragraphs from beautiful soup scrape\n",
    "\n",
    "# def trim_fat(string):\n",
    "#     return string[35:-115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to vectorize the type_of_material series into a y target vector.\n",
    "def vectorize_type(ser):\n",
    "    y = ser.copy()\n",
    "    y.replace({'Op-Ed': 1,'News': 0}, inplace=True)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rate of correct predictions out of total predictions\n",
    "def metrics_(tn, fp, fn, tp):\n",
    "    accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "    print(f'accuracy = {accuracy}')\n",
    "    recall = (tp) / (tp + fn)\n",
    "    print(f'recall = {recall}')\n",
    "    precision = (tp) / (tp + fp)\n",
    "    print(f'precision = {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.51 s, sys: 254 ms, total: 1.77 s\n",
      "Wall time: 1.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_2019 = pd.read_csv('data/trim2019_text_type.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 749 µs, sys: 171 µs, total: 920 µs\n",
      "Wall time: 920 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_2019_df = _2019.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X. X is currently pandas series of unsplit strings\n",
    "\n",
    "X = _2019_df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define y as a series of op-ed or news\n",
    "\n",
    "y = _2019_df.type_of_material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.6 ms, sys: 1.95 ms, total: 13.5 ms\n",
      "Wall time: 12.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# vectorize y in to (1, 0) (op-ed, news)\n",
    "\n",
    "y = vectorize_type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn series into list...\n",
    "\n",
    "corpus = list(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn TfidfVectorizer(stop_words='english', strip_accents='ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25 s, sys: 472 ms, total: 25.4 s\n",
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#create vectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(#input='content', \n",
    "#                 encoding='utf-8', \n",
    "#                 decode_error='strict', \n",
    "                 strip_accents=None, \n",
    "                 lowercase=True, \n",
    "#                 preprocessor=None, \n",
    "#                 tokenizer=None, \n",
    "#                 analyzer='word', \n",
    "                 stop_words='english', \n",
    "#                 token_pattern='(?u)\\b\\w\\w+\\b', \n",
    "#                 ngram_range=(1, 1), \n",
    "#                 max_df=1.0, \n",
    "#                 min_df=1, \n",
    "                 max_features=None, \n",
    "#                 vocabulary=None, \n",
    "#                 binary=False, \n",
    "#                 dtype=<class 'numpy.float64'>, \n",
    "#                 norm='l2', \n",
    "#                 use_idf=True, \n",
    "#                 smooth_idf=True, \n",
    "#                 sublinear_tf=False\n",
    ")\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 176 ms, sys: 2.95 ms, total: 179 ms\n",
      "Wall time: 178 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stop_words = vectorizer.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215840"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resample class size w/ imbalanced learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41748,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41748, 215840)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 µs, sys: 1e+03 ns, total: 24 µs\n",
      "Wall time: 26 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#balance the classes\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 4139), (1, 4139)]\n",
      "CPU times: user 28.2 ms, sys: 11 ms, total: 39.2 ms\n",
      "Wall time: 38.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#X, y --> X_resampled, y_resampled\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "\n",
    "#return a list of tuples for item, and count of item. in this case 4139 each\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8278,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8278, 215840)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 ms, sys: 10.1 ms, total: 22.9 ms\n",
      "Wall time: 22 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#test, train, split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes/imbalanced learn/TFIDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# multinm_clf = MultinomialNB()\n",
    "# multinm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multinm_clf.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = multinm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #clf.score = accuracy = 'true'(pos/neg) / total\n",
    "\n",
    "# multinm_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix(y_true = y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tn, fp, fn, tp = confusion_matrix(y_true = y_test, y_pred = y_pred).ravel()\n",
    "# (tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "\n",
    "# accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # rate of actual op-ed articles, out of all the actual od-ed articles\n",
    "\n",
    "# recall = (tp) / (tp + fn)\n",
    "# recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rate of correct predictions of op-ed articles out of all predictions\n",
    "\n",
    "# precision = (tp) / (tp + fp)\n",
    "# precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "\n",
    "# accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "# print(f'accuracy = {accuracy}')\n",
    "# recall = (tp) / (tp + fn)\n",
    "# print(f'recall = {recall}')\n",
    "# precision = (tp) / (tp + fp)\n",
    "# print(f'precision = {precision}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class sklearn.ensemble.RandomForestClassifier(n_estimators=100, \n",
    "#                                               *, \n",
    "#                                               criterion='gini', \n",
    "#                                               max_depth=None, \n",
    "#                                               min_samples_split=2, \n",
    "#                                               min_samples_leaf=1, \n",
    "#                                               min_weight_fraction_leaf=0.0, \n",
    "#                                               max_features='auto', \n",
    "#                                               max_leaf_nodes=None, \n",
    "#                                               min_impurity_decrease=0.0, \n",
    "#                                               min_impurity_split=None, \n",
    "#                                               bootstrap=True, \n",
    "#                                               oob_score=False, \n",
    "#                                               n_jobs=None, \n",
    "#                                               random_state=None, \n",
    "#                                               verbose=0, \n",
    "#                                               warm_start=False, \n",
    "#                                               class_weight=None, \n",
    "#                                               ccp_alpha=0.0, \n",
    "#                                               max_samples=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58 µs, sys: 5 µs, total: 63 µs\n",
      "Wall time: 65.6 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_clf = RandomForestClassifier(max_depth=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 373 ms, sys: 33.5 ms, total: 406 ms\n",
      "Wall time: 406 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9415458937198068"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf.score = accuracy = 'true'(pos/neg) / total\n",
    "\n",
    "rf_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1003,   17],\n",
       "       [ 104,  946]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true = y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1003, 17, 104, 946)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true = y_test, y_pred = y_pred).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "\n",
    "# accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rate of actual op-ed articles, out of all the actual od-ed articles\n",
    "\n",
    "# recall = (tp) / (tp + fn)\n",
    "# recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rate of correct predictions of op-ed articles out of all predictions\n",
    "\n",
    "# precision = (tp) / (tp + fp)\n",
    "# precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9415458937198068\n",
      "recall = 0.900952380952381\n",
      "precision = 0.9823468328141225\n"
     ]
    }
   ],
   "source": [
    "#rate of correct predictions out of total predictions\n",
    "\n",
    "accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "print(f'accuracy = {accuracy}')\n",
    "recall = (tp) / (tp + fn)\n",
    "print(f'recall = {recall}')\n",
    "precision = (tp) / (tp + fp)\n",
    "print(f'precision = {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class sklearn.ensemble.RandomForestClassifier(n_estimators=100, \n",
    "#                                               *, \n",
    "#                                               criterion='gini', \n",
    "#                                               max_depth=None, \n",
    "#                                               min_samples_split=2, \n",
    "#                                               min_samples_leaf=1, \n",
    "#                                               min_weight_fraction_leaf=0.0, \n",
    "#                                               max_features='auto', \n",
    "#                                               max_leaf_nodes=None, \n",
    "#                                               min_impurity_decrease=0.0, \n",
    "#                                               min_impurity_split=None, \n",
    "#                                               bootstrap=True, \n",
    "#                                               oob_score=False, \n",
    "#                                               n_jobs=None, \n",
    "#                                               random_state=None, \n",
    "#                                               verbose=0, \n",
    "#                                               warm_start=False, \n",
    "#                                               class_weight=None, \n",
    "#                                               ccp_alpha=0.0, \n",
    "#                                               max_samples=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what is this random forest doing?\n",
    "1. takes all X and y which is my text and classifiers as vectors(tfidf)\n",
    "2. take a random number of 8278 instances (tfidf vector) and uses a random number of 219112 features to make best decision.\n",
    "3. bags/bootstraps that model\n",
    "4. does it again a bunch of times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accuracy, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "# def metrics_(tn, fp, fn, tp):\n",
    "#     accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "#     print(f'accuracy = {accuracy}')\n",
    "#     recall = (tp) / (tp + fn)\n",
    "#     print(f'recall = {recall}')\n",
    "#     precision = (tp) / (tp + fp)\n",
    "#     print(f'precision = {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics_(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bag of words\n",
    "# get sparse matrix\n",
    "# overlay bag of words onto sparce matrix\n",
    "# argsort to find most important (highest number) word that it's splitting w/ most infomation gain/ least entroy... whatever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer(*, \n",
    "#                 input='content', \n",
    "#                 encoding='utf-8', \n",
    "#                 decode_error='strict', \n",
    "#                 strip_accents=None, \n",
    "#                 lowercase=Truelowercase=True \n",
    "#                 preprocessor=None, \n",
    "#                 tokenizer=None, \n",
    "#                 analyzer='word', \n",
    "#                 stop_words=None, \n",
    "#                 token_pattern='(?u)\\b\\w\\w+\\b', \n",
    "#                 ngram_range=(1, 1), \n",
    "#                 max_df=1.0, \n",
    "#                 min_df=1, \n",
    "#                 max_features=None, \n",
    "#                 vocabulary=None, \n",
    "#                 binary=False, \n",
    "#                 dtype=<class 'numpy.float64'>, \n",
    "#                 norm='l2', \n",
    "#                 use_idf=True, \n",
    "#                 smooth_idf=True, \n",
    "#                 sublinear_tf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_2019_df = _2019.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X. X is currently pandas series of unsplit strings\n",
    "\n",
    "X_nltk = nltk_2019_df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define y as a series of op-ed or news\n",
    "\n",
    "y_nktk = nltk_2019_df.type_of_material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.6 ms, sys: 3.2 ms, total: 14.8 ms\n",
      "Wall time: 13.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# vectorize y in to (1, 0) (op-ed, news)\n",
    "\n",
    "y_nktk = vectorize_type(y_nktk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn series into list...\n",
    "\n",
    "corpus_nltk = list(X_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenize w/ nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.3 s, sys: 1.96 s, total: 16.2 s\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "regex_tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "tokenized_punc = [regex_tokenizer.tokenize(article.lower())for article in corpus_nltk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2218"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(tokenized_punc[0])) #2218"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41748"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# tokenized = [word_tokenize(article.lower()) for article in corpus_nltk]\n",
    "\n",
    "# CPU times: user 4min 46s, sys: 2.39 s, total: 4min 48s\n",
    "# Wall time: 4min 50s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #list of list of strings. one list of strings per documents. list are various lengths around 1000\n",
    "\n",
    "# len(tokenized[0]) #2596"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## is this really how nltk implementation works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.4 s, sys: 31 s, total: 42.4 s\n",
      "Wall time: 52.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stop = set(stopwords.words('english'))\n",
    "docs = [[word for word in words if word not in stop]\n",
    "            for words in tokenized_punc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1132"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hopefully this reduced the number of strings / list\n",
    "\n",
    "len(tokenized[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41748"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#docs is new tokenized, but with stop words removed\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stemming/lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "snowball = SnowballStemmer('english')\n",
    "wordnet = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# docs_porter = [[porter.stem(word) for word in words]\n",
    "#                    for words in docs]\n",
    "# docs_snowball = [[snowball.stem(word) for word in words]\n",
    "#                      for words in docs]\n",
    "# docs_wordnet = [[wordnet.lemmatize(word) for word in words]\n",
    "#                     for words in docs]\n",
    "\n",
    "# CPU times: user 14min 59s, sys: 18.4 s, total: 15min 18s\n",
    "# Wall time: 15min 26s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 16s, sys: 5.21 s, total: 7min 21s\n",
      "Wall time: 7min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "docs_porter = [[porter.stem(word) for word in words]\n",
    "                   for words in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 5s, sys: 5.98 s, total: 5min 11s\n",
      "Wall time: 5min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "docs_snowball = [[snowball.stem(word) for word in words]\n",
    "                     for words in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 24s, sys: 4.5 s, total: 1min 28s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "docs_wordnet = [[wordnet.lemmatize(word) for word in words]\n",
    "                    for words in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'\", ',', 'in', 'essay', '“', 'crack-up', ',', '”', 'f.', 'scott', 'fitzgerald', 'wrote', ',', '“', 'test', 'first-rat', 'intellig', 'abil', 'hold', 'two', 'oppos', 'idea', 'mind', 'time', ',', 'still', 'retain', 'abil', 'function.', '”', \"'\", ',', 'on', 'new', 'year', '’', 'day', '1919', ',', 'headlin', 'new', 'york', 'time', 'gave', 'hint', 'difficult', 'would', 'american', ',', 'struggl', 'live', 'shimmer', 'promis', 'made', 'world', 'great', 'war', ',', 'end', 'month', '.', \"'\", ',', 'pole', ',', 'newli', 'independ', 'alreadi', 'threaten', 'neighbor', ',', 'call', 'american', 'protect', '.', 'countri', ',', 'like', 'ireland', ',', 'cusp', 'independ', ',', 'ask', 'help', '.', 'bewild', 'set', 'new', 'respons', 'settl', 'upon', 'countri', 'long', 'cherish', 'freedom', 'old', 'world', '.', \"'\", ',', 'overwhelm', ',', 'american', 'long', 'get', 'old', 'live', 'back', '.', 'clear', 'road', 'map', '“', 'normalci', ',', '”', 'use', 'word', 'began', 'gain', 'traction', 'chao', 'postwar', 'year', '.', 'grammarian', 'fault', 'clumsi', 'neolog', ',', 'made', 'popular', '.', 'rakish', 'ohio', 'senat', ',', 'warren', 'hard', ',', 'would', 'eventu', 'ride', 'way', 'white', 'hous', '.', 'crack', 'old', 'record', ',', 'heard', 'promis', ',', 'vagu', ',', 'make', 'america', 'great', '.', '’', 'work', 'well', '.', \"'\", ',', 'there', 'reason', 'believ', 'lofti', 'promis', '1919', 'begin', '.', 'peac', ',', 'everyth', 'felt', 'new', '.', 'certain', 'true', 'geopolit', 'realm', ',', 'negoti', 'conven', 'pari', ',', 'eager', 'redraw', 'world', 'map', '.', 'difficult', 'know', 'begin', '.', 'german', ',', 'austrian', 'ottoman', 'empir', 'part', 'ash', 'heap', 'histori', ',', 'memor', 'phrase', 'leon', 'trotski', '.', 'countri', ',', 'russia', ',', 'disappear', ',', 'undergo', 'transform', 'profound', 'destabil', 'half', 'europ', '.', 'oversea', ',', 'territori', 'belong', 'belliger', 'exchang', 'like', 'carpet', 'second-hand', 'bazaar', '.', 'centuri', 'later', ',', 'middl', 'east', 'africa', ',', 'world', 'still', 'struggl', 'decis', 'made', 'hastili', '1919', '.', \"'\", ',', 'but', 'anyon', 'could', 'solv', 'nasti', 'problem', ',', 'american', 'could', '.', 'beleagu', 'world', ',', 'seem', 'almost', 'superhuman', '.', 'despit', 'late', 'entri', 'war', ',', 'shape', 'conflict', 'decis', 'manpow', ',', 'matériel', 'chirpi', 'market', '.', '“', 'democraci', '”', 'word', 'hour', ',', 'elixir', 'problem', ',', 'accord', 'presid', 'woodrow', 'wilson', ',', 'inton', 'impress', 'solemn', '.', \"'\", ',', 'for', 'time', ',', 'world', 'believ', '.', 'head', 'pari', ',', 'longest', 'oversea', 'trip', 'presid', ',', 'lioniz', 'leader', 'ever', '.', 'film', 'footag', 'captur', 'odd', 'contrast', 'quiet', 'ocean', 'passag', ',', 'follow', 'euphoria', 'crowd', 'franc', ',', 'hope', 'would', 'solv', 'problem', '.', 'tall', 'order', '.', \"'\", ',', 'we', 'still', 'live', 'close', 'graini', 'footag', ',', 'insid', 'world', 'emerg', 'versaill', 'hall', 'mirror', '.', 'german', 'resent', 'harsh', 'condit', 'impos', 'fuel', 'rise', 'adolf', 'hitler', ',', ',', 'like', 'mani', ',', 'found', 'polit', 'voic', '1919.', 'historian', 'would', 'later', 'trace', 'origin', 'world', 'war', 'ii', 'treati', '’', 'shortcom', ',', 'swirl', 'nation', 'fail', 'calm', '.', 'presid', 'wilson', 'promis', 'build', 'world', '“', 'safe', 'democraci', ',', '”', 'result', 'neither', 'safe', ',', 'mani', 'case', ',', 'democrat', '.', 'british', 'politician', 'whose', 'career', 'bare', 'surviv', 'war', ',', 'winston', 'churchil', ',', 'saw', 'clear', '“', 'crippl', ',', 'broken', 'world', ',', '”', 'divid', 'along', 'fault', 'line', 'never', 'obliter', '.', \"'\", ',', 'larg', 'part', 'british', ',', 'french', 'belgian', 'empir', 'remain', 'intact', ',', 'distress', 'million', 'hope', 'democraci', '.', 'inspir', 'wind', 'chang', ',', 'independ', 'movement', 'sprang', 'around', 'world', '.', 'success', ',', 'mani', 'other', ',', 'self-determin', ',', 'anoth', 'one', 'wilson', '’', 'ring', 'phrase', ',', 'elus', 'best', '.', 'weari', 'european', 'diplomat', 'chafe', 'moralist', 'speech', ',', 'scorn', '“', 'sermonettes.', '”', 'presid', 'franc', ',', 'georg', 'clemenceau', ',', 'complain', '“', 'talk', 'wilson', 'someth', 'like', 'convers', 'jesus', 'christ', '!', '”', 'wilson', 'would', 'sure', 'second', 'thought', '.', \"'\", ',', 'still', ',', 'pocket', 'realism', 'within', 'ideal', 'politician', ',', 'blind', 'spot', ',', 'understood', 'world', 'could', 'continu', '.', 'wilson', 'long', 'critic', 'failur', ',', 'correct', 'grasp', 'core', 'truth', ',', 'still', 'relev', ',', 'lazi', 'return', 'unbridl', 'nation', 'recip', 'conflict', '.', 'like', 'presid', ',', 'relish', 'consult', 'congress', ',', 'misread', 'democraci', 'boomerang', ',', 'newli', 'elect', 'republican', 'major', 'refus', 'approv', 'plan', 'leagu', 'nation', '.', \"'\", ',', 'desper', 'outflank', ',', 'tri', 'take', 'case', 'direct', 'peopl', ',', 'boister', 'ralli', ',', 'far', 'east', 'coast', 'elit', '—', 'anoth', 'way', '2019', 'mirror', '1919.', 'strain', 'effort', 'result', 'stroke', ',', 'near', 'incapacit', 'wilson', 'last', 'year', 'presid', '.', 'democraci', '’', 'great', 'spokesman', 'imperil', 'system', 'govern', 'went', 'length', 'defend', '.', 'crack-up', 'one', 'mani', '1919', '.', \"'\", ',', 'to', 'young', 'writer', 'like', 'fitzgerald', ',', 'receiv', 'first', 'book', 'contract', '1919', ',', 'obvious', 'old', 'word', 'work', 'new', 'one', 'need', 'found', '.', 'writer', 'simpli', 'invent', '—', 'jame', 'joyc', 'constant', 'write', 'new', 'one', 'scribbledehobbl', ',', 'notebook', '.', \"'\", ',', 'other', 'lament', 'vanish', ',', 'dread', 'come', 'next', '.', '“', 'mani', 'ingeni', 'love', 'thing', 'gone', ',', '”', 'william', 'butler', 'yeat', 'wrote', ',', 'poem', 'titl', '“', 'nineteen', 'hundr', 'nineteen.', '”', 'less', 'five', 'year', 'elaps', 'sinc', 'war', 'start', '1914', ',', 'everyth', 'felt', 'differ', '.', 'yeat', ',', 'new', 'sight', 'sound', 'terrifi', ':', 'one', 'famous', 'poem', ',', '“', 'second', 'come', ',', '”', 'imagin', 'apocalyps', 'popul', 'fantast', 'beast', 'would', 'give', 'j.k.', 'rowl', 'run', 'money', '.', 'despit', 'gloom', ',', 'becom', 'one', 'over-quot', 'poem', 'histori', '.', \"'\", ',', 'but', 'million', 'other', ',', 'sight', 'sound', '1919', 'glorious', '.', 'wage', 'war', 'releas', 'galvan', 'energi', 'american', ',', 'attack', 'problem', 'victori', 'stun', 'effici', '.', 'includ', 'tremend', 'contribut', 'immigr', ',', 'women', 'african-american', ',', 'raucous', 'celebr', 'victori', 'parad', 'upon', 'return', '.', 'one', 'parad', 'new', 'york', 'fete', 'famous', 'harlem', 'hellfight', 'regiment', ',', 'march', 'behind', 'spirit', 'band', 'play', 'kind', 'music', 'american', 'never', 'heard', ',', 'soon', 'known', 'jazz', '.', \"'\", ',', 'one', 'hottest', 'song', '1919', 'novelti', 'hit', ',', '“', 'ya', 'gon', 'na', 'keep', '’', 'em', 'farm', '(', '’', 'seen', 'pare', ')', '?', '”', 'fair', 'question', 'countri', 'go', 'return', 'easili', 'prewar', 'attitud', 'race', 'citizenship', '.', 'return', 'doughboy', 'brought', 'exuber', 'close', 'war', 'effort', ',', 'also', 'exacerb', 'tension', 'entitl', 'democraci', 'self-determin', ',', 'peski', 'phrase', 'woodrow', 'wilson', 'kept', 'repeat', '.', \"'\", ',', 'throughout', '1919', ',', 'anoth', 'way', 'american', 'seem', 'hold', 'two', 'oppos', 'thought', 'time', '.', 'larg', 'number', 'african-american', 'chose', 'form', 'self-determin', 'move', 'south', ',', 'toward', 'northern', 'citi', ',', 'midwest', 'west', 'coast', ',', 'demograph', 'chang', 'alter', 'america', 'forev', '.', 'even', 'move', ',', 'mani', 'found', 'democraci', 'daili', 'challeng', '.', \"'\", ',', 'that', 'year', 'south', ',', 'two', 'children', 'born', 'near', ',', 'either', 'side', 'alabama-georgia', 'line', ',', 'reveal', 'quick', 'countri', 'chang', '.', 'jacki', 'robinson', 'grew', 'new', 'kind', 'america', ',', 'thank', 'mother', ',', 'move', 'california', '.', 'georg', 'wallac', 'spent', 'life', 'tri', 'hold', 'back', 'tide', 'chang', 'robinson', '’', 'generat', 'help', 'unleash', '.', \"'\", ',', 'throughout', 'long', 'year', ',', 'tension', 'simmer', 'america', '’', 'gleam', 'surfac', '.', 'ugli', 'race', 'riot', 'chicago', 'took', 'live', '38', 'peopl', 'late', 'juli', '.', 'anxieti', 'target', 'immigr', ',', 'found', 'american', 'less', 'welcom', 'statu', 'greet', 'new', 'york', 'harbor', '.', 'defend', 'old', 'order', ',', 'america', 'done', 'part', ',', 'need', 'open', 'floodgat', '.', 'mani', 'other', ',', 'seek', 'broader', 'form', 'democraci', ',', 'wilson', '’', 'rhetor', 'seem', 'describ', 'countri', 'exist', 'vivid', 'imagin', 'realiti', '.', \"'\", ',', 'torn', 'two', 'direct', ',', 'world', '’', 'wealthiest', 'countri', 'seem', 'head', 'form', 'crack-up', '.', 'throughout', '1919', ',', 'wave', 'fear', 'paralyz', 'american', ',', 'reel', 'dead', 'influenza', 'epidem', 'start', 'year', ',', 'campaign', 'letter', 'bomb', 'sent', 'anarchist', 'spring', '.', 'vigor', 'govern', 'respons', 'led', 'creation', 'f.b.i', '.', 'seri', 'raid', 'conduct', 'overzeal', 'attorney', 'general', ',', 'a.', 'mitchel', 'palmer', '.', '“', 'palmer', 'raid', '”', 'awaken', 'fear', 'polic', 'state', 'reveal', 'difficult', 'democraci', 'could', '.', 'retaliatori', 'bomb', ',', 'direct', 'palmer', ',', 'explod', 'outsid', 'hous', 'washington', ',', 'near', 'kill', 'neighbor', ',', 'franklin', 'roosevelt', '.', 'roosevelt', 'gave', 'speech', 'name', 'new', 'deal', ',', '13', 'year', 'later', ',', 'rememb', 'wilson', ',', 'fail', ',', 'usher', 'american', 'new', 'era', '.', \"'\", ',', \"'\", 'long', 'centuri', 'elaps', ',', 'contradict', '1919', 'still', 'bear', 'scrutini', '.', 'old', 'fault', 'line', 'seem', 'closer', 'surfac', 'roosevelt', '’', 'day', ',', 'american', 'larg', 'unit', 'behind', 'great', 'effort', 'end', 'poverti', 'crush', 'fascism', '.', \"'\", ',', \"'\", 'hundr', 'year', 'ago', ',', 'possibl', 'look', 'countri', 'see', 'two', 'differ', 'version', 'america', '.', 'sure', ',', 'thrive', 'nation', 'immigr', ',', 'innov', 'dizzi', 'rate', ',', 'bustl', 'citi', 'envi', 'world', '.', 'also', 'quieter', 'countri', ',', 'domin', 'farmer', 'small', 'town', ',', 'polit', 'social', 'conserv', ',', 'dismay', 'excess', 'would', 'soon', 'known', 'jazz', 'age', '.', 'prohibit', 'anoth', 'achiev', '—', '’', 'worth', '—', '1919', '.', \"'\", ',', 'neither', 'side', 'monopoli', 'virtu', ',', 'event', 'would', 'prove', '.', 'urban', 'rural', 'america', 'produc', 'equal', 'share', 'polit', 'rascal', '.', 'rascal', ',', 'various', 'guis', ',', 'anoth', 'featur', 'life', ',', 'new', 'form', 'entertain', 'began', 'domin', 'attent', ',', 'demand', 'villain', 'hero', 'equal', 'measur', '.', 'mani', 'case', ',', 'war', 'acceler', 'trend', ',', 'advanc', 'research', 'radio', 'communic', 'use', 'newsreel', 'mobil', 'support', 'militari', 'effort', '.', 'soon', ',', 'mass', 'communic', 'affect', 'american', ',', 'rural', 'urban', 'alik', '.', 'huge', 'new', 'movi', 'palac', 'built', '—', 'capitol', ',', 'new', 'york', ',', 'could', 'seat', '4,000', '—', 'hollywood', 'continu', 'grow', 'apac', ',', 'new', 'kind', 'dream', 'factori', ',', 'built', 'around', 'studio', 'star', '.', \"'\", ',', 'sport', 'big', 'busi', 'well', '—', 'one', 'case', ',', 'bit', 'big', ',', 'mobster', 'abl', 'alter', 'outcom', '1919', 'world', 'seri', '.', 'money', 'affect', 'fan', 'way', ',', '—', 'owner', 'boston', 'red', 'sox', 'trade', 'babe', 'ruth', 'new', 'york', 'yanke', 'end', 'year', ',', 'invok', 'curs', 'team', ',', 'would', 'win', 'anoth', 'world', 'seri', '2004', '.', \"'\", ',', 'the', 'rural-urban', 'divid', 'moder', 'anoth', 'way', '.', 'sale', 'automobil', 'near', 'doubl', '1919', ',', 'american', 'happili', 'return', 'leisur', 'pursuit', 'expand', 'horizon', 'everi', 'sens', '.', 'one', 'eager', 'driver', 'abl', 'coax', 'vehicl', '120', 'mile', 'hour', '—', 'brooklyn', '!', \"'\", ',', 'fortun', ',', 'crackup', 'result', '.', \"'\", ',', 'soon', 'car', 'chang', 'everyth', '.', 'new', 'suburban', 'ring', 'bloom', 'around', 'citi', ',', 'join', 'urban', 'rural', 'creat', 'someth', 'quit', 'either', '.', 'accident', 'effect', 'war', 'signific', 'boost', 'oil', 'product', ',', 'result', 'heavi', 'emphasi', 'machin', 'like', 'tank', 'airplan', 'use', 'intern', 'combust', 'engin', '.', 'american', 'quick', 'corral', 'market', ',', 'embrac', 'automobil', 'like', 'one', 'els', '.', 'prewar', 'experiment', 'steam-pow', 'electr', 'vehicl', 'wane', 'result', '.', \"'\", ',', 'to', 'better', 'support', 'all-import', 'vehicl', ',', 'thousand', 'mile', 'highway', 'built', ',', 'chang', 'countri', 'forev', '.', 'promot', 'idea', 'interst', 'travel', ',', 'militari', 'convoy', 'left', 'washington', 'california', 'juli', '1919.', 'new', 'york', 'time', 'call', '“', 'largest', 'aggreg', 'motor', 'vehicl', 'ever', 'start', 'trip', 'length.', '”', \"'\", ',', 'but', 'convoy', 'broke', 'repeat', ',', 'took', '62', 'day', 'reach', 'destin', '.', 'averag', 'six', 'mile', 'hour', ',', 'almost', '’', 'make', 'utah', '.', 'turn', ',', 'almost', 'pave', 'road', 'illinoi', 'nevada', '.', 'decad', 'later', ',', 'offic', 'led', 'convoy', ',', 'dwight', 'd.', 'eisenhow', ',', 'would', 'push', 'nation', 'highway', 'system', 'presid', '.', 'even', 'well-public', 'divid', 'red', 'blue', 'state', ',', 'general', 'reach', 'need', ',', 'anoth', 'unexpect', 'result', 'pivot', 'year', '.', \"'\", ',', 'in', 'overquot', 'poem', '1919', ',', 'yeat', 'wrote', '“', 'thing', 'fall', 'apart', ',', 'center', 'hold.', '”', 'word', 'often', 'ring', 'true', 'today', ',', 'anoth', 'divid', 'moment', '.', 'one', 'comfort', 'histori', 'see', 'wrong', 'earlier', 'prognost', 'doom', 'could', '.', 'studi', 'way', 'fail', 'fall', 'apart', ',', 'perhap', 'glean', 'small', 'harvest', 'hope', 'year', 'ahead', '.', \"'\", ',', \"'\"]\n"
     ]
    }
   ],
   "source": [
    "print((docs_snowball[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            word           porter         snowball       lemmatizer\n",
      "             'in              'in               in              'in\n",
      "      first-rate        first-rat        first-rat       first-rate\n",
      "    intelligence         intellig         intellig     intelligence\n",
      "         ability             abil             abil          ability\n",
      "         opposed            oppos            oppos          opposed\n",
      "         ability             abil             abil          ability\n",
      "             'on              'on               on              'on\n",
      "       headlines          headlin          headlin         headline\n",
      "      struggling          struggl          struggl       struggling\n",
      "      shimmering          shimmer          shimmer       shimmering\n",
      "        promises           promis           promis          promise\n",
      "           ended              end              end            ended\n",
      "          'poles            'pole             pole           'poles\n",
      "           newly            newli            newli            newly\n",
      "     independent         independ         independ      independent\n",
      "         already          alreadi          alreadi          already\n",
      "      threatened         threaten         threaten       threatened\n",
      "         calling             call             call          calling\n",
      "       countries          countri          countri          country\n",
      "    independence         independ         independ     independence\n",
      "          asking              ask              ask           asking\n",
      "     bewildering           bewild           bewild      bewildering\n",
      "responsibilities          respons          respons   responsibility\n",
      "        settling            settl            settl         settling\n",
      "         country          countri          countri          country\n",
      "       cherished          cherish          cherish        cherished\n",
      " 'overwhelmingly  'overwhelmingli        overwhelm  'overwhelmingly\n",
      "          longed             long             long           longed\n",
      "           lives             live             live             life\n",
      "        normalcy         normalci         normalci         normalcy\n",
      "           chaos             chao             chao            chaos\n",
      "         faulted            fault            fault          faulted\n",
      "          clumsy           clumsi           clumsi           clumsy\n",
      "       neologism           neolog           neolog        neologism\n",
      "         senator            senat            senat          senator\n",
      "         harding             hard             hard          harding\n",
      "      eventually           eventu           eventu       eventually\n",
      "           house             hous             hous            house\n",
      "         crackly          crackli            crack          crackly\n",
      "       recording           record           record        recording\n",
      "       promising           promis           promis        promising\n",
      "         vaguely             vagu             vagu          vaguely\n",
      "          'there           'there            there           'there\n",
      "         believe           believ           believ          believe\n",
      "           lofty            lofti            lofti            lofty\n",
      "        promises           promis           promis          promise\n",
      "       beginning            begin            begin        beginning\n",
      "           peace             peac             peac            peace\n",
      "      everything          everyth          everyth       everything\n",
      "       certainly        certainli          certain        certainly\n",
      "    geopolitical         geopolit         geopolit     geopolitical\n",
      "     negotiators           negoti           negoti       negotiator\n",
      "        convened           conven           conven         convened\n",
      "           paris             pari             pari            paris\n",
      "         empires            empir            empir           empire\n",
      "         history          histori          histori          history\n",
      "       memorable            memor            memor        memorable\n",
      "         trotsky          trotski          trotski          trotsky\n",
      "         country          countri          countri          country\n",
      "     disappeared        disappear        disappear      disappeared\n",
      "      undergoing          undergo          undergo       undergoing\n",
      "  transformation        transform        transform   transformation\n",
      "   destabilizing         destabil         destabil    destabilizing\n",
      "          europe            europ            europ           europe\n",
      "        overseas          oversea          oversea         overseas\n",
      "     territories        territori        territori        territory\n",
      "       belonging           belong           belong        belonging\n",
      "    belligerents         belliger         belliger      belligerent\n",
      "       exchanged          exchang          exchang        exchanged\n",
      "         century          centuri          centuri          century\n",
      "          middle            middl            middl           middle\n",
      "      struggling          struggl          struggl       struggling\n",
      "       decisions            decis            decis         decision\n",
      "         hastily          hastili          hastili          hastily\n",
      "            'but             'but              but             'but\n",
      "          anyone            anyon            anyon           anyone\n",
      "           solve             solv             solv            solve\n",
      "           nasty            nasti            nasti            nasty\n",
      "     beleaguered          beleagu          beleagu      beleaguered\n",
      "          seemed             seem             seem           seemed\n",
      "         despite           despit           despit          despite\n",
      "           entry            entri            entri            entry\n",
      "          shaped            shape            shape           shaped\n",
      "      decisively            decis            decis       decisively\n",
      "        manpower           manpow           manpow         manpower\n",
      "          chirpy           chirpi           chirpi           chirpy\n",
      "       marketing           market           market        marketing\n",
      "       democracy        democraci        democraci        democracy\n",
      "       according           accord           accord        according\n",
      "       president           presid           presid        president\n",
      "         intoned            inton            inton          intoned\n",
      "      impressive          impress          impress       impressive\n",
      "       solemnity           solemn           solemn        solemnity\n",
      "            'for             'for              for             'for\n",
      "        believed           believ           believ         believed\n",
      "          headed             head             head           headed\n",
      "           paris             pari             pari            paris\n",
      "        overseas          oversea          oversea         overseas\n",
      "       president           presid           presid        president\n",
      "        lionized           lioniz           lioniz         lionized\n",
      "         footage           footag           footag          footage\n",
      "        captures           captur           captur          capture\n",
      "         oceanic            ocean            ocean          oceanic\n",
      "         passage           passag           passag          passage\n",
      "        followed           follow           follow         followed\n",
      "          france            franc            franc           france\n",
      "           hoped             hope             hope            hoped\n",
      "           solve             solv             solv            solve\n",
      "             'we              'we               we              'we\n",
      "          grainy           graini           graini           grainy\n",
      "         footage           footag           footag          footage\n",
      "          inside            insid            insid           inside\n",
      "         emerged            emerg            emerg          emerged\n",
      "      versailles          versail         versaill       versailles\n",
      "      resentment           resent           resent       resentment\n",
      "      conditions           condit           condit        condition\n",
      "         imposed            impos            impos          imposed\n",
      "          fueled             fuel             fuel           fueled\n",
      "            many             mani             mani             many\n",
      "       political            polit            polit        political\n",
      "           voice             voic             voic            voice\n",
      "          treaty           treati           treati           treaty\n",
      "    shortcomings         shortcom         shortcom      shortcoming\n",
      "        swirling            swirl            swirl         swirling\n",
      "    nationalisms           nation           nation      nationalism\n",
      "          failed             fail             fail           failed\n",
      "       president           presid           presid        president\n",
      "        promised           promis           promis         promised\n",
      "       democracy        democraci        democraci        democracy\n",
      "            many             mani             mani             many\n",
      "      democratic         democrat         democrat       democratic\n",
      "          barely             bare             bare           barely\n",
      "        survived           surviv           surviv         survived\n",
      "       churchill         churchil         churchil        churchill\n",
      "         clearly          clearli            clear          clearly\n",
      "        crippled           crippl           crippl         crippled\n",
      "         divided            divid            divid          divided\n",
      "     obliterated          obliter          obliter      obliterated\n",
      "          'large            'larg             larg           'large\n",
      "         empires            empir            empir           empire\n",
      "        remained           remain           remain         remained\n",
      "          hoping             hope             hope           hoping\n",
      "     democracies        democraci        democraci        democracy\n",
      "        inspired           inspir           inspir         inspired\n",
      "          change            chang            chang           change\n",
      "    independence         independ         independ     independence\n",
      "      successful          success          success       successful\n",
      "            many             mani             mani             many\n",
      "          others            other            other           others\n",
      "self-determination    self-determin    self-determin self-determination\n",
      "         another            anoth            anoth          another\n",
      "         ringing             ring             ring          ringing\n",
      "         elusive             elus             elus          elusive\n",
      "           weary            weari            weari            weary\n",
      "          chafed            chafe            chafe           chafed\n",
      "      moralistic         moralist         moralist       moralistic\n",
      "         scorned            scorn            scorn          scorned\n",
      "       president           presid           presid        president\n",
      "          france            franc            franc           france\n",
      "         georges            georg            georg           george\n",
      "      complained         complain         complain       complained\n",
      "         talking             talk             talk          talking\n",
      "       something           someth           someth        something\n",
      "      conversing          convers          convers       conversing\n",
      "           jesus             jesu            jesus            jesus\n",
      "          surely             sure             sure           surely\n",
      "        seconded           second           second         seconded\n",
      "          'still           'still            still           'still\n",
      "        idealism            ideal            ideal         idealism\n",
      "        continue          continu          continu         continue\n",
      "      criticized           critic           critic       criticized\n",
      "        failures           failur           failur          failure\n",
      "        relevant            relev            relev         relevant\n",
      "            lazy             lazi             lazi             lazy\n",
      "       unbridled          unbridl          unbridl        unbridled\n",
      "     nationalism           nation           nation      nationalism\n",
      "          recipe            recip            recip           recipe\n",
      "      presidents           presid           presid        president\n",
      "      consulting          consult          consult       consulting\n",
      "      misreading          misread          misread       misreading\n",
      "       democracy        democraci        democraci        democracy\n",
      "     boomeranged        boomerang        boomerang      boomeranged\n",
      "           newly            newli            newli            newly\n",
      "         elected            elect            elect          elected\n",
      "        majority            major            major         majority\n",
      "         refused            refus            refus          refused\n",
      "         approve           approv           approv          approve\n",
      "          league            leagu            leagu           league\n",
      "      'desperate          'desper           desper       'desperate\n",
      "           tried              tri              tri            tried\n",
      "        directly         directli           direct         directly\n",
      "          people            peopl            peopl           people\n",
      "      boisterous          boister          boister       boisterous\n",
      "         rallies            ralli            ralli            rally\n",
      "          elites             elit             elit            elite\n",
      "         another            anoth            anoth          another\n",
      "        resulted           result           result         resulted\n",
      "          nearly           nearli             near           nearly\n",
      "   incapacitated        incapacit        incapacit    incapacitated\n",
      "      presidency           presid           presid       presidency\n",
      "       democracy        democraci        democraci        democracy\n",
      "       imperiled          imperil          imperil        imperiled\n",
      "      government           govern           govern       government\n",
      "            many             mani             mani             many\n",
      "             'to              'to               to              'to\n",
      "        received           receiv           receiv         received\n",
      "         obvious           obviou          obvious          obvious\n",
      "         working             work             work          working\n",
      "          needed             need             need           needed\n",
      "          simply           simpli           simpli           simply\n",
      "        invented           invent           invent         invented\n",
      "           james             jame             jame            james\n",
      "           joyce             joyc             joyc            joyce\n",
      "      constantly       constantli         constant       constantly\n",
      "         writing            write            write          writing\n",
      "scribbledehobble  scribbledehobbl  scribbledehobbl scribbledehobble\n",
      "         'others           'other            other          'others\n",
      "        lamented           lament           lament         lamented\n",
      "        vanished           vanish           vanish         vanished\n",
      "        dreading            dread            dread         dreading\n",
      "            many             mani             mani             many\n",
      "       ingenious           ingeni           ingeni        ingenious\n",
      "          lovely             love             love           lovely\n",
      "           yeats             yeat             yeat            yeats\n",
      "          titled             titl             titl           titled\n",
      "         hundred            hundr            hundr          hundred\n",
      "            less             less             less               le\n",
      "         elapsed            elaps            elaps          elapsed\n",
      "           since             sinc             sinc            since\n",
      "         started            start            start          started\n",
      "      everything          everyth          everyth       everything\n",
      "       different           differ           differ        different\n",
      "           yeats             yeat             yeat            yeats\n",
      "      terrifying          terrifi          terrifi       terrifying\n",
      "          famous            famou           famous           famous\n",
      "          coming             come             come           coming\n",
      "        imagined           imagin           imagin         imagined\n",
      "      apocalypse        apocalyps        apocalyps       apocalypse\n",
      "       populated            popul            popul        populated\n",
      "       fantastic          fantast          fantast        fantastic\n",
      "         rowling             rowl             rowl          rowling\n",
      "         despite           despit           despit          despite\n",
      "          become            becom            becom           become\n",
      "     over-quoted        over-quot        over-quot      over-quoted\n",
      "         history          histori          histori          history\n",
      "            'but             'but              but             'but\n",
      "          others            other            other           others\n",
      "        glorious          gloriou         glorious         glorious\n",
      "          waging             wage             wage           waging\n",
      "        released           releas           releas         released\n",
      "        galvanic           galvan           galvan         galvanic\n",
      "          energy           energi           energi           energy\n",
      "        attacked           attack           attack         attacked\n",
      "         victory          victori          victori          victory\n",
      "        stunning             stun             stun         stunning\n",
      "      efficiency           effici           effici       efficiency\n",
      "        included           includ           includ         included\n",
      "      tremendous          tremend          tremend       tremendous\n",
      "   contributions        contribut        contribut     contribution\n",
      "      immigrants           immigr           immigr        immigrant\n",
      "           women            women            women            woman\n",
      "       raucously          raucous          raucous        raucously\n",
      "      celebrated           celebr           celebr       celebrated\n",
      "         victory          victori          victori          victory\n",
      "         parades            parad            parad           parade\n",
      "          parade            parad            parad           parade\n",
      "           feted             fete             fete            feted\n",
      "          famous            famou           famous           famous\n",
      "    hellfighters        hellfight        hellfight     hellfighters\n",
      "        marching            march            march         marching\n",
      "        spirited           spirit           spirit         spirited\n",
      "         playing             play             play          playing\n",
      "            'one             'one              one             'one\n",
      "         novelty          novelti          novelti          novelty\n",
      "           paree             pare             pare            paree\n",
      "         country          countri          countri          country\n",
      "           going               go               go            going\n",
      "          easily           easili           easili           easily\n",
      "       attitudes          attitud          attitud         attitude\n",
      "       exuberant           exuber           exuber        exuberant\n",
      "     exacerbated          exacerb          exacerb      exacerbated\n",
      "        entitled           entitl           entitl         entitled\n",
      "       democracy        democraci        democraci        democracy\n",
      "self-determination    self-determin    self-determin self-determination\n",
      "           pesky            peski            peski            pesky\n",
      "       repeating           repeat           repeat        repeating\n",
      "     'throughout      'throughout       throughout      'throughout\n",
      "         another            anoth            anoth          another\n",
      "          seemed             seem             seem           seemed\n",
      "        opposing            oppos            oppos         opposing\n",
      "           large             larg             larg            large\n",
      "self-determination    self-determin    self-determin self-determination\n",
      "          moving             move             move           moving\n",
      "          cities             citi             citi             city\n",
      "     demographic        demograph        demograph      demographic\n",
      "          change            chang            chang           change\n",
      "         altered            alter            alter          altered\n",
      "         forever            forev            forev          forever\n",
      "            many             mani             mani             many\n",
      "       democracy        democraci        democraci        democracy\n",
      "           daily            daili            daili            daily\n",
      "       challenge         challeng         challeng        challenge\n",
      "           'that            'that             that            'that\n",
      "        children         children         children            child\n",
      "        revealed           reveal           reveal         revealed\n",
      "         quickly          quickli            quick          quickly\n",
      "         country          countri          countri          country\n",
      "        changing            chang            chang         changing\n",
      "          jackie            jacki            jacki           jackie\n",
      "          thanks            thank            thank           thanks\n",
      "           moved             move             move            moved\n",
      "          george            georg            georg           george\n",
      "         wallace           wallac           wallac          wallace\n",
      "          trying              tri              tri           trying\n",
      "          change            chang            chang           change\n",
      "      generation            gener          generat       generation\n",
      "          helped             help             help           helped\n",
      "     'throughout      'throughout       throughout      'throughout\n",
      "        simmered           simmer           simmer         simmered\n",
      "        gleaming            gleam            gleam         gleaming\n",
      "        surfaces           surfac           surfac          surface\n",
      "            ugly             ugli             ugli             ugly\n",
      "           lives             live             live             life\n",
      "          people            peopl            peopl           people\n",
      "            july             juli             juli             july\n",
      "       anxieties          anxieti          anxieti          anxiety\n",
      "        targeted           target           target         targeted\n",
      "      immigrants           immigr           immigr        immigrant\n",
      "            less             less             less               le\n",
      "       welcoming           welcom           welcom        welcoming\n",
      "          statue            statu            statu           statue\n",
      "         greeted            greet            greet          greeted\n",
      "       defenders           defend           defend         defender\n",
      "      floodgates         floodgat         floodgat        floodgate\n",
      "            many             mani             mani             many\n",
      "          others            other            other           others\n",
      "         seeking             seek             seek          seeking\n",
      "       democracy        democraci        democraci        democracy\n",
      "        rhetoric           rhetor           rhetor         rhetoric\n",
      "          seemed             seem             seem           seemed\n",
      "        describe          describ          describ         describe\n",
      "         country          countri          countri          country\n",
      "         existed            exist            exist          existed\n",
      "         vividly          vividli            vivid          vividly\n",
      "     imagination           imagin           imagin      imagination\n",
      "         reality          realiti          realiti          reality\n",
      "           'torn            'torn             torn            'torn\n",
      "      directions           direct           direct        direction\n",
      "         country          countri          countri          country\n",
      "          seemed             seem             seem           seemed\n",
      "          headed             head             head           headed\n",
      "       paralyzed          paralyz          paralyz        paralyzed\n",
      "          reeled             reel             reel           reeled\n",
      "          deadly           deadli             dead           deadly\n",
      "        epidemic           epidem           epidem         epidemic\n",
      "        vigorous            vigor            vigor         vigorous\n",
      "      government           govern           govern       government\n",
      "        response          respons          respons         response\n",
      "          series             seri             seri           series\n",
      "       conducted          conduct          conduct        conducted\n",
      "     overzealous         overzeal         overzeal      overzealous\n",
      "         general            gener          general          general\n",
      "        mitchell          mitchel          mitchel         mitchell\n",
      "        awakened           awaken           awaken         awakened\n",
      "          police            polic            polic           police\n",
      "        revealed           reveal           reveal         revealed\n",
      "       democracy        democraci        democraci        democracy\n",
      "     retaliatory      retaliatori      retaliatori      retaliatory\n",
      "        directed           direct           direct         directed\n",
      "        exploded           explod           explod         exploded\n",
      "         outside           outsid           outsid          outside\n",
      "           house             hous             hous            house\n",
      "          nearly           nearli             near           nearly\n",
      "         killing             kill             kill          killing\n",
      "           named             name             name            named\n",
      "      remembered           rememb           rememb       remembered\n",
      "        failings             fail             fail          failing\n",
      "         ushered            usher            usher          ushered\n",
      "         century          centuri          centuri          century\n",
      "         elapsed            elaps            elaps          elapsed\n",
      "  contradictions       contradict       contradict    contradiction\n",
      "        scrutiny         scrutini         scrutini         scrutiny\n",
      "         surface           surfac           surfac          surface\n",
      "         largely             larg             larg          largely\n",
      "          united             unit             unit           united\n",
      "         poverty          poverti          poverti          poverty\n",
      "         hundred            hundr            hundr          hundred\n",
      "        possible          possibl          possibl         possible\n",
      "         country          countri          countri          country\n",
      "       different           differ           differ        different\n",
      "        thriving           thrive           thrive         thriving\n",
      "      immigrants           immigr           immigr        immigrant\n",
      "      innovating            innov            innov       innovating\n",
      "        dizzying            dizzi            dizzi         dizzying\n",
      "        bustling            bustl            bustl         bustling\n",
      "          cities             citi             citi             city\n",
      "            envy             envi             envi             envy\n",
      "         country          countri          countri          country\n",
      "       dominated            domin            domin        dominated\n",
      "     politically            polit            polit      politically\n",
      "        socially           social           social         socially\n",
      "    conservative          conserv          conserv     conservative\n",
      "        dismayed           dismay           dismay         dismayed\n",
      "     prohibition         prohibit         prohibit      prohibition\n",
      "         another            anoth            anoth          another\n",
      "     achievement           achiev           achiev      achievement\n",
      "        'neither         'neither          neither         'neither\n",
      "        monopoly         monopoli         monopoli         monopoly\n",
      "          virtue            virtu            virtu           virtue\n",
      "        produced           produc           produc         produced\n",
      "       political            polit            polit        political\n",
      "       rascality           rascal           rascal        rascality\n",
      "         various           variou          various          various\n",
      "          guises             guis             guis            guise\n",
      "         another            anoth            anoth          another\n",
      "         feature           featur           featur          feature\n",
      "   entertainment        entertain        entertain    entertainment\n",
      "        dominate            domin            domin         dominate\n",
      "       attention           attent           attent        attention\n",
      "       demanding           demand           demand        demanding\n",
      "         measure           measur           measur          measure\n",
      "            many             mani             mani             many\n",
      "     accelerated          acceler          acceler      accelerated\n",
      "       advancing           advanc           advanc        advancing\n",
      "   communication           commun         communic    communication\n",
      "           using              use              use            using\n",
      "        mobilize            mobil            mobil         mobilize\n",
      "        military         militari         militari         military\n",
      "   communication           commun         communic    communication\n",
      "       affecting           affect           affect        affecting\n",
      "           alike             alik             alik            alike\n",
      "           movie             movi             movi            movie\n",
      "         palaces            palac            palac           palace\n",
      "       continued          continu          continu        continued\n",
      "           apace             apac             apac            apace\n",
      "         factory          factori          factori          factory\n",
      "         'sports           'sport            sport          'sports\n",
      "        business             busi             busi         business\n",
      "            able              abl              abl             able\n",
      "         outcome           outcom           outcom          outcome\n",
      "          series             seri             seri           series\n",
      "        affected           affect           affect         affected\n",
      "          traded            trade            trade           traded\n",
      "         yankees            yanke            yanke           yankee\n",
      "         invoked            invok            invok          invoked\n",
      "           curse             curs             curs            curse\n",
      "         another            anoth            anoth          another\n",
      "          series             seri             seri           series\n",
      "            'the             'the              the             'the\n",
      "          divide            divid            divid           divide\n",
      "       moderated            moder            moder        moderated\n",
      "         another            anoth            anoth          another\n",
      "     automobiles        automobil        automobil       automobile\n",
      "          nearly           nearli             near           nearly\n",
      "         doubled            doubl            doubl          doubled\n",
      "         happily          happili          happili          happily\n",
      "        returned           return           return         returned\n",
      "         leisure           leisur           leisur          leisure\n",
      "        expanded           expand           expand         expanded\n",
      "           every            everi            everi            every\n",
      "           sense             sens             sens            sense\n",
      "            able              abl              abl             able\n",
      "         vehicle           vehicl           vehicl          vehicle\n",
      "    'fortunately          'fortun           fortun     'fortunately\n",
      "        crackups          crackup          crackup         crackups\n",
      "        resulted           result           result         resulted\n",
      "           'soon            'soon             soon            'soon\n",
      "        changing            chang            chang         changing\n",
      "      everything          everyth          everyth       everything\n",
      "         bloomed            bloom            bloom          bloomed\n",
      "          cities             citi             citi             city\n",
      "         joining             join             join          joining\n",
      "          create            creat            creat           create\n",
      "       something           someth           someth        something\n",
      "           quite             quit             quit            quite\n",
      "      accidental         accident         accident       accidental\n",
      "     significant         signific         signific      significant\n",
      "      production          product          product       production\n",
      "           heavy            heavi            heavi            heavy\n",
      "        emphasis          emphasi          emphasi         emphasis\n",
      "        machines           machin           machin          machine\n",
      "       airplanes          airplan          airplan         airplane\n",
      "            used              use              use             used\n",
      "        internal           intern           intern         internal\n",
      "      combustion          combust          combust       combustion\n",
      "         engines            engin            engin           engine\n",
      "        embraced           embrac           embrac         embraced\n",
      "      automobile        automobil        automobil       automobile\n",
      "            else              els              els             else\n",
      " experimentation       experiment       experiment  experimentation\n",
      "   steam-powered        steam-pow        steam-pow    steam-powered\n",
      "        electric           electr           electr         electric\n",
      "        vehicles           vehicl           vehicl          vehicle\n",
      "           waned             wane             wane            waned\n",
      "             'to              'to               to              'to\n",
      "   all-important       all-import       all-import    all-important\n",
      "         vehicle           vehicl           vehicl          vehicle\n",
      "         changed            chang            chang          changed\n",
      "         country          countri          countri          country\n",
      "         forever            forev            forev          forever\n",
      "         promote           promot           promot          promote\n",
      "      interstate          interst          interst       interstate\n",
      "        military         militari         militari         military\n",
      "            july             juli             juli             july\n",
      "          called             call             call           called\n",
      "     aggregation           aggreg           aggreg      aggregation\n",
      "        vehicles           vehicl           vehicl          vehicle\n",
      "         started            start            start          started\n",
      "            'but             'but              but             'but\n",
      "      repeatedly       repeatedli           repeat       repeatedly\n",
      "     destination           destin           destin      destination\n",
      "        averaged           averag           averag         averaged\n",
      "          turned             turn             turn           turned\n",
      "           paved             pave             pave            paved\n",
      "        illinois          illinoi          illinoi         illinois\n",
      "         decades            decad            decad           decade\n",
      "         officer            offic            offic          officer\n",
      "      eisenhower         eisenhow         eisenhow       eisenhower\n",
      "        national           nation           nation         national\n",
      "       president           presid           presid        president\n",
      " well-publicized      well-public      well-public  well-publicized\n",
      "          divide            divid            divid           divide\n",
      "       generally            gener          general        generally\n",
      "         another            anoth            anoth          another\n",
      "      unexpected         unexpect         unexpect       unexpected\n",
      "         pivotal            pivot            pivot          pivotal\n",
      "             'in              'in               in              'in\n",
      "      overquoted         overquot         overquot       overquoted\n",
      "           yeats             yeat             yeat            yeats\n",
      "         another            anoth            anoth          another\n",
      "         divided            divid            divid          divided\n",
      "         history          histori          histori          history\n",
      "          seeing              see              see           seeing\n",
      " prognosticators         prognost         prognost   prognosticator\n",
      "        studying            studi            studi         studying\n",
      "          failed             fail             fail           failed\n",
      "         perhaps           perhap           perhap          perhaps\n",
      "CPU times: user 10.5 ms, sys: 5.37 ms, total: 15.9 ms\n",
      "Wall time: 11.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Print the stemmed and lemmatized words from the first document\n",
    "print(\"%16s %16s %16s %16s\" % (\"word\", \"porter\", \"snowball\", \"lemmatizer\"))\n",
    "for i in range(min(len(docs_porter[0]), len(docs_snowball[0]), len(docs_wordnet[0]))):\n",
    "    p, s, w = docs_porter[0][i], docs_snowball[0][i], docs_wordnet[0][i]\n",
    "    if len(set((p, s, w))) != 1:\n",
    "        print(\"%16s %16s %16s %16s\" % (docs[0][i], p, s, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
