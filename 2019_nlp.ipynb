{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Pipeline \n",
    "\n",
    "![](images/pipeline-walkthrough1.png)\n",
    "\n",
    "Below is a to do list when converting text into vector form: \n",
    "\n",
    "**Clean text and Create a Bag of Words (BoW)**\n",
    ">1. Lowercase the text\n",
    "2. Tokenize \n",
    "3. Strip out punctuation or undesirable text\n",
    "4. Remove Stopwords \n",
    "5. Stemming or Lemmatizing\n",
    "6. Compute N-Grams\n",
    "7. Use this to create BoW\n",
    "\n",
    "**Vectorize BoW**\n",
    ">8. Term Frequencies\n",
    "9. Document Frequencies\n",
    "10. TF-IDF\n",
    "11. Normalize vectors\n",
    "\n",
    "Let's go through both what each of these steps are and how to do them in python with the following corpus of comments about data science...\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion to cut off extra intro paragraphs from beautiful soup scrape\n",
    "\n",
    "# def trim_fat(string):\n",
    "#     return string[35:-115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to vectorize the type_of_material series into a y target vector.\n",
    "def vectorize_type(ser):\n",
    "    y = ser.copy()\n",
    "    y.replace({'Op-Ed': 1,'News': 0}, inplace=True)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rate of correct predictions out of total predictions\n",
    "def metrics_(tn, fp, fn, tp):\n",
    "    accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "    print(f'accuracy = {accuracy}')\n",
    "    recall = (tp) / (tp + fn)\n",
    "    print(f'recall = {recall}')\n",
    "    precision = (tp) / (tp + fp)\n",
    "    print(f'precision = {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.46 s, sys: 265 ms, total: 1.73 s\n",
      "Wall time: 1.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_2019 = pd.read_csv('data/drop2019_text_type.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 884 µs, sys: 258 µs, total: 1.14 ms\n",
      "Wall time: 1.22 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_2019_df = _2019.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X. X is currently pandas series of unsplit strings\n",
    "\n",
    "X = _2019_df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define y as a series of op-ed or news\n",
    "\n",
    "y = _2019_df.type_of_material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 ms, sys: 1.81 ms, total: 12.3 ms\n",
      "Wall time: 11.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# vectorize y in to (1, 0) (op-ed, news)\n",
    "\n",
    "y = vectorize_type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn series into list...\n",
    "\n",
    "corpus = list(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn TfidfVectorizer(stop_words='english', strip_accents='ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #create vectorizer\n",
    "\n",
    "# vectorizer = TfidfVectorizer(#input='content', \n",
    "# #                 encoding='utf-8', \n",
    "# #                 decode_error='strict', \n",
    "#                  strip_accents=None, \n",
    "#                  lowercase=True, \n",
    "# #                 preprocessor=None, \n",
    "# #                 tokenizer=None, \n",
    "# #                 analyzer='word', \n",
    "#                  stop_words='english', \n",
    "# #                 token_pattern='(?u)\\b\\w\\w+\\b', \n",
    "# #                 ngram_range=(1, 1), \n",
    "# #                 max_df=1.0, \n",
    "# #                 min_df=1, \n",
    "#                  max_features=None, \n",
    "# #                 vocabulary=None, \n",
    "# #                 binary=False, \n",
    "# #                 dtype=<class 'numpy.float64'>, \n",
    "# #                 norm='l2', \n",
    "# #                 use_idf=True, \n",
    "# #                 smooth_idf=True, \n",
    "# #                 sublinear_tf=False\n",
    "# )\n",
    "# X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# stop_words = vectorizer.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_names;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resample class size w/ imbalanced learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #balance the classes\n",
    "\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# rus = RandomUnderSampler(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #X, y --> X_resampled, y_resampled\n",
    "# X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "\n",
    "# #return a list of tuples for item, and count of item. in this case 4139 each\n",
    "# print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #test, train, split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes/imbalanced learn/TFIDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# multinm_clf = MultinomialNB()\n",
    "# multinm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multinm_clf.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = multinm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #clf.score = accuracy = 'true'(pos/neg) / total\n",
    "\n",
    "# multinm_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix(y_true = y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tn, fp, fn, tp = confusion_matrix(y_true = y_test, y_pred = y_pred).ravel()\n",
    "# (tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "\n",
    "# accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # rate of actual op-ed articles, out of all the actual od-ed articles\n",
    "\n",
    "# recall = (tp) / (tp + fn)\n",
    "# recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rate of correct predictions of op-ed articles out of all predictions\n",
    "\n",
    "# precision = (tp) / (tp + fp)\n",
    "# precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "\n",
    "# accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "# print(f'accuracy = {accuracy}')\n",
    "# recall = (tp) / (tp + fn)\n",
    "# print(f'recall = {recall}')\n",
    "# precision = (tp) / (tp + fp)\n",
    "# print(f'precision = {precision}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class sklearn.ensemble.RandomForestClassifier(n_estimators=100, \n",
    "#                                               *, \n",
    "#                                               criterion='gini', \n",
    "#                                               max_depth=None, \n",
    "#                                               min_samples_split=2, \n",
    "#                                               min_samples_leaf=1, \n",
    "#                                               min_weight_fraction_leaf=0.0, \n",
    "#                                               max_features='auto', \n",
    "#                                               max_leaf_nodes=None, \n",
    "#                                               min_impurity_decrease=0.0, \n",
    "#                                               min_impurity_split=None, \n",
    "#                                               bootstrap=True, \n",
    "#                                               oob_score=False, \n",
    "#                                               n_jobs=None, \n",
    "#                                               random_state=None, \n",
    "#                                               verbose=0, \n",
    "#                                               warm_start=False, \n",
    "#                                               class_weight=None, \n",
    "#                                               ccp_alpha=0.0, \n",
    "#                                               max_samples=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# rf_clf = RandomForestClassifier(max_depth=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #clf.score = accuracy = 'true'(pos/neg) / total\n",
    "\n",
    "# rf_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix(y_true = y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tn, fp, fn, tp = confusion_matrix(y_true = y_test, y_pred = y_pred).ravel()\n",
    "# (tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "\n",
    "# accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rate of actual op-ed articles, out of all the actual od-ed articles\n",
    "\n",
    "# recall = (tp) / (tp + fn)\n",
    "# recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rate of correct predictions of op-ed articles out of all predictions\n",
    "\n",
    "# precision = (tp) / (tp + fp)\n",
    "# precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "\n",
    "# accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "# print(f'accuracy = {accuracy}')\n",
    "# recall = (tp) / (tp + fn)\n",
    "# print(f'recall = {recall}')\n",
    "# precision = (tp) / (tp + fp)\n",
    "# print(f'precision = {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class sklearn.ensemble.RandomForestClassifier(n_estimators=100, \n",
    "#                                               *, \n",
    "#                                               criterion='gini', \n",
    "#                                               max_depth=None, \n",
    "#                                               min_samples_split=2, \n",
    "#                                               min_samples_leaf=1, \n",
    "#                                               min_weight_fraction_leaf=0.0, \n",
    "#                                               max_features='auto', \n",
    "#                                               max_leaf_nodes=None, \n",
    "#                                               min_impurity_decrease=0.0, \n",
    "#                                               min_impurity_split=None, \n",
    "#                                               bootstrap=True, \n",
    "#                                               oob_score=False, \n",
    "#                                               n_jobs=None, \n",
    "#                                               random_state=None, \n",
    "#                                               verbose=0, \n",
    "#                                               warm_start=False, \n",
    "#                                               class_weight=None, \n",
    "#                                               ccp_alpha=0.0, \n",
    "#                                               max_samples=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_2019_df = _2019.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X. X is currently pandas series of unsplit strings\n",
    "\n",
    "X_nltk = nltk_2019_df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define y as a series of op-ed or news\n",
    "\n",
    "y_nktk = nltk_2019_df.type_of_material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 ms, sys: 1.9 ms, total: 13.8 ms\n",
      "Wall time: 12.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# vectorize y in to (1, 0) (op-ed, news)\n",
    "\n",
    "y_nltk = vectorize_type(y_nktk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn series into list...\n",
    "\n",
    "corpus_nltk = list(X_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenize w/ nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from nltk.tokenize import RegexpTokenizer\n",
    "# regex_tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "# tokenized_punc = [regex_tokenizer.tokenize(article.lower())for article in corpus_nltk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (len(tokenized_punc[0])) #2218"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(tokenized_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# tokenized = [word_tokenize(article.lower()) for article in corpus_nltk]\n",
    "\n",
    "# CPU times: user 4min 46s, sys: 2.39 s, total: 4min 48s\n",
    "# Wall time: 4min 50s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #list of list of strings. one list of strings per documents. list are various lengths around 1000\n",
    "\n",
    "# len(tokenized[0]) #2596"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## take out stop work via ntlk. does this work against sklearn when i vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# stop = set(stopwords.words('english'))\n",
    "# tokenized_docs = [[word for word in words if word not in stop]\n",
    "#             for words in tokenized_punc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #hopefully this reduced the number of strings / list\n",
    "\n",
    "# len(tokenized[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #docs is new tokenized, but with stop words removed\n",
    "\n",
    "# len(tokenized_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stemming/lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# porter = PorterStemmer()\n",
    "snowball = SnowballStemmer('english')\n",
    "# wordnet = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# docs_porter = [[porter.stem(word) for word in words]\n",
    "#                    for words in docs]\n",
    "# docs_snowball = [[snowball.stem(word) for word in words]\n",
    "#                      for words in docs]\n",
    "# docs_wordnet = [[wordnet.lemmatize(word) for word in words]\n",
    "#                     for words in docs]\n",
    "\n",
    "# CPU times: user 14min 59s, sys: 18.4 s, total: 15min 18s\n",
    "# Wall time: 15min 26s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# docs_porter = [[porter.stem(word) for word in words]\n",
    "#                    for words in docs]\n",
    "\n",
    "# CPU times: user 7min 16s, sys: 5.21 s, total: 7min 21s\n",
    "# Wall time: 7min 22s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# snowball_stemm = [[snowball.stem(word) for word in words]\n",
    "#                      for words in tokenized_docs]\n",
    "\n",
    "# # CPU times: user 5min 5s, sys: 5.98 s, total: 5min 11s\n",
    "# # Wall time: 5min 13s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# docs_wordnet = [[wordnet.lemmatize(word) for word in words]\n",
    "#                     for words in docs]\n",
    "\n",
    "# CPU times: user 1min 24s, sys: 4.5 s, total: 1min 28s\n",
    "# Wall time: 1min 30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# ## Print the stemmed and lemmatized words from the first document\n",
    "# print(\"%16s %16s %16s %16s\" % (\"word\", \"porter\", \"snowball\", \"lemmatizer\"))\n",
    "# for i in range(min(len(docs_porter[0]), len(docs_snowball[0]), len(docs_wordnet[0]))):\n",
    "#     p, s, w = docs_porter[0][i], docs_snowball[0][i], docs_wordnet[0][i]\n",
    "#     if len(set((p, s, w))) != 1:\n",
    "#         print(\"%16s %16s %16s %16s\" % (docs[0][i], p, s, w))\n",
    "#         print(docs[0][i], w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs and lemmatizer are the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I choose SNOWBALL!!!! to sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus_nltk[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snowball = SnowballStemmer('english')\n",
    "# snowball_tokenized = [snowball.stem(word) for word in word_tokenize(doc.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 µs, sys: 0 ns, total: 16 µs\n",
      "Wall time: 20.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def snowball_tokenize(doc):\n",
    "    snowball = SnowballStemmer('english')\n",
    "    return [snowball.stem(word) for word in word_tokenize(doc.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37 µs, sys: 0 ns, total: 37 µs\n",
      "Wall time: 40.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#create vectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(#input='content', \n",
    "#                 encoding='utf-8', \n",
    "#                 decode_error='strict', \n",
    "                 strip_accents='ascii', \n",
    "                 lowercase=True, \n",
    "#                 preprocessor=None, \n",
    "                 tokenizer=snowball_tokenize, \n",
    "#                 analyzer='word', \n",
    "                 stop_words='english', \n",
    "#                 token_pattern='(?u)\\b\\w\\w+\\b', \n",
    "#                 ngram_range=(1, 1), \n",
    "#                 max_df=1.0, \n",
    "#                 min_df=1, \n",
    "                 max_features=None, \n",
    "#                 vocabulary=None, \n",
    "#                 binary=False, \n",
    "#                 dtype=<class 'numpy.float64'>, \n",
    "#                 norm='l2', \n",
    "#                 use_idf=True, \n",
    "#                 smooth_idf=True, \n",
    "#                 sublinear_tf=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 47s, sys: 7.02 s, total: 10min 54s\n",
      "Wall time: 11min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_snowball = vectorizer.fit_transform(corpus_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class sklearn.feature_extraction.text.CountVectorizer(*, \n",
    "#                                                       input='content', \n",
    "#                                                       encoding='utf-8', \n",
    "#                                                       decode_error='strict', \n",
    "#                                                       strip_accents=None, \n",
    "#                                                       lowercase=True, \n",
    "#                                                       preprocessor=None, \n",
    "#                                                       tokenizer=None, \n",
    "#                                                       stop_words=None, \n",
    "#                                                       token_pattern='(?u)\\b\\w\\w+\\b', \n",
    "#                                                       ngram_range=(1, 1), \n",
    "#                                                       analyzer='word', \n",
    "#                                                       max_df=1.0, \n",
    "#                                                       min_df=1, \n",
    "#                                                       max_features=None, \n",
    "#                                                       vocabulary=None, \n",
    "#                                                       binary=False, \n",
    "#                                                       dtype=<class 'numpy.int64'>\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(strip_accents='None',\n",
    "                                   lowercase=True,\n",
    "                                   tokenizer=snowball_tokenize,\n",
    "                                   stop_words='english',\n",
    "                                   max_features=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# balance classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31 µs, sys: 18 µs, total: 49 µs\n",
      "Wall time: 52.9 µs\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# #balance the classes\n",
    "\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# rus = RandomUnderSampler(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 3957), (1, 3957)]\n",
      "CPU times: user 19.8 ms, sys: 11.8 ms, total: 31.6 ms\n",
      "Wall time: 30.7 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# #X, y --> X_resampled, y_resampled\n",
    "# X_resampled, y_resampled = rus.fit_resample(X_snowball, y_nltk)\n",
    "# print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.6 ms, sys: 11.3 ms, total: 25.9 ms\n",
      "Wall time: 25.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#test, train, split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# rf_clf = RandomForestClassifier(max_depth=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #clf.score = accuracy = 'true'(pos/neg) / total\n",
    "\n",
    "# rf_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tn, fp, fn, tp = confusion_matrix(y_true = y_test, y_pred = y_pred).ravel()\n",
    "# (tn, fp, fn, tp)\n",
    "# metrics_(tn, fp, fn, tp)\n",
    "# print(f'tn={tn}, fp={fp}, fn={fn}, tp={tp})')\n",
    "# print(rf_clf.n_features_)\n",
    "# print(rf_clf.n_classes_)\n",
    "# print(rf_clf.n_outputs_)\n",
    "# # what are the actual parametrs set in the function. something specific about the random forest i forgot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stop = vectorizer.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nltk_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37728, 234816)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_snowball.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_import = rf_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property feature_importances_\n",
    "# The impurity-based feature importances.\n",
    "\n",
    "# The higher, the more important the feature. The importance of a feature is computed as the (normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance.\n",
    "\n",
    "# Warning: impurity-based feature importances can be misleading for high cardinality features (many unique values). See sklearn.inspection.permutation_importance as an alternative.\n",
    "\n",
    "# Returns\n",
    "# feature_importances_ndarray of shape (n_features,)\n",
    "# The values of this array sum to 1, unless all trees are single node trees consisting of only the root node, in which case it will be an array of zeros.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_scores = pd.Series(feature_import,\n",
    "#                            index=nltk_features)\n",
    "# feat_scores = feat_scores.sort_values()\n",
    "# ax = feat_scores.plot(kind='barh', figsize=(10,20))\n",
    "# ax.set_title('\"Decrease in Impurity\" Importance')\n",
    "# ax.set_xlabel('Average contribution to the reduction in variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = permutation_importance(rf_clf, X_test, y_test, n_repeats=30, random_state=0)\n",
    "# for index in r.importances_mean.argsort()[::-1]:\n",
    "#     if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "#         print(f\"{feature_names[i]:<8}\"\n",
    "#               f\"{r.importances_mean[i]:.3f}\"\n",
    "#               f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# test_x = test_vectorizer.fit_transform(corpus_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 3957), (1, 3957)]\n",
      "CPU times: user 21.3 ms, sys: 11.6 ms, total: 32.9 ms\n",
      "Wall time: 32.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#balance the classes\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "\n",
    "#X, y --> X_resampled, y_resampled\n",
    "X_resampled, y_resampled = rus.fit_resample(X_snowball, y_nltk)\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.39 ms, sys: 3.44 ms, total: 12.8 ms\n",
      "Wall time: 11.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#test, train, split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 663 ms, sys: 17.5 ms, total: 680 ms\n",
      "Wall time: 687 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tn, fp, fn, tp = confusion_matrix(y_true = y_test, y_pred = y_pred).ravel()\n",
    "(tn, fp, fn, tp)\n",
    "metrics_(tn, fp, fn, tp)\n",
    "print(f'tn={tn}, fp={fp}, fn={fn}, tp={tp})')\n",
    "print(rf_clf.n_features_)\n",
    "print(rf_clf.n_classes_)\n",
    "print(rf_clf.n_outputs_)\n",
    "feat_names = vectorizer.get_feature_names()\n",
    "print(len(feat_names))\n",
    "feature_import = rf_clf.feature_importances_\n",
    "print(type(feature_import))\n",
    "feature_import.shape\n",
    "# what are the actual parametrs set in the function. something specific about the random forest i forgot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feature_import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1979, 234816)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1979,)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_scores = pd.Series(feature_import[:20],\n",
    "                           index=feat_names[:20])\n",
    "feat_scores = feat_scores.sort_values()\n",
    "ax = feat_scores.plot(kind='barh', figsize=(10,20))\n",
    "ax.set_title('\"Decrease in Impurity\" Importance')\n",
    "ax.set_xlabel('Average contribution to the reduction in variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r = permutation_importance(rf_clf, X_test.toarray(), y_test, n_repeats=30, random_state=0)\n",
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "        print(f\"{feat_names[i]:<8}\"\n",
    "              f\"{r.importances_mean[i]:.3f}\"\n",
    "              f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
