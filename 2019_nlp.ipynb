{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Pipeline \n",
    "\n",
    "![](images/pipeline-walkthrough1.png)\n",
    "\n",
    "Below is a to do list when converting text into vector form: \n",
    "\n",
    "**Clean text and Create a Bag of Words (BoW)**\n",
    ">1. Lowercase the text\n",
    "2. Tokenize \n",
    "3. Strip out punctuation or undesirable text\n",
    "4. Remove Stopwords \n",
    "5. Stemming or Lemmatizing\n",
    "6. Compute N-Grams\n",
    "7. Use this to create BoW\n",
    "\n",
    "**Vectorize BoW**\n",
    ">8. Term Frequencies\n",
    "9. Document Frequencies\n",
    "10. TF-IDF\n",
    "11. Normalize vectors\n",
    "\n",
    "Let's go through both what each of these steps are and how to do them in python with the following corpus of comments about data science...\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion to cut off extra intro paragraphs from beautiful soup scrape\n",
    "\n",
    "# def trim_fat(string):\n",
    "#     return string[35:-115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to vectorize the type_of_material series into a y target vector.\n",
    "def vectorize_type(ser):\n",
    "    y = ser.copy()\n",
    "    y.replace({'Op-Ed': 1,'News': 0}, inplace=True)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rate of correct predictions out of total predictions\n",
    "def metrics_(tn, fp, fn, tp):\n",
    "    accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "    print(f'accuracy = {accuracy}')\n",
    "    recall = (tp) / (tp + fn)\n",
    "    print(f'recall = {recall}')\n",
    "    precision = (tp) / (tp + fp)\n",
    "    print(f'precision = {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.65 s, sys: 311 ms, total: 1.96 s\n",
      "Wall time: 1.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_2019 = pd.read_csv('data/trim2019_text_type.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 798 µs, sys: 16 µs, total: 814 µs\n",
      "Wall time: 852 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_2019_df = _2019.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X. X is currently pandas series of unsplit strings\n",
    "\n",
    "X = _2019_df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define y as a series of op-ed or news\n",
    "\n",
    "y = _2019_df.type_of_material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 ms, sys: 6.08 ms, total: 16.4 ms\n",
      "Wall time: 15.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# vectorize y in to (1, 0) (op-ed, news)\n",
    "\n",
    "y = vectorize_type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn series into list...\n",
    "\n",
    "corpus = list(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn TfidfVectorizer(stop_words='english', strip_accents='ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #create vectorizer\n",
    "\n",
    "# vectorizer = TfidfVectorizer(#input='content', \n",
    "# #                 encoding='utf-8', \n",
    "# #                 decode_error='strict', \n",
    "#                  strip_accents=None, \n",
    "#                  lowercase=True, \n",
    "# #                 preprocessor=None, \n",
    "# #                 tokenizer=None, \n",
    "# #                 analyzer='word', \n",
    "#                  stop_words='english', \n",
    "# #                 token_pattern='(?u)\\b\\w\\w+\\b', \n",
    "# #                 ngram_range=(1, 1), \n",
    "# #                 max_df=1.0, \n",
    "# #                 min_df=1, \n",
    "#                  max_features=None, \n",
    "# #                 vocabulary=None, \n",
    "# #                 binary=False, \n",
    "# #                 dtype=<class 'numpy.float64'>, \n",
    "# #                 norm='l2', \n",
    "# #                 use_idf=True, \n",
    "# #                 smooth_idf=True, \n",
    "# #                 sublinear_tf=False\n",
    "# )\n",
    "# X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# stop_words = vectorizer.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_names;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resample class size w/ imbalanced learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #balance the classes\n",
    "\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# rus = RandomUnderSampler(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #X, y --> X_resampled, y_resampled\n",
    "# X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "\n",
    "# #return a list of tuples for item, and count of item. in this case 4139 each\n",
    "# print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #test, train, split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes/imbalanced learn/TFIDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# multinm_clf = MultinomialNB()\n",
    "# multinm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multinm_clf.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = multinm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #clf.score = accuracy = 'true'(pos/neg) / total\n",
    "\n",
    "# multinm_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix(y_true = y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tn, fp, fn, tp = confusion_matrix(y_true = y_test, y_pred = y_pred).ravel()\n",
    "# (tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "\n",
    "# accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # rate of actual op-ed articles, out of all the actual od-ed articles\n",
    "\n",
    "# recall = (tp) / (tp + fn)\n",
    "# recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rate of correct predictions of op-ed articles out of all predictions\n",
    "\n",
    "# precision = (tp) / (tp + fp)\n",
    "# precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "\n",
    "# accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "# print(f'accuracy = {accuracy}')\n",
    "# recall = (tp) / (tp + fn)\n",
    "# print(f'recall = {recall}')\n",
    "# precision = (tp) / (tp + fp)\n",
    "# print(f'precision = {precision}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class sklearn.ensemble.RandomForestClassifier(n_estimators=100, \n",
    "#                                               *, \n",
    "#                                               criterion='gini', \n",
    "#                                               max_depth=None, \n",
    "#                                               min_samples_split=2, \n",
    "#                                               min_samples_leaf=1, \n",
    "#                                               min_weight_fraction_leaf=0.0, \n",
    "#                                               max_features='auto', \n",
    "#                                               max_leaf_nodes=None, \n",
    "#                                               min_impurity_decrease=0.0, \n",
    "#                                               min_impurity_split=None, \n",
    "#                                               bootstrap=True, \n",
    "#                                               oob_score=False, \n",
    "#                                               n_jobs=None, \n",
    "#                                               random_state=None, \n",
    "#                                               verbose=0, \n",
    "#                                               warm_start=False, \n",
    "#                                               class_weight=None, \n",
    "#                                               ccp_alpha=0.0, \n",
    "#                                               max_samples=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# rf_clf = RandomForestClassifier(max_depth=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #clf.score = accuracy = 'true'(pos/neg) / total\n",
    "\n",
    "# rf_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix(y_true = y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tn, fp, fn, tp = confusion_matrix(y_true = y_test, y_pred = y_pred).ravel()\n",
    "# (tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "\n",
    "# accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rate of actual op-ed articles, out of all the actual od-ed articles\n",
    "\n",
    "# recall = (tp) / (tp + fn)\n",
    "# recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rate of correct predictions of op-ed articles out of all predictions\n",
    "\n",
    "# precision = (tp) / (tp + fp)\n",
    "# precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "\n",
    "# accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "# print(f'accuracy = {accuracy}')\n",
    "# recall = (tp) / (tp + fn)\n",
    "# print(f'recall = {recall}')\n",
    "# precision = (tp) / (tp + fp)\n",
    "# print(f'precision = {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class sklearn.ensemble.RandomForestClassifier(n_estimators=100, \n",
    "#                                               *, \n",
    "#                                               criterion='gini', \n",
    "#                                               max_depth=None, \n",
    "#                                               min_samples_split=2, \n",
    "#                                               min_samples_leaf=1, \n",
    "#                                               min_weight_fraction_leaf=0.0, \n",
    "#                                               max_features='auto', \n",
    "#                                               max_leaf_nodes=None, \n",
    "#                                               min_impurity_decrease=0.0, \n",
    "#                                               min_impurity_split=None, \n",
    "#                                               bootstrap=True, \n",
    "#                                               oob_score=False, \n",
    "#                                               n_jobs=None, \n",
    "#                                               random_state=None, \n",
    "#                                               verbose=0, \n",
    "#                                               warm_start=False, \n",
    "#                                               class_weight=None, \n",
    "#                                               ccp_alpha=0.0, \n",
    "#                                               max_samples=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_2019_df = _2019.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X. X is currently pandas series of unsplit strings\n",
    "\n",
    "X_nltk = nltk_2019_df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define y as a series of op-ed or news\n",
    "\n",
    "y_nktk = nltk_2019_df.type_of_material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 ms, sys: 1.43 ms, total: 12.7 ms\n",
      "Wall time: 11.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# vectorize y in to (1, 0) (op-ed, news)\n",
    "\n",
    "y_nltk = vectorize_type(y_nktk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn series into list...\n",
    "\n",
    "corpus_nltk = list(X_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenize w/ nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from nltk.tokenize import RegexpTokenizer\n",
    "# regex_tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "# tokenized_punc = [regex_tokenizer.tokenize(article.lower())for article in corpus_nltk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (len(tokenized_punc[0])) #2218"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(tokenized_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# tokenized = [word_tokenize(article.lower()) for article in corpus_nltk]\n",
    "\n",
    "# CPU times: user 4min 46s, sys: 2.39 s, total: 4min 48s\n",
    "# Wall time: 4min 50s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #list of list of strings. one list of strings per documents. list are various lengths around 1000\n",
    "\n",
    "# len(tokenized[0]) #2596"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## take out stop work via ntlk. does this work against sklearn when i vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_punc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenized_punc' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stop = set(stopwords.words('english'))\n",
    "tokenized_docs = [[word for word in words if word not in stop]\n",
    "            for words in tokenized_punc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #hopefully this reduced the number of strings / list\n",
    "\n",
    "# len(tokenized[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #docs is new tokenized, but with stop words removed\n",
    "\n",
    "# len(tokenized_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stemming/lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# porter = PorterStemmer()\n",
    "snowball = SnowballStemmer('english')\n",
    "# wordnet = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# docs_porter = [[porter.stem(word) for word in words]\n",
    "#                    for words in docs]\n",
    "# docs_snowball = [[snowball.stem(word) for word in words]\n",
    "#                      for words in docs]\n",
    "# docs_wordnet = [[wordnet.lemmatize(word) for word in words]\n",
    "#                     for words in docs]\n",
    "\n",
    "# CPU times: user 14min 59s, sys: 18.4 s, total: 15min 18s\n",
    "# Wall time: 15min 26s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# docs_porter = [[porter.stem(word) for word in words]\n",
    "#                    for words in docs]\n",
    "\n",
    "# CPU times: user 7min 16s, sys: 5.21 s, total: 7min 21s\n",
    "# Wall time: 7min 22s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# snowball_stemm = [[snowball.stem(word) for word in words]\n",
    "#                      for words in tokenized_docs]\n",
    "\n",
    "# # CPU times: user 5min 5s, sys: 5.98 s, total: 5min 11s\n",
    "# # Wall time: 5min 13s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# docs_wordnet = [[wordnet.lemmatize(word) for word in words]\n",
    "#                     for words in docs]\n",
    "\n",
    "# CPU times: user 1min 24s, sys: 4.5 s, total: 1min 28s\n",
    "# Wall time: 1min 30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# ## Print the stemmed and lemmatized words from the first document\n",
    "# print(\"%16s %16s %16s %16s\" % (\"word\", \"porter\", \"snowball\", \"lemmatizer\"))\n",
    "# for i in range(min(len(docs_porter[0]), len(docs_snowball[0]), len(docs_wordnet[0]))):\n",
    "#     p, s, w = docs_porter[0][i], docs_snowball[0][i], docs_wordnet[0][i]\n",
    "#     if len(set((p, s, w))) != 1:\n",
    "#         print(\"%16s %16s %16s %16s\" % (docs[0][i], p, s, w))\n",
    "#         print(docs[0][i], w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs and lemmatizer are the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I choose SNOWBALL!!!! to sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus_nltk[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snowball = SnowballStemmer('english')\n",
    "# snowball_tokenized = [snowball.stem(word) for word in word_tokenize(doc.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 µs, sys: 0 ns, total: 11 µs\n",
      "Wall time: 14.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def snowball_tokenize(doc):\n",
    "    snowball = SnowballStemmer('english')\n",
    "    return [snowball.stem(word) for word in word_tokenize(doc.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38 µs, sys: 30 µs, total: 68 µs\n",
      "Wall time: 70.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#create vectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(#input='content', \n",
    "#                 encoding='utf-8', \n",
    "#                 decode_error='strict', \n",
    "                 strip_accents='ascii', \n",
    "                 lowercase=True, \n",
    "#                 preprocessor=None, \n",
    "                 tokenizer=snowball_tokenize, \n",
    "#                 analyzer='word', \n",
    "                 stop_words='english', \n",
    "#                 token_pattern='(?u)\\b\\w\\w+\\b', \n",
    "#                 ngram_range=(1, 1), \n",
    "#                 max_df=1.0, \n",
    "#                 min_df=1, \n",
    "                 max_features=None, \n",
    "#                 vocabulary=None, \n",
    "#                 binary=False, \n",
    "#                 dtype=<class 'numpy.float64'>, \n",
    "#                 norm='l2', \n",
    "#                 use_idf=True, \n",
    "#                 smooth_idf=True, \n",
    "#                 sublinear_tf=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 5s, sys: 7.11 s, total: 13min 12s\n",
      "Wall time: 13min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_snowball = vectorizer.fit(corpus_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 15s, sys: 7.39 s, total: 13min 23s\n",
      "Wall time: 13min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_snowball = X_snowball.transform(corpus_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class sklearn.feature_extraction.text.CountVectorizer(*, \n",
    "#                                                       input='content', \n",
    "#                                                       encoding='utf-8', \n",
    "#                                                       decode_error='strict', \n",
    "#                                                       strip_accents=None, \n",
    "#                                                       lowercase=True, \n",
    "#                                                       preprocessor=None, \n",
    "#                                                       tokenizer=None, \n",
    "#                                                       stop_words=None, \n",
    "#                                                       token_pattern='(?u)\\b\\w\\w+\\b', \n",
    "#                                                       ngram_range=(1, 1), \n",
    "#                                                       analyzer='word', \n",
    "#                                                       max_df=1.0, \n",
    "#                                                       min_df=1, \n",
    "#                                                       max_features=None, \n",
    "#                                                       vocabulary=None, \n",
    "#                                                       binary=False, \n",
    "#                                                       dtype=<class 'numpy.int64'>\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(strip_accents='None',\n",
    "                                   lowercase=True,\n",
    "                                   tokenizer=snowball_tokenize,\n",
    "                                   stop_words='english',\n",
    "                                   max_features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22 µs, sys: 0 ns, total: 22 µs\n",
      "Wall time: 25 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#balance the classes\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 4139), (1, 4139)]\n",
      "CPU times: user 25.3 ms, sys: 8.59 ms, total: 33.9 ms\n",
      "Wall time: 32.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#X, y --> X_resampled, y_resampled\n",
    "X_resampled, y_resampled = rus.fit_resample(X_snowball, y_nltk)\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.5 ms, sys: 8.72 ms, total: 20.2 ms\n",
      "Wall time: 18.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#test, train, split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40 µs, sys: 0 ns, total: 40 µs\n",
      "Wall time: 42 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_clf = RandomForestClassifier(max_depth=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 397 ms, sys: 28.7 ms, total: 425 ms\n",
      "Wall time: 427 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9304347826086956"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf.score = accuracy = 'true'(pos/neg) / total\n",
    "\n",
    "rf_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9304347826086956\n",
      "recall = 0.8942857142857142\n",
      "precision = 0.9660493827160493\n",
      "tn=987, fp=33, fn=111, tp=939)\n",
      "263494\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true = y_test, y_pred = y_pred).ravel()\n",
    "(tn, fp, fn, tp)\n",
    "metrics_(tn, fp, fn, tp)\n",
    "print(f'tn={tn}, fp={fp}, fn={fn}, tp={tp})')\n",
    "print(rf_clf.n_features_)\n",
    "print(rf_clf.n_classes_)\n",
    "print(rf_clf.n_outputs_)\n",
    "# what are the actual parametrs set in the function. something specific about the random forest i forgot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stop = vectorizer.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nltk_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41748, 263494)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_snowball.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the bag of words\n",
    "columns = nltk_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_import = rf_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property feature_importances_\n",
    "# The impurity-based feature importances.\n",
    "\n",
    "# The higher, the more important the feature. The importance of a feature is computed as the (normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance.\n",
    "\n",
    "# Warning: impurity-based feature importances can be misleading for high cardinality features (many unique values). See sklearn.inspection.permutation_importance as an alternative.\n",
    "\n",
    "# Returns\n",
    "# feature_importances_ndarray of shape (n_features,)\n",
    "# The values of this array sum to 1, unless all trees are single node trees consisting of only the root node, in which case it will be an array of zeros.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_scores = pd.Series(feature_import,\n",
    "#                            index=nltk_features)\n",
    "# feat_scores = feat_scores.sort_values()\n",
    "# ax = feat_scores.plot(kind='barh', figsize=(10,20))\n",
    "# ax.set_title('\"Decrease in Impurity\" Importance')\n",
    "# ax.set_xlabel('Average contribution to the reduction in variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = permutation_importance(rf_clf, X_test, y_test, n_repeats=30, random_state=0)\n",
    "# for index in r.importances_mean.argsort()[::-1]:\n",
    "#     if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "#         print(f\"{feature_names[i]:<8}\"\n",
    "#               f\"{r.importances_mean[i]:.3f}\"\n",
    "#               f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.6 ms, sys: 12.9 ms, total: 27.4 ms\n",
      "Wall time: 27.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#create vectorizer\n",
    "\n",
    "test_vectorizer = TfidfVectorizer(#input='content', \n",
    "#                 encoding='utf-8', \n",
    "#                 decode_error='strict', \n",
    "                 strip_accents='ascii', \n",
    "                 lowercase=True, \n",
    "#                 preprocessor=None, \n",
    "                 tokenizer=snowball_tokenize, \n",
    "#                 analyzer='word', \n",
    "                 stop_words='english', \n",
    "#                 token_pattern='(?u)\\b\\w\\w+\\b', \n",
    "#                 ngram_range=(1, 1), \n",
    "#                 max_df=1.0, \n",
    "#                 min_df=1, \n",
    "                 max_features=450, \n",
    "#                 vocabulary=None, \n",
    "#                 binary=False, \n",
    "#                 dtype=<class 'numpy.float64'>, \n",
    "#                 norm='l2', \n",
    "#                 use_idf=True, \n",
    "#                 smooth_idf=True, \n",
    "#                 sublinear_tf=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 55s, sys: 3.9 s, total: 12min 59s\n",
      "Wall time: 13min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_x = test_vectorizer.fit_transform(corpus_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 4139), (1, 4139)]\n",
      "CPU times: user 16.3 ms, sys: 9.15 ms, total: 25.4 ms\n",
      "Wall time: 24.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#balance the classes\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "\n",
    "#X, y --> X_resampled, y_resampled\n",
    "X_resampled, y_resampled = rus.fit_resample(test_x, y_nltk)\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.13 ms, sys: 4.64 ms, total: 10.8 ms\n",
      "Wall time: 9.45 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#test, train, split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 645 ms, sys: 14.2 ms, total: 659 ms\n",
      "Wall time: 662 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test450_rf_clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "test450_rf_clf.fit(X_train, y_train)\n",
    "test450_y_pred = test450_rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9304347826086956\n",
      "recall = 0.8942857142857142\n",
      "precision = 0.9660493827160493\n",
      "tn=987, fp=33, fn=111, tp=939)\n",
      "263494\n",
      "2\n",
      "1\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "CPU times: user 13.5 ms, sys: 2.98 ms, total: 16.5 ms\n",
      "Wall time: 14.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(450,)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tn, fp, fn, tp = confusion_matrix(y_true = y_test, y_pred = y_pred).ravel()\n",
    "(tn, fp, fn, tp)\n",
    "metrics_(tn, fp, fn, tp)\n",
    "print(f'tn={tn}, fp={fp}, fn={fn}, tp={tp})')\n",
    "print(rf_clf.n_features_)\n",
    "print(rf_clf.n_classes_)\n",
    "print(rf_clf.n_outputs_)\n",
    "test450_feat_names = test_vectorizer.get_feature_names()\n",
    "print(type(test450_feat_names))\n",
    "feature_import = test450_rf_clf.feature_importances_\n",
    "print(type(feature_import))\n",
    "feature_import.shape\n",
    "# what are the actual parametrs set in the function. something specific about the random forest i forgot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test450_feat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feature_import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2070, 450)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2070,)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_scores = pd.Series(feature_import,\n",
    "#                            index=test450_feat_names)\n",
    "# feat_scores = feat_scores.sort_values()\n",
    "# ax = feat_scores.plot(kind='barh', figsize=(10,20))\n",
    "# ax.set_title('\"Decrease in Impurity\" Importance')\n",
    "# ax.set_xlabel('Average contribution to the reduction in variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@       0.022 +/- 0.003\n",
      "facebook0.022 +/- 0.003\n",
      "twitter 0.006 +/- 0.001\n",
      "york    0.006 +/- 0.002\n",
      ")       0.005 +/- 0.002\n",
      "follow  0.004 +/- 0.001\n",
      "said    0.003 +/- 0.001\n",
      "polici  0.001 +/- 0.000\n",
      "data    0.000 +/- 0.000\n",
      "econom  0.000 +/- 0.000\n",
      "tuesday 0.000 +/- 0.000\n",
      "elect   0.000 +/- 0.000\n",
      "mean    0.000 +/- 0.000\n",
      "CPU times: user 4min 2s, sys: 3.99 s, total: 4min 6s\n",
      "Wall time: 4min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "r = permutation_importance(test450_rf_clf, X_test.toarray(), y_test, n_repeats=30, random_state=0)\n",
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "        print(f\"{test450_feat_names[i]:<8}\"\n",
    "              f\"{r.importances_mean[i]:.3f}\"\n",
    "              f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
