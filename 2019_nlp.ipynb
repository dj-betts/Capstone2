{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Pipeline \n",
    "\n",
    "![](images/pipeline-walkthrough1.png)\n",
    "\n",
    "Below is a to do list when converting text into vector form: \n",
    "\n",
    "**Clean text and Create a Bag of Words (BoW)**\n",
    ">1. Lowercase the text\n",
    "2. Tokenize \n",
    "3. Strip out punctuation or undesirable text\n",
    "4. Remove Stopwords \n",
    "5. Stemming or Lemmatizing\n",
    "6. Compute N-Grams\n",
    "7. Use this to create BoW\n",
    "\n",
    "**Vectorize BoW**\n",
    ">8. Term Frequencies\n",
    "9. Document Frequencies\n",
    "10. TF-IDF\n",
    "11. Normalize vectors\n",
    "\n",
    "Let's go through both what each of these steps are and how to do them in python with the following corpus of comments about data science...\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion to cut off extra intro paragraphs from beautiful soup scrape\n",
    "\n",
    "# def trim_fat(string):\n",
    "#     return string[35:-115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to vectorize the type_of_material series into a y target vector.\n",
    "def vectorize_type(ser):\n",
    "    y = ser.copy()\n",
    "    y.replace({'Op-Ed': 1,'News': 0}, inplace=True)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(datetime.datetime.now())\n",
    "print(f'vectorizer = {vectorizer}')\n",
    "tn, fp, fn, tp = confusion_matrix(y_true = y_test, y_pred = y_pred).ravel()\n",
    "(tn, fp, fn, tp)\n",
    "metrics_(tn, fp, fn, tp)\n",
    "print(f'tn={tn}, fp={fp}, fn={fn}, tp={tp})')\n",
    "print(f'num_features = {rf_clf.n_features_}')\n",
    "#print(rf_clf.n_classes_)\n",
    "#print(rf_clf.n_outputs_)\n",
    "feat_names = vectorizer.get_feature_names()\n",
    "feature_import = rf_clf.feature_importances_\n",
    "print(type(feature_import))\n",
    "feature_import.shape\n",
    "print(f'vectorizer = {vectorizer}')\n",
    "# what are the actual parametrs set in the function. something specific about the random forest i forgot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rate of correct predictions out of total predictions\n",
    "def metrics_(tn, fp, fn, tp):\n",
    "    print(datetime.datetime.now())\n",
    "    accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "    print(f'accuracy = {accuracy}')\n",
    "    recall = (tp) / (tp + fn)\n",
    "    print(f'recall = {recall}')\n",
    "    precision = (tp) / (tp + fp)\n",
    "    print(f'precision = {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that removes string.punctuation w/out the '?'\n",
    "def punc_strip(string):\n",
    "    my_lil_punc_string = '!\"#$$%&\\()*+,-./:;<=>@[\\\\]^_`{|}~'\n",
    "    extras = '[\\',.â€œ-â€â€™!â€”:()?@]$;\"â€“/#|&â€˜Â°\\\\â€¦%<â€+Â¡Â«Â»_â€¢*>â€º=â‚¬Â·â– â™¦Â£ğŸ’ƒğŸ½âˆ™â‰ {}Â¿ğŸ˜‚Â¥Ì‡Ìƒâ˜…Â§ğŸ‡ºğŸ‡¸Â©ï¼ğŸ’£ã€‚^â€‘ğŸ”¥ğŸ˜¡â€³Ì€ğŸš¨âƒ£ğŸ˜¤ğŸŒ«`â—ğŸ¤­âœ“ğŸ“–ğŸ“¹âœ‹ğŸ‘€Â¢ğŸ’”ğŸ˜â€’ğŸ“²ğŸ“ºğŸ™ï¿¼ğŸ˜â†“â¤ï¸ğŸ˜˜ğŸ‰ğŸ¥‚ğŸ¦”ğŸ¥©ğŸğŸ‘ğŸ¤¸ğŸ•³ğŸŒµâ›½âš•ğŸ”Šâ„¢â€ â€¾â€²Ìˆ×´Ã·ğŸ’œğŸ’›Â¨Â´ğŸ’¥â˜„Ì~â€šâŒšâ†‘ğŸğŸ‡°ğŸ‡ªğŸŒâ†’ğŸ—£â”€â€¼â—‡ğŸ˜¾ğŸ¤·ğŸ»â™‚âœ”ğŸ’ªÂ®â™ªğŸ˜±ğŸ‘ØŒÂ¯âŒ˜ğŸŒˆğŸ¤©âœ¨ÌŠğŸ¤£âˆ’ğŸ˜‰â™¥ğŸ‘ğŸ’©ğŸ¤ğŸ’‹ğŸ§“ğŸ‘®ğŸ‘´â™€ğŸ¥´ğŸâš¡ğŸ¤”ğŸ™Ã—ğŸ’¯ğŸš‚ğŸ™ğŸ¾à¹ˆà¦¾à¦‚à¦¼à§‡à§à¦¿à§ğŸ†ğŸ’¦ğŸ¥ğŸ’Œâ—¾ğŸ“±ğŸ‘‹ğŸ¼ØŸğŸ™‚ğŸš«â—ğŸ™„ğŸ›‘ğŸŒ§â„Ì¶ğŸ¤ï¼›ğŸ¤¯ğŸ§µğŸ˜¹Â¶â¡ğŸ˜ğŸ”§âœŒâ¼â—‰ğŸ±âšªÌ§Ì„â”ğŸ˜ºğŸ˜ğŸ‡¬ğŸ‡§ğŸ‘ğŸº'\n",
    "    punc_list = my_lil_punc_string + extras\n",
    "    \n",
    "    for char in string:\n",
    "        if char in punc_list:  \n",
    "            string = string.replace(char, \"\")\n",
    "            \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.19 s, sys: 321 ms, total: 2.51 s\n",
      "Wall time: 2.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_2019 = pd.read_csv('data/p_section_notna2019.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.04 ms, sys: 1.76 ms, total: 7.8 ms\n",
      "Wall time: 7.45 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_2019_df = _2019.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X. X is currently pandas series of unsplit strings\n",
    "\n",
    "X = _2019_df.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# manual punctuation work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #function that removes string.punctuation w/out the '?'\n",
    "# def punc_strip(string):\n",
    "#     my_lil_punc_string = '!\"#$%&\\()*+,-./:;<=>@[\\\\]^_`{|}~'\n",
    "#     extras = '[\\',.â€œ-â€â€™!â€”:()?@]$;\"â€“/#|&â€˜Â°\\\\â€¦%<â€+Â¡Â«Â»_â€¢*>â€º=â‚¬Â·â– â™¦Â£ğŸ’ƒğŸ½âˆ™â‰ {}Â¿ğŸ˜‚Â¥Ì‡Ìƒâ˜…Â§ğŸ‡ºğŸ‡¸Â©ï¼ğŸ’£ã€‚^â€‘ğŸ”¥ğŸ˜¡â€³Ì€ğŸš¨âƒ£ğŸ˜¤ğŸŒ«`â—ğŸ¤­âœ“ğŸ“–ğŸ“¹âœ‹ğŸ‘€Â¢ğŸ’”ğŸ˜â€’ğŸ“²ğŸ“ºğŸ™ï¿¼ğŸ˜â†“â¤ï¸ğŸ˜˜ğŸ‰ğŸ¥‚ğŸ¦”ğŸ¥©ğŸğŸ‘ğŸ¤¸ğŸ•³ğŸŒµâ›½âš•ğŸ”Šâ„¢â€ â€¾â€²Ìˆ×´Ã·ğŸ’œğŸ’›Â¨Â´ğŸ’¥â˜„Ì~â€šâŒšâ†‘ğŸğŸ‡°ğŸ‡ªğŸŒâ†’ğŸ—£â”€â€¼â—‡ğŸ˜¾ğŸ¤·ğŸ»â™‚âœ”ğŸ’ªÂ®â™ªğŸ˜±ğŸ‘ØŒÂ¯âŒ˜ğŸŒˆğŸ¤©âœ¨ÌŠğŸ¤£âˆ’ğŸ˜‰â™¥ğŸ‘ğŸ’©ğŸ¤ğŸ’‹ğŸ§“ğŸ‘®ğŸ‘´â™€ğŸ¥´ğŸâš¡ğŸ¤”ğŸ™Ã—ğŸ’¯ğŸš‚ğŸ™ğŸ¾à¹ˆà¦¾à¦‚à¦¼à§‡à§à¦¿à§ğŸ†ğŸ’¦ğŸ¥ğŸ’Œâ—¾ğŸ“±ğŸ‘‹ğŸ¼ØŸğŸ™‚ğŸš«â—ğŸ™„ğŸ›‘ğŸŒ§â„Ì¶ğŸ¤ï¼›ğŸ¤¯ğŸ§µğŸ˜¹Â¶â¡ğŸ˜ğŸ”§âœŒâ¼â—‰ğŸ±âšªÌ§Ì„â”ğŸ˜ºğŸ˜ğŸ‡¬ğŸ‡§ğŸ‘ğŸº'\n",
    "#     punc_list = my_lil_punc + extras\n",
    "    \n",
    "#     for char in string:\n",
    "#         if char in punc_list:  \n",
    "#             string = string.replace(char, \"\")\n",
    "            \n",
    "#     return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.3 s, sys: 291 ms, total: 36.6 s\n",
      "Wall time: 36.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = X.apply(punc_strip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define y as a series of op-ed or news\n",
    "\n",
    "y = _2019_df.type_of_material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.07 ms, sys: 944 Âµs, total: 9.01 ms\n",
      "Wall time: 8.44 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# vectorize y in to (1, 0) (op-ed, news)\n",
    "\n",
    "y = vectorize_type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn series into list...\n",
    "\n",
    "corpus = list(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Advertisement Supported by Imagine what we could do with our money and hours if we set our phones aside for a year By Paul Greenberg Mr Greenberg is a fellow at the Safina Center More than threequarters of all Americans own a smartphone In 2018 those 253 million Americans spent 1380 and 1460 hours on their smartphone and other mobile devices Thats 91 waking days cumulatively that adds up to 370 billion waking American hours and 349 billion In 2019 heres what we could do instead In most Western states that 1380 you spent on your phone could buy half an acre of land In the right conditions that half acre could easily accommodate 150 trees A single tree sequesters 48 pounds of carbon a year It takes about 30 minutes for an amateur forester to plant a tree If every American smartphone owner used that time and money to plant half an acre of trees we would sequester about 886 million tons of carbon a year enough to offset more than 10 percent of the countrys annual emissions If you dont want to do the planting yourself the National Forest Foundation says it could meet all of its planting goals if every smartphone user gave it just 60 cents A recent study of romantic relationships among college students in the journal Psychology of Popular Media Culture found that smartphone dependency is significantly linked to relationship uncertainty and that partners perceived smartphone dependency predicts less relationship satisfaction According to another recent study more than 29 percent of Americans would rather give up sex for three months than give up their smartphone for a single week Now flip that around If you gave up your device for a year you would have time to make love about 16000 times assuming youre like most Americans and your lovemaking sessions last an average of 54 minutes not counting foreplay If all that sex doesnt bring you and your partner closer you could pay for about four hours of couples therapy Not enough time The renowned couples therapist Esther Perel has managed to fix some couples problems in three Currently the American political system undercounts the votes of the majority of Americans either through gerrymandering or the unfair distribution of Senate seats and electoral votes But this system can be changed particularly if we push for a program for voter reform at a grassroots level As David Gold an attorney with the organization Democratism noted Quitting devices would give citizens enough time and money to visit their local and state representatives three times a week for a year and cover the cost of the trip in gas or mass transit to lobby for reform Every year 10 million tons of plastic waste flows into the ocean According to George Leonard of the Ocean Conservancy if Americans applied all the money they allocate to smartphones to solving plastic pollution There would be enough money available to pay for the necessary improvements in waste management in Asian countries for 70 years And if the time Americans spent on smartphones were applied to ocean clean up at a rate of five pounds of plastic garbage per person per hour The volunteer effort could clean up the amount of plastic that flows into the global ocean 118 times over The average reader reading at a speed of 280 words per minute would take approximately 71Â½ hours to read the 13 million words in Marcel Prousts In Search of Lost Time With 1460 hours repurposed from device usage a reader would get through the books almost 20 times With the 1380 in devicefree savings you could spend the weekend in IlliersCombray the setting of Prousts first madeleinesoaked memories and see if he got it right According to the Mayo Clinic swimming walking or running for 30 minutes a day will lower your blood pressure by four to nine millimeters of mercury as much or more than some blood pressure medication Yes you could keep your phone with you while you exercise but who needs the stress And if youd rather not exercise blood pressure medication costs about 900 per year The average American spends 14000 per decade on smartphones Thats 70000 over the course of an average working life Invested in a conservative mutual fund with an annual rate of return of 4 percent that would yield over 13 million in retirement savings The current median household retirement savings is 5000 Last year the globecircling Scottish cyclist Mark Beaumont smashed the world circumnavigation record by riding around the worlds land mass in 79 days He pedaled 16 hours a day for a total of 1264 hours  or just under a years worth of smartphone usage Average humans couldnt match Mr Beaumonts feat but the money and time saved by ditching their phones would afford them a lot of time with a personal trainer Smartphone usage is highest among teenagers and people in their early 20s And its at this crucial time when virtuosity in a musical instrument can be attained At current rates of device usage most young people will burn through the famous 10000 hours Malcolm Gladwell associated with becoming an elite pianist over the course of the next decade How many virtuosos will we lose in the years ahead if device use among young people continues to grow apace Using English as a baseline you would need approximately 700 hours to become proficient in a foreign language as measured by Common European Framework of Reference for Languages With the time you spend staring into your device you could learn two A recent study found that children between 7 months and 24 months old experienced higher levels of distress and were less likely to investigate their surroundings when their parents were on their mobile devices Secure attachment begins in infancy when children take visual cues of attachment from their parents gaze Every moment you look at your infant instead of your phone is an investment in the future Paul Greenberg is a fellow at the Safina Center and the author of the forthcoming iQuit 50 Things to Do iNstead Follow The New York Times Opinion section on Facebook Twitter NYTopinion and Instagram Advertisement'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn TfidfVectorizer(stop_words='english', strip_accents='ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #create vectorizer\n",
    "\n",
    "# vectorizer = TfidfVectorizer(#input='content', \n",
    "# #                 encoding='utf-8', \n",
    "# #                 decode_error='strict', \n",
    "#                  strip_accents=None, \n",
    "#                  lowercase=True, \n",
    "# #                 preprocessor=None, \n",
    "# #                 tokenizer=None, \n",
    "# #                 analyzer='word', \n",
    "#                  stop_words='english', \n",
    "# #                 token_pattern='(?u)\\b\\w\\w+\\b', \n",
    "# #                 ngram_range=(1, 1), \n",
    "# #                 max_df=1.0, \n",
    "# #                 min_df=1, \n",
    "#                  max_features=None, \n",
    "# #                 vocabulary=None, \n",
    "# #                 binary=False, \n",
    "# #                 dtype=<class 'numpy.float64'>, \n",
    "# #                 norm='l2', \n",
    "# #                 use_idf=True, \n",
    "# #                 smooth_idf=True, \n",
    "# #                 sublinear_tf=False\n",
    "# )\n",
    "# X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# stop_words = vectorizer.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_names;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resample class size w/ imbalanced learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #balance the classes\n",
    "\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# rus = RandomUnderSampler(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #X, y --> X_resampled, y_resampled\n",
    "# X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "\n",
    "# #return a list of tuples for item, and count of item. in this case 4139 each\n",
    "# print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #test, train, split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes/imbalanced learn/TFIDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# multinm_clf = MultinomialNB()\n",
    "# multinm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multinm_clf.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = multinm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #clf.score = accuracy = 'true'(pos/neg) / total\n",
    "\n",
    "# multinm_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix(y_true = y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tn, fp, fn, tp = confusion_matrix(y_true = y_test, y_pred = y_pred).ravel()\n",
    "# (tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "\n",
    "# accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # rate of actual op-ed articles, out of all the actual od-ed articles\n",
    "\n",
    "# recall = (tp) / (tp + fn)\n",
    "# recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rate of correct predictions of op-ed articles out of all predictions\n",
    "\n",
    "# precision = (tp) / (tp + fp)\n",
    "# precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "\n",
    "# accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "# print(f'accuracy = {accuracy}')\n",
    "# recall = (tp) / (tp + fn)\n",
    "# print(f'recall = {recall}')\n",
    "# precision = (tp) / (tp + fp)\n",
    "# print(f'precision = {precision}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class sklearn.ensemble.RandomForestClassifier(n_estimators=100, \n",
    "#                                               *, \n",
    "#                                               criterion='gini', \n",
    "#                                               max_depth=None, \n",
    "#                                               min_samples_split=2, \n",
    "#                                               min_samples_leaf=1, \n",
    "#                                               min_weight_fraction_leaf=0.0, \n",
    "#                                               max_features='auto', \n",
    "#                                               max_leaf_nodes=None, \n",
    "#                                               min_impurity_decrease=0.0, \n",
    "#                                               min_impurity_split=None, \n",
    "#                                               bootstrap=True, \n",
    "#                                               oob_score=False, \n",
    "#                                               n_jobs=None, \n",
    "#                                               random_state=None, \n",
    "#                                               verbose=0, \n",
    "#                                               warm_start=False, \n",
    "#                                               class_weight=None, \n",
    "#                                               ccp_alpha=0.0, \n",
    "#                                               max_samples=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# rf_clf = RandomForestClassifier(max_depth=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #clf.score = accuracy = 'true'(pos/neg) / total\n",
    "\n",
    "# rf_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix(y_true = y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tn, fp, fn, tp = confusion_matrix(y_true = y_test, y_pred = y_pred).ravel()\n",
    "# (tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "\n",
    "# accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rate of actual op-ed articles, out of all the actual od-ed articles\n",
    "\n",
    "# recall = (tp) / (tp + fn)\n",
    "# recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rate of correct predictions of op-ed articles out of all predictions\n",
    "\n",
    "# precision = (tp) / (tp + fp)\n",
    "# precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rate of correct predictions out of total predictions\n",
    "\n",
    "# accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "# print(f'accuracy = {accuracy}')\n",
    "# recall = (tp) / (tp + fn)\n",
    "# print(f'recall = {recall}')\n",
    "# precision = (tp) / (tp + fp)\n",
    "# print(f'precision = {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class sklearn.ensemble.RandomForestClassifier(n_estimators=100, \n",
    "#                                               *, \n",
    "#                                               criterion='gini', \n",
    "#                                               max_depth=None, \n",
    "#                                               min_samples_split=2, \n",
    "#                                               min_samples_leaf=1, \n",
    "#                                               min_weight_fraction_leaf=0.0, \n",
    "#                                               max_features='auto', \n",
    "#                                               max_leaf_nodes=None, \n",
    "#                                               min_impurity_decrease=0.0, \n",
    "#                                               min_impurity_split=None, \n",
    "#                                               bootstrap=True, \n",
    "#                                               oob_score=False, \n",
    "#                                               n_jobs=None, \n",
    "#                                               random_state=None, \n",
    "#                                               verbose=0, \n",
    "#                                               warm_start=False, \n",
    "#                                               class_weight=None, \n",
    "#                                               ccp_alpha=0.0, \n",
    "#                                               max_samples=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_2019_df = _2019.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X. X is currently pandas series of unsplit strings\n",
    "\n",
    "X_nltk = nltk_2019_df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define y as a series of op-ed or news\n",
    "\n",
    "y_nktk = nltk_2019_df.type_of_material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 ms, sys: 1.74 ms, total: 12.2 ms\n",
      "Wall time: 10.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# vectorize y in to (1, 0) (op-ed, news)\n",
    "\n",
    "y_nltk = vectorize_type(y_nktk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn series into list...\n",
    "\n",
    "corpus_nltk = list(X_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenize w/ nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from nltk.tokenize import RegexpTokenizer\n",
    "# regex_tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "# tokenized_punc = [regex_tokenizer.tokenize(article.lower())for article in corpus_nltk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (len(tokenized_punc[0])) #2218"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(tokenized_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# tokenized = [word_tokenize(article.lower()) for article in corpus_nltk]\n",
    "\n",
    "# CPU times: user 4min 46s, sys: 2.39 s, total: 4min 48s\n",
    "# Wall time: 4min 50s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #list of list of strings. one list of strings per documents. list are various lengths around 1000\n",
    "\n",
    "# len(tokenized[0]) #2596"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## take out stop work via ntlk. does this work against sklearn when i vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# stop = set(stopwords.words('english'))\n",
    "# tokenized_docs = [[word for word in words if word not in stop]\n",
    "#             for words in tokenized_punc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #hopefully this reduced the number of strings / list\n",
    "\n",
    "# len(tokenized[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #docs is new tokenized, but with stop words removed\n",
    "\n",
    "# len(tokenized_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stemming/lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# porter = PorterStemmer()\n",
    "snowball = SnowballStemmer('english')\n",
    "# wordnet = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# docs_porter = [[porter.stem(word) for word in words]\n",
    "#                    for words in docs]\n",
    "# docs_snowball = [[snowball.stem(word) for word in words]\n",
    "#                      for words in docs]\n",
    "# docs_wordnet = [[wordnet.lemmatize(word) for word in words]\n",
    "#                     for words in docs]\n",
    "\n",
    "# CPU times: user 14min 59s, sys: 18.4 s, total: 15min 18s\n",
    "# Wall time: 15min 26s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# docs_porter = [[porter.stem(word) for word in words]\n",
    "#                    for words in docs]\n",
    "\n",
    "# CPU times: user 7min 16s, sys: 5.21 s, total: 7min 21s\n",
    "# Wall time: 7min 22s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# snowball_stemm = [[snowball.stem(word) for word in words]\n",
    "#                      for words in tokenized_docs]\n",
    "\n",
    "# # CPU times: user 5min 5s, sys: 5.98 s, total: 5min 11s\n",
    "# # Wall time: 5min 13s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# docs_wordnet = [[wordnet.lemmatize(word) for word in words]\n",
    "#                     for words in docs]\n",
    "\n",
    "# CPU times: user 1min 24s, sys: 4.5 s, total: 1min 28s\n",
    "# Wall time: 1min 30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# ## Print the stemmed and lemmatized words from the first document\n",
    "# print(\"%16s %16s %16s %16s\" % (\"word\", \"porter\", \"snowball\", \"lemmatizer\"))\n",
    "# for i in range(min(len(docs_porter[0]), len(docs_snowball[0]), len(docs_wordnet[0]))):\n",
    "#     p, s, w = docs_porter[0][i], docs_snowball[0][i], docs_wordnet[0][i]\n",
    "#     if len(set((p, s, w))) != 1:\n",
    "#         print(\"%16s %16s %16s %16s\" % (docs[0][i], p, s, w))\n",
    "#         print(docs[0][i], w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs and lemmatizer are the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I choose SNOWBALL!!!! to sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\'Advertisement\\', \\'Supported by\\', \\'Imagine what we could do with our money, and hours, if we set our phones aside for a year.\\', \\'By Paul Greenberg\\', \\'Mr. Greenberg is a fellow at the Safina Center.\\', \\'More than three-quarters of all Americans own a smartphone. In 2018 those 253 million Americans spent $1,380 and 1,460 hours on their smartphone and other mobile devices. Thatâ€™s 91 waking days; cumulatively, that adds up to 370 billion waking American hours and $349 billion.\\', \\'In 2019, hereâ€™s what we could do instead.\\', \"In most Western states, that $1,380 you spent on your phone could buy half an acre of land. In the right conditions, that half acre could easily accommodate 150 trees. A single tree sequesters 48 pounds of carbon a year. It takes about 30 minutes for an amateur forester to plant a tree. If every American smartphone owner used that time and money to plant half an acre of trees, we would sequester about 886 million tons of carbon a year, enough to offset more than 10 percent of the countryâ€™s annual emissions. If you don\\'t want to do the planting yourself, the National Forest Foundation says it could meet all of its planting goals if every smartphone user gave it just 60 cents.\", \\'A recent study of romantic relationships among college students in the journal Psychology of Popular Media Culture found that â€œsmartphone dependency is significantly linked to relationship uncertaintyâ€ and that â€œpartnersâ€™ perceived smartphone dependency predicts less relationship satisfaction.â€ According to another recent study, more than 29 percent of Americans would rather give up sex for three months than give up their smartphone for a single week.\\', \\'Now flip that around: If you gave up your device for a year, you would have time to make love about 16,000 times (assuming youâ€™re like most Americans and your lovemaking sessions last an average of 5.4 minutes, not counting foreplay).\\', \\'If all that sex doesnâ€™t bring you and your partner closer, you could pay for about four hours of couples therapy. Not enough time? The renowned couples therapist Esther Perel has managed to fix some couplesâ€™ problems in three.\\', \\'Currently the American political system undercounts the votes of the majority of Americans, either through gerrymandering or the unfair distribution of Senate seats and electoral votes. But this system can be changed particularly if we push for a program for voter reform at a grassroots level. As David Gold, an attorney with the organization Democratism, noted, â€œQuitting devices would give citizens enough time and money to visit their local and state representatives three times a week for a year and cover the cost of the trip in gas or mass transit to lobby for reform.â€\\', \\'Every year 10 million tons of plastic waste flows into the ocean. According to George Leonard of the Ocean Conservancy, if Americans applied all the money they allocate to smartphones to solving plastic pollution, â€œThere would be enough money available to pay for the necessary improvements in waste management in Asian countries for 70 years.â€ And if the time Americans spent on smartphones were applied to ocean clean up at a rate of five pounds of plastic garbage per person per hour, â€œThe volunteer effort could clean up the amount of plastic that flows into the global ocean 118 times over.â€\\', \\'The average reader, reading at a speed of 280 words per minute, would take approximately 71Â½ hours to read the 1.3 million words in Marcel Proustâ€™s â€œIn Search of Lost Time.â€ With 1,460 hours repurposed from device usage, a reader would get through the books almost 20 times. With the $1,380 in device-free savings, you could spend the weekend in Illiers-Combray, the setting of Proustâ€™s first madeleine-soaked memories, and see if he got it right.\\', \\'According to the Mayo Clinic, swimming, walking or running for 30 minutes a day will lower your blood pressure by four to nine millimeters of mercury, as much or more than some blood pressure medication. Yes, you could keep your phone with you while you exercise, but who needs the stress? And if youâ€™d rather not exercise, blood pressure medication costs about $900 per year.\\', \\'The average American spends $14,000 per decade on smartphones. Thatâ€™s $70,000 over the course of an average working life. Invested in a conservative mutual fund with an annual rate of return of 4 percent, that would yield over $1.3 million in retirement savings. (The current median household retirement savings is $5,000.)\\', \\'Last year the globe-circling Scottish cyclist Mark Beaumont smashed the world circumnavigation record by riding around the worldâ€™s land mass in 79 days. He pedaled 16 hours a day for a total of 1,264 hours â€” or just under a yearâ€™s worth of smartphone usage. Average humans couldnâ€™t match Mr. Beaumontâ€™s feat, but the money and time saved by ditching their phones would afford them a lot of time with a personal trainer.\\', \\'Smartphone usage is highest among teenagers and people in their early 20s. And itâ€™s at this crucial time when virtuosity in a musical instrument can be attained. At current rates of device usage, most young people will burn through the famous 10,000 hours Malcolm Gladwell associated with becoming an â€œelite pianistâ€ over the course of the next decade. How many virtuosos will we lose in the years ahead if device use among young people continues to grow apace?\\', \\'Using English as a baseline, you would need approximately 700 hours to become proficient in a foreign language as measured by Common European Framework of Reference for Languages. With the time you spend staring into your device, you could learn two.\\', \\'A recent study found that children between 7 months and 24 months old experienced higher levels of distress and were less likely to investigate their surroundings when their parents were on their mobile devices. Secure attachment begins in infancy when children take visual cues of attachment from their parentsâ€™ gaze. Every moment you look at your infant instead of your phone is an investment in the future.\\', \\'Paul Greenberg is a fellow at the Safina Center and the author of the forthcoming \"iQuit: 50 Things to Do iNstead.\"\\', \\'Follow The New York Times Opinion section on Facebook, Twitter (@NYTopinion) and Instagram.\\', \\'Advertisement\\']'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(corpus_nltk[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6261"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_nltk[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snowball = SnowballStemmer('english')\n",
    "# snowball_tokenized = [snowball.stem(word) for word in word_tokenize(doc.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 Âµs, sys: 0 ns, total: 3 Âµs\n",
      "Wall time: 5.01 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def snowball_tokenize(doc):\n",
    "    snowball = SnowballStemmer('english')\n",
    "    return [snowball.stem(word) for word in word_tokenize(doc.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_token = snowball_tokenize(corpus_nltk[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1235"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2596\n",
    "len(test_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38 Âµs, sys: 1e+03 ns, total: 39 Âµs\n",
      "Wall time: 39.8 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#create vectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(#input='content', \n",
    "#                 encoding='utf-8', \n",
    "#                 decode_error='strict', \n",
    "                 strip_accents=None, \n",
    "                 lowercase=True, \n",
    "#                 preprocessor=None, \n",
    "                 tokenizer=snowball_tokenize, \n",
    "#                 analyzer='word', \n",
    "                 stop_words=None, \n",
    "#                 token_pattern='(?u)\\b\\w\\w+\\b', \n",
    "#                 ngram_range=(1, 1), \n",
    "                 max_df=0.85, \n",
    "                 min_df=0.15, \n",
    "                 max_features=None, \n",
    "#                 vocabulary=None, \n",
    "#                 binary=False, \n",
    "#                 dtype=<class 'numpy.float64'>, \n",
    "#                 norm='l2', \n",
    "#                 use_idf=True, \n",
    "#                 smooth_idf=True, \n",
    "#                 sublinear_tf=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-04 00:27:59.387722\n",
      "CPU times: user 10min, sys: 3.47 s, total: 10min 4s\n",
      "Wall time: 10min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "X_snowball = vectorizer.fit_transform(corpus_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.85, min_df=0.15,\n",
       "                tokenizer=<function snowball_tokenize at 0x7f986bb795f0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class sklearn.feature_extraction.text.CountVectorizer(*, \n",
    "#                                                       input='content', \n",
    "#                                                       encoding='utf-8', \n",
    "#                                                       decode_error='strict', \n",
    "#                                                       strip_accents=None, \n",
    "#                                                       lowercase=True, \n",
    "#                                                       preprocessor=None, \n",
    "#                                                       tokenizer=None, \n",
    "#                                                       stop_words=None, \n",
    "#                                                       token_pattern='(?u)\\b\\w\\w+\\b', \n",
    "#                                                       ngram_range=(1, 1), \n",
    "#                                                       analyzer='word', \n",
    "#                                                       max_df=1.0, \n",
    "#                                                       min_df=1, \n",
    "#                                                       max_features=None, \n",
    "#                                                       vocabulary=None, \n",
    "#                                                       binary=False, \n",
    "#                                                       dtype=<class 'numpy.int64'>\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(strip_accents='None',\n",
    "                                   lowercase=True,\n",
    "                                   tokenizer=snowball_tokenize,\n",
    "                                   stop_words='english',\n",
    "                                   max_features=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# balance classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #balance the classes\n",
    "\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# rus = RandomUnderSampler(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #X, y --> X_resampled, y_resampled\n",
    "# X_resampled, y_resampled = rus.fit_resample(X_snowball, y_nltk)\n",
    "# print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #test, train, split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# rf_clf = RandomForestClassifier(max_depth=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #clf.score = accuracy = 'true'(pos/neg) / total\n",
    "\n",
    "# rf_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tn, fp, fn, tp = confusion_matrix(y_true = y_test, y_pred = y_pred).ravel()\n",
    "# (tn, fp, fn, tp)\n",
    "# metrics_(tn, fp, fn, tp)\n",
    "# print(f'tn={tn}, fp={fp}, fn={fn}, tp={tp})')\n",
    "# print(rf_clf.n_features_)\n",
    "# print(rf_clf.n_classes_)\n",
    "# print(rf_clf.n_outputs_)\n",
    "# # what are the actual parametrs set in the function. something specific about the random forest i forgot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stop = vectorizer.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nltk_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(nltk_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30256, 607)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_snowball.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_import = rf_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property feature_importances_\n",
    "# The impurity-based feature importances.\n",
    "\n",
    "# The higher, the more important the feature. The importance of a feature is computed as the (normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance.\n",
    "\n",
    "# Warning: impurity-based feature importances can be misleading for high cardinality features (many unique values). See sklearn.inspection.permutation_importance as an alternative.\n",
    "\n",
    "# Returns\n",
    "# feature_importances_ndarray of shape (n_features,)\n",
    "# The values of this array sum to 1, unless all trees are single node trees consisting of only the root node, in which case it will be an array of zeros.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_scores = pd.Series(feature_import,\n",
    "#                            index=nltk_features)\n",
    "# feat_scores = feat_scores.sort_values()\n",
    "# ax = feat_scores.plot(kind='barh', figsize=(10,20))\n",
    "# ax.set_title('\"Decrease in Impurity\" Importance')\n",
    "# ax.set_xlabel('Average contribution to the reduction in variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = permutation_importance(rf_clf, X_test, y_test, n_repeats=30, random_state=0)\n",
    "# for index in r.importances_mean.argsort()[::-1]:\n",
    "#     if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "#         print(f\"{feature_names[i]:<8}\"\n",
    "#               f\"{r.importances_mean[i]:.3f}\"\n",
    "#               f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# test_x = test_vectorizer.fit_transform(corpus_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2043), (1, 2043)]\n",
      "RandomUnderSampler(random_state=0)\n",
      "CPU times: user 10.4 ms, sys: 3.26 ms, total: 13.6 ms\n",
      "Wall time: 12.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#balance the classes\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "\n",
    "#X, y --> X_resampled, y_resampled\n",
    "X_resampled, y_resampled = rus.fit_resample(X_snowball, y_nltk)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "print(rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.36 ms, sys: 2.89 ms, total: 7.25 ms\n",
      "Wall time: 6.11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#test, train, split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 448 ms, sys: 7.73 ms, total: 455 ms\n",
      "Wall time: 456 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-04 00:38:08.480030\n",
      "vectorizer = TfidfVectorizer(max_df=0.85, min_df=0.15,\n",
      "                tokenizer=<function snowball_tokenize at 0x7f986bb795f0>)\n",
      "accuracy = 0.9422700587084148\n",
      "recall = 0.8955512572533849\n",
      "precision = 0.9893162393162394\n",
      "tn=500, fp=5, fn=54, tp=463)\n",
      "num_features = 607\n",
      "<class 'numpy.ndarray'>\n",
      "vectorizer = TfidfVectorizer(max_df=0.85, min_df=0.15,\n",
      "                tokenizer=<function snowball_tokenize at 0x7f986bb795f0>)\n",
      "CPU times: user 13.1 ms, sys: 3.5 ms, total: 16.6 ms\n",
      "Wall time: 14.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.datetime.now())\n",
    "print(f'vectorizer = {vectorizer}')\n",
    "tn, fp, fn, tp = confusion_matrix(y_true = y_test, y_pred = y_pred).ravel()\n",
    "(tn, fp, fn, tp)\n",
    "metrics_(tn, fp, fn, tp)\n",
    "print(f'tn={tn}, fp={fp}, fn={fn}, tp={tp})')\n",
    "print(f'num_features = {rf_clf.n_features_}')\n",
    "#print(rf_clf.n_classes_)\n",
    "#print(rf_clf.n_outputs_)\n",
    "feat_names = vectorizer.get_feature_names()\n",
    "feature_import = rf_clf.feature_importances_\n",
    "print(type(feature_import))\n",
    "feature_import.shape\n",
    "print(f'vectorizer = {vectorizer}')\n",
    "# what are the actual parametrs set in the function. something specific about the random forest i forgot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feature_import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022, 607)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022,)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-04 00:38:08.514854\n",
      "CPU times: user 192 ms, sys: 32 ms, total: 224 ms\n",
      "Wall time: 294 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Average contribution to the reduction in variance')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.datetime.now())\n",
    "feat_scores = pd.Series(feature_import,\n",
    "                           index=feat_names)\n",
    "feat_scores = feat_scores.sort_values()\n",
    "ax = feat_scores[-20:].plot(kind='barh', figsize=(10,20))\n",
    "ax.set_title('\"Decrease in Impurity\" Importance')\n",
    "ax.set_xlabel('Average contribution to the reduction in variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-04 00:38:09.007928\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m                 \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/inspection/_permutation_importance.py\u001b[0m in \u001b[0;36mpermutation_importance\u001b[0;34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state)\u001b[0m\n\u001b[1;32m    135\u001b[0m     scores = Parallel(n_jobs=n_jobs)(delayed(_calculate_permutation_scores)(\n\u001b[1;32m    136\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     ) for col_idx in range(X.shape[1]))\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mimportances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline_score\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/inspection/_permutation_importance.py\u001b[0m in \u001b[0;36m_calculate_permutation_scores\u001b[0;34m(estimator, X, y, col_idx, random_state, n_repeats, scorer)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mX_permuted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_permuted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshuffling_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mfeature_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_permuted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_round\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \"\"\"\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \"\"\"\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    684\u001b[0m             delayed(_accumulate_prediction)(e.predict_proba, X, all_proba,\n\u001b[1;32m    685\u001b[0m                                             lock)\n\u001b[0;32m--> 686\u001b[0;31m             for e in self.estimators_)\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mproba\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    855\u001b[0m                                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nested_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m                                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reducer_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m                                          self._pickle_cache)\n\u001b[0m\u001b[1;32m    858\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, iterator_slice, backend_and_jobs, reducer_callback, pickle_cache)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reducer_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreducer_callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_and_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend_and_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.datetime.now())\n",
    "r = permutation_importance(rf_clf, X_test.toarray(), y_test, n_repeats=30, random_state=0)\n",
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "        print(f\"{feat_names[i]:<8}\"\n",
    "              f\"{r.importances_mean[i]:.3f}\"\n",
    "              f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sens         0.001267\n",
       "mani         0.001284\n",
       "seem         0.001299\n",
       "author       0.001310\n",
       "there        0.001319\n",
       "fact         0.001346\n",
       "statement    0.001461\n",
       "â€˜            0.001571\n",
       "rather       0.001606\n",
       "season       0.001622\n",
       "comment      0.001623\n",
       "do           0.001719\n",
       "tuesday      0.001799\n",
       "friday       0.002157\n",
       "me           0.002360\n",
       "month        0.002612\n",
       "elect        0.002974\n",
       "should       0.002979\n",
       "two          0.003585\n",
       "ad           0.003685\n",
       "t            0.004260\n",
       "if           0.004280\n",
       "interview    0.004498\n",
       "?            0.004775\n",
       "about        0.005079\n",
       "actual       0.005253\n",
       "trump        0.005717\n",
       "ms.          0.005775\n",
       "all          0.006343\n",
       "polit        0.006506\n",
       "some         0.006745\n",
       "â€”            0.006815\n",
       "american     0.007597\n",
       "america      0.007982\n",
       "or           0.009995\n",
       "you          0.010766\n",
       "mr           0.013420\n",
       "like         0.015586\n",
       "follow       0.016222\n",
       "mr.          0.016847\n",
       "ani          0.020204\n",
       "what         0.026053\n",
       "think        0.027135\n",
       "here         0.027260\n",
       ":            0.027314\n",
       "(            0.027780\n",
       "york         0.031114\n",
       "twitter      0.031989\n",
       "hear         0.032132\n",
       "we           0.032751\n",
       "time         0.034157\n",
       "facebook     0.037798\n",
       "said         0.044982\n",
       "d            0.048962\n",
       "letter       0.051223\n",
       ")            0.052248\n",
       "our          0.052415\n",
       "publish      0.052463\n",
       "commit       0.054793\n",
       "email        0.068486\n",
       "dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_scores[-60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
